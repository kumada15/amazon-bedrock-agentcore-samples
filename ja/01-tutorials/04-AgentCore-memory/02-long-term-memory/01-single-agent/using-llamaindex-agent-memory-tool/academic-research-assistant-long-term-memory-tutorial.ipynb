{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex ã¨ AgentCore Memory - å­¦è¡“ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆï¼ˆé•·æœŸè¨˜æ†¶ï¼‰\n",
    "\n",
    "## ã¯ã˜ã‚ã«\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€Amazon Bedrock AgentCore Memory æ©Ÿèƒ½ã¨ LlamaIndex ã‚’çµ±åˆã—ã¦ã€**é•·æœŸè¨˜æ†¶**ã‚’æŒã¤å­¦è¡“ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚è¤‡æ•°ã®ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã§ã®æ°¸ç¶šæ€§ã‚’å®Ÿç¾ã—ã€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒæ•°é€±é–“ã‹ã‚‰æ•°ãƒ¶æœˆã«ã‚ãŸã‚‹ç ”ç©¶ä½œæ¥­ã§ç´¯ç©çš„ãªçŸ¥è­˜ã‚’æ§‹ç¯‰ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚\n",
    "\n",
    "## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦\n",
    "\n",
    "![LlamaIndex AgentCore Long-Term Memory Architecture](LlamaIndex-AgentCore-LTM-Arch.png)\n",
    "\n",
    "## ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã®è©³ç´°\n",
    "\n",
    "**ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«è©³ç´°:**\n",
    "- **ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ—**: é•·æœŸã‚¯ãƒ­ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ Memory\n",
    "- **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹**: å­¦è¡“ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ\n",
    "- **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: LlamaIndex\n",
    "- **LLM ãƒ¢ãƒ‡ãƒ«**: Anthropic Claude 3.7 Sonnet\n",
    "- **ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ**: AgentCore é•·æœŸ Memoryã€LlamaIndex Agentã€ç ”ç©¶ãƒ„ãƒ¼ãƒ«\n",
    "- **é›£æ˜“åº¦**: ä¸Šç´š\n",
    "\n",
    "## ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤\n",
    "\n",
    "**ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç ”ç©¶ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹**: çµ„ç¹”ã®çŸ¥è­˜ã‚’è“„ç©ã—ã€ç ”ç©¶ã®é€²åŒ–ã‚’è¿½è·¡ã—ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨æœŸé–“ã«ã‚ãŸã‚‹åŒ…æ‹¬çš„ãªå­¦è¡“ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¶­æŒã™ã‚‹æ°¸ç¶šçš„ãª AI ãƒ¡ãƒ¢ãƒªã§ç ”ç©¶ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å¤‰é©ã—ã¾ã™ã€‚\n",
    "\n",
    "**ä¸»ãªå°‚é–€çš„åˆ©ç‚¹:**\n",
    "- **ç ”ç©¶ã®ç¶™ç¶šæ€§**: ç ”ç©¶ãƒ•ã‚§ãƒ¼ã‚ºã¨ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼é–“ã®ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ãªçŸ¥è­˜ç§»è»¢\n",
    "- **çµ„ç¹”çš„è¨˜æ†¶**: é‡è¦ãªç ”ç©¶ã‚¤ãƒ³ã‚µã‚¤ãƒˆã€æ–¹æ³•è«–ã€ç™ºè¦‹ã‚’æ°¸ç¶šçš„ã«ä¿å­˜\n",
    "- **ã‚¯ãƒ­ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹**: è¤‡æ•°ã®ç ”ç©¶ã‚¤ãƒ‹ã‚·ã‚¢ãƒãƒ–ã«ã‚ãŸã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨é–¢é€£æ€§ã‚’ç‰¹å®š\n",
    "- **åŠ©æˆé‡‘ç”³è«‹ã®å“è¶Šæ€§**: èª¬å¾—åŠ›ã®ã‚ã‚‹è³‡é‡‘ç”³è«‹ã®ãŸã‚ã®éå»ã®ç ”ç©¶ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨\n",
    "- **å­¦è¡“ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: è¤‡æ•°å¹´ã«ã‚ãŸã‚‹å…±åŒç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è©³ç´°ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¶­æŒ\n",
    "- **å‡ºç‰ˆæˆ¦ç•¥**: æˆ¦ç•¥çš„ãªå‡ºç‰ˆè¨ˆç”»ã®ãŸã‚ã®ç ”ç©¶ãƒ†ãƒ¼ãƒã¨å¼•ç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¿½è·¡\n",
    "\n",
    "## é•·æœŸè¨˜æ†¶ã®è¨­å®š\n",
    "\n",
    "**æŠ€è¡“ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**: ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€12ãƒ¶æœˆä¿æŒã® Semantic Strategy ã‚’ä½¿ç”¨ã—ãŸ AgentCore Memory ã‚’ä½¿ç”¨ã—ã¾ã™ï¼š\n",
    "- **Memory ã‚¿ã‚¤ãƒ—**: è‡ªå‹•ã‚¤ãƒ³ã‚µã‚¤ãƒˆæŠ½å‡ºã‚’å‚™ãˆãŸ Semantic Strategy\n",
    "- **ä¿æŒæœŸé–“**: ç ”ç©¶ã®ç¶™ç¶šæ€§ã®ãŸã‚ã®365æ—¥ã‚¤ãƒ™ãƒ³ãƒˆæœ‰åŠ¹æœŸé™\n",
    "- **ã‚¯ãƒ­ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³**: åŒã˜ actor_id + memory_idã€ç ”ç©¶æœŸé–“ã”ã¨ã«ç•°ãªã‚‹ session_id\n",
    "- **æ¤œç´¢æ©Ÿèƒ½**: ç ”ç©¶å±¥æ­´å…¨ä½“ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã®ãŸã‚ã®çµ„ã¿è¾¼ã¿ãƒ¡ãƒ¢ãƒªå–å¾—ãƒ„ãƒ¼ãƒ«\n",
    "\n",
    "## æŠ€è¡“æ¦‚è¦\n",
    "\n",
    "**ä¸»ãªé•·æœŸè¨˜æ†¶ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ:**\n",
    "1. **Semantic Strategy è¨­å®š**: 365æ—¥ä¿æŒã®è‡ªå‹•ã‚¤ãƒ³ã‚µã‚¤ãƒˆæŠ½å‡ºç”¨ SemanticStrategy ã‚’ä½¿ç”¨\n",
    "2. **ã‚¯ãƒ­ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³æ°¸ç¶šæ€§**: åŒã˜ actor_id + memory_idã€æœŸé–“ã”ã¨ã«ç•°ãªã‚‹ session_id ã§çŸ¥è­˜ã®ç¶™ç¶šæ€§ã‚’å®Ÿç¾\n",
    "3. **ã‚«ã‚¹ã‚¿ãƒ  Memory æ¤œç´¢ãƒ„ãƒ¼ãƒ«**: AgentCore ã®ãƒã‚¤ãƒ†ã‚£ãƒ– search_long_term_memories() ã‚’ LlamaIndex FunctionTool ã§ãƒ©ãƒƒãƒ—\n",
    "4. **ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**: ä¼šè©±ã‚¤ãƒ™ãƒ³ãƒˆ â†’ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªå¤‰æ›ã®ãŸã‚ã®90ç§’å¾…æ©Ÿ\n",
    "5. **å‹•çš„ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†**: æŸ”è»Ÿãªã‚»ãƒƒã‚·ãƒ§ãƒ³å‡¦ç†ã®ãŸã‚ memory.context.session_id ã‚’ä½¿ç”¨\n",
    "\n",
    "**å­¦ç¿’å†…å®¹:**\n",
    "\n",
    "- è¤‡æ•°ã®ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ã‚ãŸã‚‹æ°¸ç¶šçš„ãª AgentCore Memory ã®ä½œæˆ\n",
    "- æ™‚é–“çµŒéã«ä¼´ã†ç´¯ç©çš„ãªç ”ç©¶çŸ¥è­˜ã®æ§‹ç¯‰\n",
    "- ç ”ç©¶å±¥æ­´å…¨ä½“ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã®å®Ÿè£…\n",
    "- ç ”ç©¶ã®é€²åŒ–ã¨å°‚é–€æ€§ã®ç™ºå±•ã‚’è¿½è·¡\n",
    "- ã‚¯ãƒ­ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¡ãƒ¢ãƒªã®æ°¸ç¶šæ€§ã¨å–å¾—ã®ãƒ†ã‚¹ãƒˆ\n",
    "\n",
    "## å‰ææ¡ä»¶\n",
    "\n",
    "- Python 3.10ä»¥ä¸Š\n",
    "- é©åˆ‡ãªæ¨©é™ã‚’æŒã¤ AWS ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "- AgentCore Memory æ¨©é™ã‚’æŒã¤ AWS IAM ãƒ­ãƒ¼ãƒ«ï¼š\n",
    "  - `bedrock-agentcore:CreateMemory`\n",
    "  - `bedrock-agentcore:CreateEvent`\n",
    "  - `bedrock-agentcore:ListEvents`\n",
    "  - `bedrock-agentcore:RetrieveMemories`\n",
    "- Amazon Bedrock ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 1: ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries including semantic strategy toolkit\n",
    "%pip install llama-index-memory-bedrock-agentcore llama-index-llms-bedrock-converse boto3 bedrock-agentcore-starter-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required components\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from bedrock_agentcore_starter_toolkit.operations.memory.manager import MemoryManager\n",
    "from bedrock_agentcore.memory.session import MemorySessionManager\n",
    "from bedrock_agentcore_starter_toolkit.operations.memory.models.strategies.semantic import SemanticStrategy\n",
    "from llama_index.memory.bedrock_agentcore import AgentCoreMemory, AgentCoreMemoryContext\n",
    "from llama_index.llms.bedrock_converse import BedrockConverse\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"âœ… All dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 2: AgentCore Memory ã®è¨­å®š\n",
    "\n",
    "é•·æœŸç ”ç©¶çŸ¥è­˜ã®ãŸã‚ã® AgentCore Memory ãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã¾ãŸã¯å–å¾—ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AgentCore Memory with Semantic Strategy for long-term persistence\n",
    "region = os.getenv('AWS_REGION', 'us-east-1')\n",
    "memory_manager = MemoryManager(region_name=region)\n",
    "\n",
    "try:\n",
    "    # Create memory with semantic strategy for automatic insight extraction\n",
    "    memory = memory_manager.get_or_create_memory(\n",
    "        name=f'AcademicResearchSemantic_{int(datetime.now().timestamp())}',\n",
    "        strategies=[SemanticStrategy(name=\"researchLongTermMemory\")],\n",
    "        event_expiry_days=365  # 12-month retention for research records\n",
    "    )\n",
    "    memory_id = memory.get('id')\n",
    "    print(f\"âœ… Created Semantic Memory: {memory_id}\")\n",
    "    print(f\"   Status: {memory.get('status')}\")\n",
    "    print(f\"   Strategies: {[s.get('name') if isinstance(s, dict) else str(s) for s in memory.get('strategies', [])]}\")\n",
    "    \n",
    "    # Wait for memory to become ACTIVE\n",
    "    if memory.get('status') != 'ACTIVE':\n",
    "        print(f\"\\nâ³ Waiting for memory to become ACTIVE (currently {memory.get('status')})...\")\n",
    "        import time\n",
    "        max_wait = 300  # 5 minutes max\n",
    "        waited = 0\n",
    "        while waited < max_wait:\n",
    "            time.sleep(10)\n",
    "            waited += 10\n",
    "            # Check status\n",
    "            current_memory = memory_manager.get_memory(memory_id)\n",
    "            status = current_memory.get('status')\n",
    "            print(f\"   [{waited}s] Status: {status}\")\n",
    "            if status == 'ACTIVE':\n",
    "                print(f\"âœ… Memory is now ACTIVE! (took {waited} seconds)\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"âš ï¸  Memory still not ACTIVE after {max_wait}s. Proceeding anyway...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating memory: {e}\")\n",
    "    memory_id = \"your-memory-id-here\"  # Replace with existing memory ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 3: ç ”ç©¶ãƒ„ãƒ¼ãƒ«ã®å®Ÿè£…\n",
    "\n",
    "å­¦è¡“ç ”ç©¶ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã®å°‚é–€ãƒ„ãƒ¼ãƒ«ã‚’å®šç¾©ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_paper_summary(title: str, authors: str, key_findings: str) -> str:\n",
    "    \"\"\"Save a research paper summary with title, authors, and key findings\"\"\"\n",
    "    print(f\"ğŸ“„ Saved paper: {title} by {authors}\")\n",
    "    return f\"Successfully saved paper summary for '{title}'\"\n",
    "\n",
    "def track_research_topic(topic: str, status: str) -> str:\n",
    "    \"\"\"Track research topic progress with current status\"\"\"\n",
    "    print(f\"ğŸ”¬ Tracking research topic: {topic} (Status: {status})\")\n",
    "    return f\"Now tracking research topic: {topic} with status {status}\"\n",
    "\n",
    "def save_research_finding(finding: str, confidence: str) -> str:\n",
    "    \"\"\"Save a research finding with confidence level\"\"\"\n",
    "    print(f\"ğŸ’¡ Research finding saved with {confidence} confidence\")\n",
    "    return f\"Saved research finding with {confidence} confidence level\"\n",
    "\n",
    "def update_research_status(topic: str, new_status: str, notes: str) -> str:\n",
    "    \"\"\"Update research topic status with notes\"\"\"\n",
    "    print(f\"ğŸ“Š Updated {topic} status to: {new_status}\")\n",
    "    return f\"Updated research status for {topic}\"\n",
    "\n",
    "def log_research_milestone(period: str, milestone: str, details: str) -> str:\n",
    "    \"\"\"Log a research milestone with period and detailed progress\"\"\"\n",
    "    print(f\"ğŸ¯ {period} milestone: {milestone}\")\n",
    "    return f\"Logged milestone for {period}: {milestone} - {details}\"\n",
    "\n",
    "def track_research_metrics(metric_type: str, value: str, source: str, period: str) -> str:\n",
    "    \"\"\"Track specific research metrics with source and timeline\"\"\"\n",
    "    print(f\"ğŸ“Š {period}: {metric_type} = {value} (from {source})\")\n",
    "    return f\"Tracked {metric_type}: {value} from {source} in {period}\"\n",
    "\n",
    "def save_research_insight(insight: str, period: str, connections: str) -> str:\n",
    "    \"\"\"Save research insights with connections to previous work\"\"\"\n",
    "    print(f\"ğŸ’¡ {period} insight: {insight[:50]}...\")\n",
    "    return f\"Saved {period} insight with connections: {connections}\"\n",
    "\n",
    "# Create tool objects for the agent\n",
    "research_tools = [\n",
    "    FunctionTool.from_defaults(fn=save_paper_summary),\n",
    "    FunctionTool.from_defaults(fn=track_research_topic),\n",
    "    FunctionTool.from_defaults(fn=save_research_finding),\n",
    "    FunctionTool.from_defaults(fn=update_research_status),\n",
    "    FunctionTool.from_defaults(fn=log_research_milestone),\n",
    "    FunctionTool.from_defaults(fn=track_research_metrics),\n",
    "    FunctionTool.from_defaults(fn=save_research_insight)\n",
    "]\n",
    "\n",
    "print(\"âœ… Research tools created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 3b: Memory å–å¾—ãƒ„ãƒ¼ãƒ«ã®è¿½åŠ \n",
    "\n",
    "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒé•·æœŸè¨˜æ†¶ã‚’æ¤œç´¢ã§ãã‚‹ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_memory_retrieval_tool(memory_id: str, actor_id: str, region: str):\n",
    "    \"\"\"Create a tool for the agent to search its own long-term memory\"\"\"\n",
    "    \n",
    "    def search_long_term_memory(query: str) -> str:\n",
    "        \"\"\"Search long-term memory for relevant research information.\n",
    "        \n",
    "        Use this tool when you need to recall:\n",
    "        - Previous research papers and findings\n",
    "        - Research topics and their status\n",
    "        - Metrics and insights from past work\n",
    "        - Research milestones and progress\n",
    "        \n",
    "        Args:\n",
    "            query: Search query describing what information you need\n",
    "        \n",
    "        Returns:\n",
    "            Relevant information from long-term memory\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from bedrock_agentcore.memory.session import MemorySessionManager\n",
    "            \n",
    "            # Create session manager\n",
    "            session_manager = MemorySessionManager(\n",
    "                memory_id=memory_id,\n",
    "                region_name=region\n",
    "            )\n",
    "            \n",
    "            # Search long-term memories in the semantic strategy namespace\n",
    "            results = session_manager.search_long_term_memories(\n",
    "                query=query,\n",
    "                namespace_prefix=\"/strategies\",  # Search in semantic strategy namespace\n",
    "                top_k=5,\n",
    "                max_results=10\n",
    "            )\n",
    "            \n",
    "            if not results:\n",
    "                return \"No relevant information found in long-term memory. This might be new information or the memory extraction may still be processing.\"\n",
    "            \n",
    "            # Format results for the agent\n",
    "            output = \"ğŸ“š Retrieved from long-term memory:\\\\n\\\\n\"\n",
    "            for i, result in enumerate(results, 1):\n",
    "                # MemoryRecord object - access content attribute\n",
    "                content = getattr(result, 'content', str(result))\n",
    "                # Truncate very long content\n",
    "                if len(content) > 300:\n",
    "                    content = content[:300] + \"...\"\n",
    "                output += f\"{i}. {content}\\\\n\\\\n\"\n",
    "            \n",
    "            return output\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"âš ï¸ Error searching memory: {str(e)}. Proceeding without historical context.\"\n",
    "    \n",
    "    return FunctionTool.from_defaults(fn=search_long_term_memory)\n",
    "\n",
    "# Create the memory retrieval tool\n",
    "memory_search_tool = create_memory_retrieval_tool(memory_id, \"academic-researcher\", region)\n",
    "\n",
    "# Add memory search to the tools list\n",
    "research_tools_with_memory = research_tools + [memory_search_tool]\n",
    "\n",
    "print(f\"âœ… Memory retrieval tool created! Total tools: {len(research_tools_with_memory)}\")\n",
    "print(\"   Using namespace: /strategies (for semantic strategy compatibility)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 3c: Memory è¨­å®šã®ç¢ºèª\n",
    "\n",
    "Semantic Strategy ãŒé©åˆ‡ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check memory configuration\nmemory_info = memory_manager.get_memory(memory_id)\nprint(f\"ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼: {memory_info.get('strategies')}\")\nprint(f\"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {memory_info.get('status')}\")\nprint(f\"åå‰: {memory_info.get('name')}\")\n\n# Show strategy details\nstrategies = memory_info.get('strategies', [])\nfor strategy in strategies:\n    print(f\"\\nã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼è©³ç´°:\")\n    print(f\"  åå‰: {strategy.get('name')}\")\n    print(f\"  ã‚¿ã‚¤ãƒ—: {strategy.get('type')}\")\n    print(f\"  ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {strategy.get('status')}\")\n    print(f\"  ID: {strategy.get('strategyId')}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 4: ãƒãƒ«ãƒã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè£…\n",
    "\n",
    "ç•°ãªã‚‹ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for LONG-TERM memory (cross-session)\n",
    "MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "RESEARCHER_ID = \"academic-researcher\"  # Same researcher across all sessions\n",
    "\n",
    "def create_research_session(session_name: str):\n",
    "    \"\"\"Create a new research session with long-term memory persistence\"\"\"\n",
    "    context = AgentCoreMemoryContext(\n",
    "        actor_id=RESEARCHER_ID,         # Same researcher\n",
    "        memory_id=memory_id,         # Same memory store (enables long-term memory)\n",
    "        session_id=f\"research-{session_name}\", # Different session per period\n",
    "        namespace=\"/academic-research\"\n",
    "    )\n",
    "    \n",
    "    memory = AgentCoreMemory(context=context)\n",
    "    llm = BedrockConverse(model=MODEL_ID)\n",
    "    agent = FunctionAgent(\n",
    "        tools=research_tools_with_memory,  # Use tools with memory search capability\n",
    "        llm=llm, \n",
    "        verbose=True,  # Enable verbose to see when memory is searched\n",
    "        system_prompt=\"\"\"You are a senior research assistant with access to long-term memory.\n",
    "        \n",
    "CRITICAL: When asked about previous research, papers, findings, or historical information, \n",
    "you MUST use the search_long_term_memory tool FIRST before responding.\n",
    "\n",
    "For example:\n",
    "- \"What research am I working on?\" â†’ Use search_long_term_memory(\"research topics\")\n",
    "- \"What papers have I reviewed?\" â†’ Use search_long_term_memory(\"papers authors\")\n",
    "- \"What findings do I have?\" â†’ Use search_long_term_memory(\"research findings\")\n",
    "\n",
    "Always provide conclusive, complete responses without asking follow-up questions.\\n\n",
    "Execute all requested actions immediately and completely. Provide detailed, professional responses.\"\"\"\n",
    "    )\n",
    "    \n",
    "    return agent, memory\n",
    "\n",
    "print(\"âœ… Multi-session Academic Research Assistant setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 5: ç¬¬1é€±ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ - åŸºç›¤æ§‹ç¯‰\n",
    "\n",
    "æœ€åˆã®ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã€åŸºç¤çŸ¥è­˜ã‚’ç¢ºç«‹ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WEEK 1 RESEARCH SESSION ===\n",
    "print(\"ğŸ—“ï¸ === WEEK 1: FOUNDATION RESEARCH ===\")\n",
    "\n",
    "agent_week1, memory_week1 = create_research_session(\"week1\")\n",
    "\n",
    "# Establish research foundation\n",
    "response = await agent_week1.run(\n",
    "    \"I'm Dr. Sarah Smith from MIT starting comprehensive research on 'Machine Learning in Healthcare Applications'. \"\n",
    "    \"Track this with status 'Literature Review'. My goal is to publish a systematic review by year-end.\",\n",
    "    memory=memory_week1\n",
    ")\n",
    "\n",
    "print(\"ğŸ¯ Week 1 Foundation:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add foundational papers with detailed metrics\n",
    "response = await agent_week1.run(\n",
    "    \"Save paper: 'Deep Learning for Medical Image Analysis' by Zhang et al (2023). \"\n",
    "    \"Key findings: CNNs achieve 95.2% accuracy in chest X-ray diagnosis, 12% improvement over radiologists, \"\n",
    "    \"trained on 100,000 images, 0.03 false positive rate.\",\n",
    "    memory=memory_week1\n",
    ")\n",
    "print(\"ğŸ“„ Week 1 Paper 1:\", response)\n",
    "\n",
    "response = await agent_week1.run(\n",
    "    \"Save paper: 'Transformers in Medical NLP' by Johnson et al (2023). \"\n",
    "    \"Key findings: BERT achieves 89.1% F1-score in clinical note classification, \"\n",
    "    \"struggles with rare diseases (<70% accuracy), excels at symptom extraction (94% precision).\",\n",
    "    memory=memory_week1\n",
    ")\n",
    "print(\"ğŸ“„ Week 1 Paper 2:\", response)\n",
    "# Explicitly track the accuracy metrics\n",
    "await agent_week1.run(\n",
    "    \"Track research metrics: metric_type 'CNN Accuracy', value '95.2%', source 'Zhang et al 2023', period 'Week 1'.\",\n",
    "    memory=memory_week1\n",
    ")\n",
    "await agent_week1.run(\n",
    "    \"Track research metrics: metric_type 'Radiologist Improvement', value '12%', source 'Zhang et al 2023', period 'Week 1'.\",\n",
    "    memory=memory_week1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow time for semantic memory processing\n",
    "import asyncio\n",
    "print(\"\\nâ³ Waiting for semantic memory extraction and indexing...\")\n",
    "print(\"   (AgentCore processes conversational events in the background)\")\n",
    "await asyncio.sleep(90)  # Increased wait time for memory extraction\n",
    "print(\"âœ… Memory processing complete - memories should now be searchable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 6: ç¬¬2é€±ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ - ã‚¯ãƒ­ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¡ãƒ¢ãƒªãƒ†ã‚¹ãƒˆ\n",
    "\n",
    "é•·æœŸè¨˜æ†¶ã®å–å¾—ã‚’ãƒ†ã‚¹ãƒˆã—ã€æ–°ã—ã„ç ”ç©¶ã‚’è¿½åŠ ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WEEK 2 RESEARCH SESSION ===\n",
    "print(\"\\nğŸ—“ï¸ === WEEK 2: EXPANSION (NEW SESSION) ===\")\n",
    "\n",
    "agent_week2, memory_week2 = create_research_session(\"week2\")\n",
    "\n",
    "# Test cross-session memory recall\n",
    "response = await agent_week2.run(\n",
    "    \"What research am I working on? What specific accuracy metrics have I found so far? Who are the key authors?\",\n",
    "    memory=memory_week2\n",
    ")\n",
    "\n",
    "print(\"ğŸ§  Week 2 Memory Test:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: ML in Healthcare, Zhang 95.2%, Johnson 89.1% F1-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new research building on previous knowledge\n",
    "response = await agent_week2.run(\n",
    "    \"Save paper: 'Federated Learning in Healthcare' by Brown et al (2023). \"\n",
    "    \"Key findings: Privacy-preserving ML enables multi-hospital collaboration, 87.3% accuracy across 15 hospitals, \"\n",
    "    \"23% improvement in rare disease detection when hospitals collaborate.\",\n",
    "    memory=memory_week2\n",
    ")\n",
    "print(\"ğŸ“„ Week 2 New Paper:\", response)\n",
    "\n",
    "# Test comparative analysis across sessions\n",
    "response = await agent_week2.run(\n",
    "    \"Compare the accuracy results: Zhang's CNNs vs Johnson's BERT vs Brown's federated learning. \"\n",
    "    \"Which performs best and in what contexts?\",\n",
    "    memory=memory_week2\n",
    ")\n",
    "print(\"ğŸ“Š Week 2 Comparative Analysis:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Zhang 95.2% (imaging), Johnson 89.1% (NLP), Brown 87.3% (federated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 7: ç¬¬3é€±ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ - åˆ†æãƒ•ã‚§ãƒ¼ã‚º\n",
    "\n",
    "ç ”ç©¶ã‚’é€²ã‚ã€è©³ç´°ãªã‚¯ãƒ­ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ³èµ·ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WEEK 3 RESEARCH SESSION ===\n",
    "print(\"\\nğŸ—“ï¸ === WEEK 3: ANALYSIS PHASE ===\")\n",
    "\n",
    "agent_week3, memory_week3 = create_research_session(\"week3\")\n",
    "\n",
    "# Update research status\n",
    "response = await agent_week3.run(\n",
    "    \"Update my 'Machine Learning in Healthcare Applications' research status to 'Analysis Phase' \"\n",
    "    \"with notes: 'Reviewed 3 key papers, identified performance patterns: imaging>NLP>federated learning'.\",\n",
    "    memory=memory_week3\n",
    ")\n",
    "print(\"ğŸ“Š Week 3 Status Update:\", response)\n",
    "\n",
    "# Test detailed cross-session recall\n",
    "response = await agent_week3.run(\n",
    "    \"What evidence do I have for the claim that imaging tasks show highest ML performance in healthcare? \"\n",
    "    \"Include specific numbers and authors.\",\n",
    "    memory=memory_week3\n",
    ")\n",
    "print(\"ğŸ” Week 3 Evidence Query:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Zhang et al CNNs 95.2% vs Johnson BERT 89.1% vs Brown federated 87.3%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 8: 1ãƒ¶æœˆç›®ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ - çµ±åˆãƒ•ã‚§ãƒ¼ã‚º\n",
    "\n",
    "åŒ…æ‹¬çš„ãªçŸ¥è­˜çµ±åˆã¨ç ”ç©¶ã®çµ±åˆã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MONTH 1 RESEARCH SESSION ===\n",
    "print(\"\\nğŸ—“ï¸ === MONTH 1: SYNTHESIS PHASE ===\")\n",
    "\n",
    "agent_month1, memory_month1 = create_research_session(\"month1\")\n",
    "\n",
    "# Update research status to synthesis phase\n",
    "response = await agent_month1.run(\n",
    "    \"Update my 'Machine Learning in Healthcare Applications' research status to 'Synthesis Phase' \"\n",
    "    \"with notes: 'Completed 3-week literature review, ready to synthesize findings into coherent framework'.\",\n",
    "    memory=memory_month1\n",
    ")\n",
    "print(\"ğŸ“Š Month 1 Status Update:\", response)\n",
    "\n",
    "# Test comprehensive synthesis across all weeks\n",
    "response = await agent_month1.run(\n",
    "    \"Based on all my research so far, what is the overall performance ranking of ML approaches in healthcare? \"\n",
    "    \"Include all specific metrics and create a comprehensive comparison.\",\n",
    "    memory=memory_month1\n",
    ")\n",
    "print(\"ğŸ” Month 1 Comprehensive Synthesis:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Ranking with Zhang 95.2% > Johnson 89.1% > Brown 87.3%, domain analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 9: 2ãƒ¶æœˆç›®ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ - åŸ·ç­†ãƒ•ã‚§ãƒ¼ã‚º\n",
    "\n",
    "åŒ…æ‹¬çš„ãªæƒ³èµ·ã¨ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MONTH 2 RESEARCH SESSION ===\n",
    "print(\"\\nğŸ—“ï¸ === MONTH 2: WRITING PHASE ===\")\n",
    "\n",
    "agent_month2, memory_month2 = create_research_session(\"month2\")\n",
    "\n",
    "# Test comprehensive recall for writing\n",
    "response = await agent_month2.run(\n",
    "    \"I'm writing my systematic review paper. What are ALL the papers I've reviewed with their exact accuracy metrics? \"\n",
    "    \"I need this for my results table.\",\n",
    "    memory=memory_month2\n",
    ")\n",
    "print(\"ğŸ“ Month 2 Comprehensive Recall:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Zhang 95.2%, Johnson 89.1%, Brown 87.3% with full details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test semantic search across research history\n",
    "response = await agent_month2.run(\n",
    "    \"What do I know about rare disease detection in my research? Which papers and what specific results?\",\n",
    "    memory=memory_month2\n",
    ")\n",
    "print(\"ğŸ” Month 2 Semantic Search:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Johnson <70% for rare diseases, Brown 23% improvement with collaboration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 10: 3ãƒ¶æœˆç›®ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ - åŠ©æˆé‡‘ç”³è«‹ã‚·ãƒŠãƒªã‚ª\n",
    "\n",
    "è“„ç©ã•ã‚ŒãŸçŸ¥è­˜ã®å®Ÿè·µçš„å¿œç”¨ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MONTH 3 RESEARCH SESSION ===\n",
    "print(\"\\nğŸ—“ï¸ === MONTH 3: GRANT PROPOSAL ===\")\n",
    "\n",
    "agent_month3, memory_month3 = create_research_session(\"month3\")\n",
    "\n",
    "# Grant proposal evidence gathering\n",
    "response = await agent_month3.run(\n",
    "    \"I'm writing an NIH grant proposal for $2M funding. What evidence can I cite about ML effectiveness in healthcare? \"\n",
    "    \"I need specific numbers, authors, years, and sample sizes.\",\n",
    "    memory=memory_month3\n",
    ")\n",
    "print(\"ğŸ’° Month 3 Grant Evidence:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Comprehensive citation with Zhang 95.2% (100K images), Johnson 89.1%, Brown 87.3% (15 hospitals)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test research evolution tracking with detailed milestones\n",
    "response = await agent_month3.run(\n",
    "    \"Provide a detailed timeline of my research evolution from Week 1 to now. What specific milestones, \"\n",
    "    \"metrics, and insights did I achieve each period? How did my research questions evolve?\",\n",
    "    memory=memory_month3\n",
    ")\n",
    "print(\"ğŸ“ˆ Month 3 Research Evolution:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Week-by-week progression with specific milestones, metrics (95.2%, 89.1%, 87.3%), and insights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 11: æœ€çµ‚ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªè©•ä¾¡\n",
    "\n",
    "é•·æœŸè¨˜æ†¶æ©Ÿèƒ½ã®åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comprehensive portfolio query\n",
    "response = await agent_month3.run(\n",
    "    \"Provide my complete research portfolio: all topics I'm working on, all papers with metrics, \"\n",
    "    \"all findings, current status of each project, and how they interconnect.\",\n",
    "    memory=memory_month3\n",
    ")\n",
    "print(\"ğŸ“‹ Complete Research Portfolio:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Full research history with all metrics, connections between ML healthcare topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è‡ªå‹•ãƒ†ã‚¹ãƒˆæ¤œè¨¼\n",
    "ã“ã‚Œã‚‰ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ã€ãƒ¡ãƒ¢ãƒªçµ±åˆãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ã‚‹ã“ã¨ã‚’æ¤œè¨¼ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define validation functions inline\n",
    "class TestValidator:\n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "    \n",
    "    def validate_memory_recall(self, response):\n",
    "        \"\"\"Check if agent can recall information from earlier in the session\"\"\"\n",
    "        # Check for substantive response (not just \"I don't know\")\n",
    "        has_content = len(response) > 50\n",
    "        # Check for memory indicators\n",
    "        has_memory_indicators = any(word in response.lower() for word in \n",
    "            ['earlier', 'mentioned', 'discussed', 'previously', 'you', 'we', 'our'])\n",
    "        return \"âœ… PASS\" if (has_content and has_memory_indicators) else \"âŒ FAIL\"\n",
    "    \n",
    "    def validate_session_memory(self, response):\n",
    "        \"\"\"Check if agent maintains context within session\"\"\"\n",
    "        has_memory_content = len(response) > 100 and any(word in response.lower() for word in \n",
    "            ['previous', 'earlier', 'mentioned', 'discussed', 'before', 'already'])\n",
    "        return \"âœ… PASS\" if has_memory_content else \"âŒ FAIL\"\n",
    "    \n",
    "    def validate_cross_reference(self, response):\n",
    "        \"\"\"Check if agent can connect current query to previous context\"\"\"\n",
    "        # Look for connecting language\n",
    "        connecting_words = ['relate', 'connection', 'previous', 'earlier', 'discussed', \n",
    "                           'mentioned', 'context', 'based on', 'as we', 'as i']\n",
    "        has_connection = any(word in response.lower() for word in connecting_words)\n",
    "        has_substance = len(response) > 80\n",
    "        return \"âœ… PASS\" if (has_connection and has_substance) else \"âŒ FAIL\"\n",
    "    \n",
    "    def run_validation_summary(self, test_results):\n",
    "        print(\"ğŸ§ª COMPREHENSIVE TEST VALIDATION SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        total_tests = len(test_results)\n",
    "        passed_tests = sum(1 for result in test_results.values() if \"PASS\" in result)\n",
    "        pass_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0\n",
    "        \n",
    "        for test_name, result in test_results.items():\n",
    "            print(f\"{test_name}: {result}\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(f\"ğŸ“Š Overall Pass Rate: {passed_tests}/{total_tests} ({pass_rate:.1f}%)\")\n",
    "        \n",
    "        if pass_rate >= 80:\n",
    "            print(\"âœ… EXCELLENT: Memory integration working correctly!\")\n",
    "        elif pass_rate >= 60:\n",
    "            print(\"âš ï¸  GOOD: Most memory features working, some issues to investigate\")\n",
    "        else:\n",
    "            print(\"âŒ NEEDS ATTENTION: Memory integration has significant issues\")\n",
    "        \n",
    "        return pass_rate\n",
    "\n",
    "validator = TestValidator()\n",
    "print(\"âœ… Validation functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run all validation tests\ntest_results = {}\n\n# Test 1: Memory recall - can the agent recall what was discussed?\nresponse1 = await agent_month3.run(\"What have we discussed so far in this session?\", memory=memory_month3)\ntest_results['Memory Recall'] = validator.validate_memory_recall(str(response1))\nprint(f\"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ 1 ã®é•·ã•: {len(str(response1))} æ–‡å­—\")\n\n# Test 2: Session memory - does the agent maintain context?\nresponse2 = await agent_month3.run(\"What did we talk about earlier?\", memory=memory_month3)\ntest_results['Session Memory'] = validator.validate_session_memory(str(response2))\nprint(f\"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ 2 ã®é•·ã•: {len(str(response2))} æ–‡å­—\")\n\n# Test 3: Cross-reference capability - can it connect to previous context?\nresponse3 = await agent_month3.run(\"How does this relate to what we discussed before?\", memory=memory_month3)\ntest_results['Cross Reference'] = validator.validate_cross_reference(str(response3))\nprint(f\"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ 3 ã®é•·ã•: {len(str(response3))} æ–‡å­—\")\n\n# Display results\nvalidator.run_validation_summary(test_results)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã¾ã¨ã‚\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ä»¥ä¸‹ã‚’å®Ÿæ¼”ã—ã¾ã—ãŸï¼š\n",
    "\n",
    "- **é•·æœŸè¨˜æ†¶ã®çµ±åˆ**: AgentCore Memory ã¨ LlamaIndex ã‚’ä½¿ç”¨ã—ãŸã‚¯ãƒ­ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³æ°¸ç¶šæ€§\n",
    "\n",
    "- **ç´¯ç©çš„çŸ¥è­˜æ§‹ç¯‰**: æ•°é€±é–“ã‹ã‚‰æ•°ãƒ¶æœˆã«ã‚ãŸã‚‹ç ”ç©¶çŸ¥è­˜ã®è“„ç©\n",
    "\n",
    "- **ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯å–å¾—**: ã‚»ãƒƒã‚·ãƒ§ãƒ³é–“ã§æ¦‚å¿µã«åŸºã¥ã„ãŸé–¢é€£æƒ…å ±ã®æ¤œç´¢\n",
    "\n",
    "- **ç ”ç©¶é€²åŒ–ã®è¿½è·¡**: æ–‡çŒ®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰åˆ†æã€åŸ·ç­†ã¸ã®è‡ªç„¶ãªé€²è¡Œ\n",
    "\n",
    "- **ã‚¯ãƒ­ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±åˆ**: è¤‡æ•°ã®ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³é–“ã§ç™ºè¦‹ã¨ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’æ¥ç¶š\n",
    "\n",
    "- **å®Ÿè·µçš„å¿œç”¨**: åŠ©æˆé‡‘ç”³è«‹ã‚µãƒãƒ¼ãƒˆã¨åŒ…æ‹¬çš„ãªãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç®¡ç†\n",
    "\n",
    "å­¦è¡“ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¯ã€é•·æœŸè¨˜æ†¶ãŒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’æ™‚é–“ã¨ã¨ã‚‚ã«è³¢ããªã‚‹æ°¸ç¶šçš„ãªç ”ç©¶ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã«å¤‰æ›ã—ã€å®Œå…¨ãªç ”ç©¶å±¥æ­´ã‚’ç¶­æŒã—ã€é•·æœŸç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã§æ´—ç·´ã•ã‚ŒãŸçŸ¥è­˜å–å¾—ã‚’å¯èƒ½ã«ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ä½¿ç”¨ã—ãŸãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«ãƒ¡ãƒ¢ãƒªã‚’å‰Šé™¤ã—ã¾ã—ã‚‡ã†ï¼š\n",
    "\n",
    "**æ³¨æ„**: ãƒ¡ãƒ¢ãƒªã‚’å®Œå…¨ã«å‰Šé™¤ã™ã‚‹å ´åˆã®ã¿å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚memory_id å¤‰æ•°ã«ã¯ã€ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å…ˆã»ã©ä½œæˆã—ãŸãƒ¡ãƒ¢ãƒªã® ID ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up AgentCore Memory resource\n",
    "try:\n",
    "    from bedrock_agentcore.memory import MemoryClient\n",
    "    \n",
    "    client = MemoryClient(region_name=region)\n",
    "    client.delete_memory(memory_id)\n",
    "    print(f\"âœ… Successfully deleted memory: {memory_id}\")\n",
    "    \n",
    "except NameError as e:\n",
    "    print(f\"âš ï¸  Variable not defined: {e}\")\n",
    "    print(\"Run the notebook from the beginning or set variables manually:\")\n",
    "    print(\"# memory_id = 'your-memory-id-here'\")\n",
    "    print(\"# region = 'us-east-1'\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error deleting memory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}