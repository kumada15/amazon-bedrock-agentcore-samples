{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 前提条件: サンプルエージェントの作成\n",
    "\n",
    "## 概要\n",
    "\n",
    "まず、評価対象となるエージェントを作成しましょう。このチュートリアルでは、異なるフレームワークを使用して評価用の2つのサンプルエージェントを作成します:\n",
    "- [Strands Agents SDK](https://strandsagents.com/)\n",
    "- [LangGraph](https://www.langchain.com/langgraph)\n",
    "\n",
    "両エージェントは Amazon Bedrock の Anthropic Claude Haiku 4.5 を LLM モデルとして使用しますが、お好みのモデルを使用することも可能です。両エージェントは同じ機能を持っています:\n",
    "- **Math Tool**: 基本的な数学演算を実行するツール\n",
    "- **Weather Tool**: 天気情報のダミー実装\n",
    "\n",
    "\n",
    "アーキテクチャは以下のようになります:\n",
    "\n",
    "![Architecture](../images/agent_architecture.png)\n",
    "\n",
    "## 前提条件\n",
    "- Python 3.10以上\n",
    "- AWS 認証情報"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## セットアップ\n",
    "\n",
    "必要なパッケージをインポートし、AWS セッションを設定します:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "print(f\"Using region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Strands エージェントのデプロイ\n",
    "Strands エージェントを AgentCore Runtime にデプロイしましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore_runtime = Runtime()\n",
    "\n",
    "agent_name = \"ac_eval_strands2\"\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"eval_agent_strands.py\",\n",
    "    auto_create_execution_role=True,\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements_strands.txt\",\n",
    "    region=region,\n",
    "    agent_name=agent_name,\n",
    "    idle_timeout=120\n",
    ")\n",
    "launch_result_strands = agentcore_runtime.launch()\n",
    "print(f\"Strands agent deployment started: {launch_result_strands}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### AgentCore Runtime でのデプロイ状態を確認\n",
    "デプロイが ACTIVE 状態になるまで待機します.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_deployment(runtime, name):\n",
    "    end_statuses = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "    while True:\n",
    "        status_response = runtime.status()\n",
    "        status = status_response.endpoint['status']\n",
    "        print(f\"{name} status: {status}\")\n",
    "        if status in end_statuses:\n",
    "            print(f\"{name} deployment completed with status: {status}\")\n",
    "            return status\n",
    "        time.sleep(10)\n",
    "\n",
    "strands_status = wait_for_deployment(agentcore_runtime, \"Strands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Runtime 上の Strands エージェントを呼び出す\n",
    "ペイロードを使用して AgentCore Runtime エンドポイントを呼び出し、Strands エージェントをテストしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id_strands = str(uuid.uuid4())\n",
    "print(f\"Session ID: {session_id_strands}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke(\n",
    "    payload={\"prompt\": \"How much is 2+2?\"},\n",
    "    session_id=session_id_strands\n",
    ")\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke(\n",
    "    payload={\"prompt\": \"How is the weather now?\"},\n",
    "    session_id=session_id_strands\n",
    ")\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke(\n",
    "    payload={\"prompt\": \"Can you tell me the capital of the US?\"},\n",
    "    session_id=session_id_strands\n",
    ")\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## LangGraph エージェントを AgentCore Runtime にデプロイ\n",
    "\n",
    "LangGraph エージェントも AgentCore Runtime にデプロイしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "langgraph_agentcore_runtime = Runtime()\n",
    "agent_name = \"ac_eval_langgraph2\"\n",
    "response = langgraph_agentcore_runtime.configure(\n",
    "    entrypoint=\"eval_agent_langgraph.py\",\n",
    "    auto_create_execution_role=True,\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements_langgraph.txt\",\n",
    "    region=region,\n",
    "    agent_name=agent_name,\n",
    "    idle_timeout=120\n",
    ")\n",
    "launch_result_langgraph = langgraph_agentcore_runtime.launch()\n",
    "print(f\"LangGraph agent deployment started: {launch_result_langgraph}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### LangGraph エージェントの状態を確認\n",
    "LangGraph エージェントを AgentCore Runtime にデプロイしたので、デプロイ状態を確認しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "langgraph_status = wait_for_deployment(langgraph_agentcore_runtime, \"LangGraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Runtime 上の LangGraph エージェントを呼び出す\n",
    "ペイロードを使用して AgentCore Runtime 上の LangGraph エージェントエンドポイントをテストします:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id_langgraph = str(uuid.uuid4())\n",
    "print(f\"Session ID: {session_id_langgraph}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = langgraph_agentcore_runtime.invoke(\n",
    "    payload={\"prompt\": \"What is 2+2?\"},\n",
    "    session_id=session_id_langgraph\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke(\n",
    "    payload={\"prompt\": \"What is the weather now?\"},\n",
    "    session_id=session_id_langgraph\n",
    ")\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke(\n",
    "    payload={\"prompt\": \"Can you tell me the capital of the US?\"},\n",
    "    session_id=session_id_langgraph\n",
    ")\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Strands: {launch_result_strands}, Session: {session_id_strands}\")\n",
    "print(f\"LangGraph: {launch_result_langgraph}, Session: {session_id_langgraph}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store launch_result_strands\n",
    "%store session_id_strands\n",
    "%store launch_result_langgraph\n",
    "%store session_id_langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## 次のステップ\n",
    "\n",
    "必要な前提条件がすべて揃いました。それでは個別の評価チュートリアルを進めましょう:\n",
    "評価チュートリアルを続けます:\n",
    "- [01-creating-custom-evaluators](../01-creating-custom-evaluators/): カスタム評価メトリクスの作成\n",
    "- [02-running-evaluations](../02-running-evaluations/): オンデマンドおよびオンライン評価の実行\n",
    "- [03-advanced](../03-advanced/): 高度なテクニックとダッシュボード"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
