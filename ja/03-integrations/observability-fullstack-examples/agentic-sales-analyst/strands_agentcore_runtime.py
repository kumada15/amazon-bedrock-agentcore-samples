#!/usr/bin/env python3

import json
import logging
import os
import re
import sys
import traceback

import psycopg2
from psycopg2 import sql
import requests
from strands import Agent, tool
from strands.hooks import AgentInitializedEvent, HookProvider, HookRegistry, MessageAddedEvent
from bedrock_agentcore.memory import MemoryClient
from flask import Flask, request, jsonify
from flask_cors import CORS
from opentelemetry import baggage
from opentelemetry.context import attach

# ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’æ¤œå‡º
DEPLOYMENT_MODE = os.getenv('DEPLOYMENT_MODE', 'ecs')  # 'ecs', 'eks'

app = Flask(__name__)
CORS(app, resources={r"/api/*": {"origins": "http://localhost:3000"}}, supports_credentials=True)

# ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ Flask ãŒã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã‚’è¡¨ç¤ºã™ã‚‹ã‚ˆã†ã«å¼·åˆ¶
sys.stdout = sys.__stdout__
sys.stderr = sys.__stderr__
app.logger.setLevel(logging.DEBUG)

# Strands ã‚ªãƒ–ã‚¶ãƒ¼ãƒãƒ“ãƒªãƒ†ã‚£ã‚’è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    from strands.observability import configure_tracer
    configure_tracer()
    print("[OTEL] âœ… Strands observability configured")
except ImportError:
    print("[OTEL] â„¹ï¸ Using ADOT auto-instrumentation for observability")
except Exception as e:
    print(f"[OTEL] âš ï¸ Observability configuration failed: {e}")
    print("[OTEL] â„¹ï¸ Falling back to ADOT auto-instrumentation")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚­ãƒ¼ãƒã‚­ãƒ£ãƒƒã‚·ãƒ¥
schema_cache = None

print(f"[{DEPLOYMENT_MODE.upper()}] âœ… Flask app created successfully")

def get_system_prompt():
    """ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã‚’å«ã‚€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã™"""
    schema = discover_schema()
    return f"""
ã‚ãªãŸã¯å½“ç¤¾ã®å–¶æ¥­ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚ç¤¾å†…ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚

å¯¾è±¡ç¯„å›²: å½“ç¤¾ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹è³ªå•ã®ã¿ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚é–¢ä¿‚ã®ãªã„è³ªå•ã«ã¤ã„ã¦ã¯ä¸å¯§ã«ãŠæ–­ã‚Šã—ã¦ãã ã•ã„ã€‚

ãƒ„ãƒ¼ãƒ«:
1. execute_sql_query - å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ã‚¨ãƒª
2. search_web - å£²ä¸Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒ:
{schema}

é‡è¦ãªãƒ«ãƒ¼ãƒ«:
1. ç¤¾å†…å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹è³ªå•ã«ã¯å¿…ãš execute_sql_query ã‚’ä½¿ç”¨ã™ã‚‹ - ã‚¯ã‚¨ãƒªå†…å®¹ã‚’èª¬æ˜ã™ã‚‹ã ã‘ã§ãªãå®Ÿéš›ã«ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹
2. search_web ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµæœã‚’è£œå®Œã™ã‚‹å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦ãªå ´åˆã®ã¿ä½¿ç”¨
3. ä¸Šè¨˜ã‚¹ã‚­ãƒ¼ãƒã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã«å¯¾ã—ã¦ SELECT ã‚¯ã‚¨ãƒªã®ã¿ã‚’ä½¿ç”¨
4. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã¯é™ã‚‰ã‚ŒãŸä¾‹ã®ã¿ - å¿…ãšã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¦ã™ã¹ã¦ã®å®Ÿéš›ã®å€¤ã¨ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèª
5. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¯2025å¹´ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹ - ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„ã¨è¨€ã†å‰ã«å¿…ãšã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
6. content ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã« SQL ã‚¯ã‚¨ãƒªã‚’å«ã‚ãªã„ - ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ã‚µã‚¤ãƒˆã¨åˆ†æã®ã¿ã‚’æä¾›
7. å¿…é ˆ: ãƒ„ãƒ¼ãƒ«ã‚’èª¬æ˜ã™ã‚‹ã®ã§ã¯ãªãã€å¿…ãšãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™ã“ã¨

ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼:
1. è³ªå•ã‚’åˆ†æã—ã¦å¿…è¦ãªæƒ…å ±ã‚’æ±ºå®š
2. ç¤¾å†…å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ãªå ´åˆã¯å¿…ãš execute_sql_query ã‚’å‘¼ã³å‡ºã™
3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµæœã‚’è£œå®Œã™ã‚‹å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦ãªå ´åˆã®ã¿ search_web ã‚’å‘¼ã³å‡ºã™
4. ä½¿ç”¨ã—ãŸãƒ„ãƒ¼ãƒ«ã‹ã‚‰ã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’å«ã‚€ JSON ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™

ğŸš¨ é‡è¦: å¿…ãš JSON å½¢å¼ã§è¿”ã™ ğŸš¨
ã™ã¹ã¦ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯æœ‰åŠ¹ãª JSON ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„ - ä¾‹å¤–ãªã—
ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãŠæ–­ã‚Šã™ã‚‹å ´åˆã§ã‚‚ JSON å½¢å¼ã§è¿”ã™ã“ã¨

JSON å‡ºåŠ›å½¢å¼ï¼ˆå¿…é ˆï¼‰:
{{
  "content": "ã“ã“ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ",
  "sources": []
}}

ä¾‹:
- å£²ä¸Šã«é–¢ã™ã‚‹è³ªå•: {{"content": "ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€åˆ†æ", "sources": [{{"type": "database", "name": "Sales Database"}}]}}
- å¯¾è±¡å¤–: {{"content": "å½“ç¤¾ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã®åˆ†æã®ã¿å¯¾å¿œå¯èƒ½ã§ã™", "sources": []}}
- ã‚¨ãƒ©ãƒ¼: {{"content": "ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã§ãã¾ã›ã‚“", "sources": []}}

JSON ã®é‡è¦ãªè¦ä»¶:
- {{ ã§å§‹ã¾ã‚Š }} ã§çµ‚ã‚ã‚‹æœ‰åŠ¹ãª JSON ã®ã¿ã‚’å‡ºåŠ›
- JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å‰å¾Œã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥ã‚Œãªã„
- å¿…ãš "content" ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ–‡å­—åˆ—ã¨ã—ã¦å«ã‚ã‚‹
- å¿…ãš "sources" é…åˆ—ã‚’å«ã‚ã‚‹ï¼ˆãƒ„ãƒ¼ãƒ«æœªä½¿ç”¨æ™‚ã¯ç©ºé…åˆ—ï¼‰
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹: {{"type": "database", "name": "Sales Database"}}
- Web ã‚½ãƒ¼ã‚¹: {{"type": "web", "title": "æ¤œç´¢çµæœã®æ­£ç¢ºãªã‚¿ã‚¤ãƒˆãƒ«", "url": "æ¤œç´¢çµæœã®æ­£ç¢ºãªURL"}}
- ã‚½ãƒ¼ã‚¹ã‚’æé€ ã—ãªã„ - ãƒ„ãƒ¼ãƒ«çµæœã‹ã‚‰ã®æ­£ç¢ºãªãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨

ğŸ”¥ çµ¶å¯¾è¦ä»¶ ğŸ”¥
ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯æ­£ç¢ºã«: {{ "content": "...", "sources": [...] }} ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„
ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯è¨±å¯ã•ã‚Œãªã„ - ã‚·ã‚¹ãƒ†ãƒ ãŒå¤±æ•—ã™ã‚‹
content ã« SQL æ–‡ã‚’å«ã‚ãªã„ - ãƒ“ã‚¸ãƒã‚¹åˆ†æã®ã¿
"""

def get_database_connection():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—ã—ã¾ã™"""
    database_url = os.getenv('DATABASE_URL')
    if database_url:
        return psycopg2.connect(database_url)
    else:
        return psycopg2.connect(
            host=os.getenv('DB_HOST', 'postgres'),
            port=os.getenv('DB_PORT', 5432),
            database=os.getenv('DB_NAME', 'sales_db'),
            user=os.getenv('DB_USER', 'postgres'),
            password=os.getenv('DB_PASSWORD', 'postgres')
        )

# amazonq-ignore-next-line
def discover_schema():
    """ã™ã¹ã¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã‚’å‹•çš„ã«æ¤œå‡ºã—ã¾ã™"""
    # amazonq-ignore-next-line
    global schema_cache
    if schema_cache:
        print('ğŸ“‹ Using cached schema')
        return schema_cache
    
    print('ğŸ” Discovering database schema dynamically...')
    # amazonq-ignore-next-line
    conn = get_database_connection()
    cursor = conn.cursor()
    
    # ã™ã¹ã¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å–å¾—
    cursor.execute("""
        SELECT 
            table_name,
            table_type,
            obj_description(c.oid) as table_comment
        FROM information_schema.tables t
        LEFT JOIN pg_class c ON c.relname = t.table_name
        WHERE table_schema = 'public'
            AND table_type = 'BASE TABLE'
        ORDER BY table_name
    """)
    tables = cursor.fetchall()
    print(f'ğŸ“Š Found {len(tables)} tables: {[t[0] for t in tables]}')
    
    schema_description = 'Database Schema:\n\n'
    
    for table_name, table_type, table_comment in tables:
        print(f'ğŸ” Analyzing table: {table_name}')
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
        cursor.execute("""
            SELECT 
                c.column_name,
                c.data_type,
                c.is_nullable,
                c.column_default,
                col_description(pgc.oid, c.ordinal_position) as column_comment
            FROM information_schema.columns c
            LEFT JOIN pg_class pgc ON pgc.relname = c.table_name
            WHERE c.table_name = %s
                AND c.table_schema = 'public'
            ORDER BY c.ordinal_position
        """, (table_name,))
        columns = cursor.fetchall()
        
        # amazonq-ignore-next-line
        schema_description += f'Table: {table_name}\n'
        if table_comment:
            schema_description += f'Description: {table_comment}\n'
        
        schema_description += 'Columns:\n'
        for col_name, data_type, is_nullable, col_default, col_comment in columns:
            schema_description += f'- {col_name} ({data_type}'
            if is_nullable == 'NO':
                schema_description += ', NOT NULL'
            if col_default:
                schema_description += f', DEFAULT {col_default}'
            if col_comment:
                schema_description += f', -- {col_comment}'
            schema_description += ')\n'
        
        # å¤šæ§˜æ€§ã‚’ç¤ºã™åŒ…æ‹¬çš„ãªã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        try:
            # æœ€åˆã®2è¡Œã ã‘ã§ãªãã€å¤šæ§˜ãªã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            cursor.execute(
                sql.SQL('SELECT * FROM {} ORDER BY RANDOM() LIMIT 5').format(
                    sql.Identifier(table_name)
                )
            )
            sample_data = cursor.fetchall()
            if sample_data:
                col_names = [desc[0] for desc in cursor.description]
                sample_dict = [dict(zip(col_names, row)) for row in sample_data]
                schema_description += f'SAMPLE DATA (5 RANDOM ROWS - NOT COMPLETE DATASET):\n{json.dumps(sample_dict, default=str, indent=2)}\n'
                
                # ä¸»è¦ãªã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ—ã®ãƒ‡ãƒ¼ã‚¿å¤šæ§˜æ€§ã‚µãƒãƒªã‚’è¿½åŠ 
                categorical_cols = ['productline', 'country', 'territory', 'dealsize', 'status']
                for col in categorical_cols:
                    if col in [c.lower() for c in col_names]:
                        cursor.execute(
                            sql.SQL('SELECT {}, COUNT(*) as count FROM {} GROUP BY {} ORDER BY count DESC LIMIT 10').format(
                                sql.Identifier(col),
                                sql.Identifier(table_name),
                                sql.Identifier(col)
                            )
                        )
                        variety_data = cursor.fetchall()
                        if variety_data:
                            schema_description += f'\nDATA VARIETY - {col.upper()} (top values):\n'
                            for value, count in variety_data:
                                schema_description += f'- {value}: {count} records\n'
                
                schema_description += f'\nCRITICAL: Sample shows only 5 random rows. The actual table contains thousands more records with extensive variety in all categorical columns. ALWAYS query the database to discover all actual values and patterns.\n'
                print(f'âœ… Added comprehensive sample data for {table_name}')
        except Exception as e:
            print(f'âš ï¸ Could not get sample data for {table_name}: {e}')
        
        schema_description += '\n'
    
    cursor.close()
    conn.close()
    
    print('âœ… Schema discovery complete')
    schema_cache = schema_description
    return schema_cache

@tool
def execute_sql_query(sql_query: str) -> str:
    """PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§SQLã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ã¯SQLã‚¯ã‚¨ãƒªã®ç”ŸæˆãŒå¿…è¦ãªå ´åˆã€ã™ã¹ã¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã€ã‚«ãƒ©ãƒ ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã‚’è‡ªå‹•çš„ã«æä¾›ã—ã¾ã™ã€‚"""
    print("\n" + "="*50)
    print("ğŸ”¥ EXECUTE_SQL_QUERY TOOL CALLED!")
    print(f"ğŸ”¥ SQL Query: {sql_query}")
    print("="*50 + "\n")
    try:
        # ãƒ‡ãƒãƒƒã‚°: æ¥ç¶šè©³ç´°ã‚’å‡ºåŠ›
        database_url = os.getenv('DATABASE_URL')
        print(f"[DB Debug] DATABASE_URL exists: {bool(database_url)}")
        if database_url:
            print("[DB Debug] Using DATABASE_URL connection")
            # amazonq-ignore-next-line
            conn = get_database_connection()
        else:
            print("[DB Debug] Using individual env vars")
            conn = get_database_connection()
        
        print("[DB Debug] Connection successful")
        print(f"[DB Debug] Executing SQL: {sql_query}")
        
        # amazonq-ignore-next-line
        cursor = conn.cursor()
        cursor.execute(sql_query)
        results = cursor.fetchall()
        columns = [desc[0] for desc in cursor.description]
        
        data = [dict(zip(columns, row)) for row in results]
        print(f"[DB Debug] Query returned {len(data)} rows")
        
        cursor.close()
        conn.close()
        
        response = {
            "data": data,
            "sql_query": sql_query,
            "source": "PostgreSQL Database",
            "record_count": len(data)
        }
        
        return json.dumps(response, default=str)
        
    except Exception as e:
        error_msg = f"Database query failed: {str(e)}"
        print(f"[DB Debug] {error_msg}")
        return json.dumps({"error": error_msg})

@tool
def search_web(query: str) -> str:
    """Brave Search APIã‚’ä½¿ç”¨ã—ã¦ã‚¯ã‚¨ãƒªã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’ã‚¦ã‚§ãƒ–æ¤œç´¢ã—ã¾ã™"""
    print("\n" + "="*50)
    print("ğŸ”¥ SEARCH_WEB TOOL CALLED WITH QUERY ONLY!")
    print(f"ğŸ”¥ Query: {query}")
    print("="*50 + "\n")
    
    all_results = []
    
    try:
        print("[Web Search Debug] Using Brave Search API...")
        
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ Brave Search API ã‚­ãƒ¼ã‚’å–å¾—
        brave_api_key = os.getenv('BRAVE_SEARCH_API_KEY')
        if not brave_api_key:
            print("[Web Search Debug] âŒ BRAVE_SEARCH_API_KEY not found in environment")
            return json.dumps({"error": "Brave Search API key not configured"})
        
        print(f"[Web Search Debug] Starting Brave search for: '{query}'")
        
        # Brave Search API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        url = "https://api.search.brave.com/res/v1/web/search"
        headers = {
            "Accept": "application/json",
            "Accept-Encoding": "gzip",
            "X-Subscription-Token": brave_api_key
        }
        params = {
            "q": query,
            # amazonq-ignore-next-line
            "count": 3
        }
        
        response = requests.get(url, headers=headers, params=params, timeout=10)
        # amazonq-ignore-next-line
        print(f"[Web Search Debug] Brave API response: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            web_results = data.get('web', {}).get('results', [])
            print(f"[Web Search Debug] Brave search returned {len(web_results)} results")
            
            for i, result in enumerate(web_results):
                search_result = {
                    'title': result.get('title', '')[:100],
                    'url': result.get('url', ''),
                    'snippet': result.get('description', '')[:200],
                    'source': 'Web Search'
                }
                all_results.append(search_result)
                print(f"[Web Search Debug] Result {i+1}: {search_result['title']} - {search_result['url']}")
                
        elif response.status_code == 429:
            print("[Web Search Debug] âŒ Rate limit exceeded for Brave Search API")
            return json.dumps({"error": "Brave Search API rate limit exceeded"})
        else:
            print(f"[Web Search Debug] âŒ Brave API error: {response.status_code} - {response.text}")
            return json.dumps({"error": f"Brave Search API error: {response.status_code}"})
                
    # amazonq-ignore-next-line
    except Exception as search_error:
        print(f"[Web Search Debug] âŒ Brave search error: {search_error}")
        print(f"[Web Search Debug] Traceback: {traceback.format_exc()}")
        return json.dumps({"error": f"Brave search failed: {search_error}"})
    
    response = {
        "query": query,
        "results": all_results,
        "source": "Web Search",
        "total_results": len(all_results)
    }
    
    print(f"[Web Search Debug] Returning {len(all_results)} results:")
    for i, result in enumerate(all_results):
        print(f"[Web Search Debug] Result {i+1}: {result['title']} - {result['url']}")
    
    print(f"[Web Search Debug] FULL RESPONSE TO AGENT:")
    print(json.dumps(response, indent=2)[:500] + "...")
    
    result = json.dumps(response)
    print(f"[Web Search Debug] Final JSON length: {len(result)}")
    return result



@app.route('/health', methods=['GET'])
def health():
    return jsonify({"status": "healthy", "runtime": f"Strands {DEPLOYMENT_MODE.upper()}"})

@app.route('/api/chat/message', methods=['POST'])
def chat_message():
    """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›ã®ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        data = request.get_json()
        user_message = data.get('message')  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã¯ 'message' ã‚’é€ä¿¡
        session_id = data.get('sessionId')
        user_id = data.get('userId')  # 'anonymous' ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ã—ãªã„

        # ãƒ¡ã‚¤ãƒ³ã® invoke é–¢æ•°ã‚’å‘¼ã³å‡ºã—
        return invoke_agent(user_message, session_id, user_id)
    except Exception as e:
        print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Chat API ERROR: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/invoke', methods=['POST'])
def invoke():
    """ç›´æ¥å‘¼ã³å‡ºã—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        data = request.get_json()
        user_message = data.get('prompt')
        session_id = data.get('sessionId')
        user_id = data.get('userId')  # 'anonymous' ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ã—ãªã„

        return invoke_agent(user_message, session_id, user_id)
    except Exception as e:
        print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Invoke ERROR: {str(e)}")
        return jsonify({"error": str(e)}), 500

# amazonq-ignore-next-line
def invoke_agent(user_message, session_id, user_id):
    """ã‚³ã‚¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—ãƒ­ã‚¸ãƒƒã‚¯"""
    try:
        
        if not user_message:
            return jsonify({"error": "No message provided"}), 400
        
        print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Processing: {user_message}")
        print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Session: {session_id}, User: {user_id}")
        
        # ã‚ªãƒ–ã‚¶ãƒ¼ãƒãƒ“ãƒªãƒ†ã‚£ã®ãŸã‚ã« OTEL baggage ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ ID ã‚’è¨­å®š
        if session_id:
            ctx = baggage.set_baggage("session.id", session_id)
            attach(ctx)
            print(f"[OTEL] Set session.id in baggage: {session_id}")
        
        # ã‚³ãƒ³ãƒ†ãƒŠãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆç”¨ã« AgentCore Memory ã‚’åˆæœŸåŒ–
        # amazonq-ignore-next-line
        global memory_id
        if not memory_id:
            try:
                print(f"ğŸ”„ Initializing AgentCore memory: {MEMORY_NAME}")
                memories = memory_client.list_memories()
                memory_id = next((m['id'] for m in memories if m['id'].startswith(MEMORY_NAME)), None)
                
                if memory_id:
                    print(f"âœ… Found existing AgentCore memory: {memory_id}")
                else:
                    print(f"ğŸ”„ Creating new AgentCore memory: {MEMORY_NAME}")
                    memory = memory_client.create_memory_and_wait(
                        name=MEMORY_NAME,
                        strategies=[],
                        description="Short-term memory for sales assistant",
                        event_expiry_days=30
                    )
                    memory_id = memory['id']
                    print(f"âœ… Created AgentCore memory: {memory_id}")
            # amazonq-ignore-next-line
            except Exception as e:
                print(f"âŒ Memory initialization failed: {e}")
                memory_id = None
        
        # AgentCore Memory ãƒ•ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
        hooks = []
        if memory_id:
            hooks.append(MemoryHookProvider(memory_client, memory_id))
        
        # amazonq-ignore-next-line
        agent = Agent(
            model="anthropic.claude-3-sonnet-20240229-v1:0",
            system_prompt=get_system_prompt(),
            tools=[execute_sql_query, search_web],
            hooks=hooks,
            state={"actor_id": user_id, "session_id": session_id}
        )
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã—
        response = agent(user_message)
        result = response.message['content'][0]['text']
        
        # JSON ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¦æ¤œè¨¼
        json_match = re.search(r'\{[\s\S]*\}', result)
        if json_match:
            json_str = json_match.group(0)
            print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Original JSON length: {len(json_str)}")
            
            # åˆ¶å¾¡æ–‡å­—ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¦ç©ºç™½ã‚’æ­£è¦åŒ–
            cleaned_json = re.sub(r'[\x00-\x1f\x7f-\x9f]', ' ', json_str)
            cleaned_json = re.sub(r'\s+', ' ', cleaned_json)
            
            # content ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å†…ã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã¦ã„ãªã„ã‚¯ã‚©ãƒ¼ãƒˆã‚’ä¿®æ­£
            try:
                # ãƒ‘ãƒ¼ã‚¹ã—ã¦å†ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã—ã¦ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚’ä¿®æ­£
                parsed = json.loads(cleaned_json)
                cleaned_json = json.dumps(parsed, ensure_ascii=False)
            except json.JSONDecodeError:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦æ‰‹å‹•ã§ã‚¯ã‚©ãƒ¼ãƒˆã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                cleaned_json = re.sub(r'"([^"]*?)"([^"]*?)"([^"]*?)"', r'"\1\\"\2\\"\3"', cleaned_json)
            
            try:
                json.loads(cleaned_json)
                result = cleaned_json
                print(f"[{DEPLOYMENT_MODE.upper()} Runtime] JSON validation successful")
            except json.JSONDecodeError as e:
                print(f"[{DEPLOYMENT_MODE.upper()} Runtime] JSON validation failed: {e}")
                print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Keeping original response")
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Final result for parsing: {result[:200]}...")
        try:
            parsed_result = json.loads(result)
            print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Successfully parsed JSON")
            # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®æœŸå¾…ã«åˆã‚ã›ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            streaming_response = {
                "type": "complete",
                "response": {
                    "answer": parsed_result.get("content", ""),
                    "sources": parsed_result.get("sources", []),
                    "reasoning": [],
                    "citations": []
                },
                "timestamp": "2025-10-03T04:26:37.529Z"
            }
            print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Returning streaming response")
            return jsonify(streaming_response)
        except json.JSONDecodeError as e:
            print(f"[{DEPLOYMENT_MODE.upper()} Runtime] JSON parse error: {e}")
            print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Error at position {e.pos}: {repr(result[max(0, e.pos-50):e.pos+50]) if hasattr(e, 'pos') else 'N/A'}")
            # æœ‰åŠ¹ãª JSON ã§ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è¿”ã™
            error_response = {
                "type": "error",
                "error": f"Failed to parse agent response: {str(e)}"
            }
            return jsonify(error_response)
        
    except Exception as e:
        print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Agent ERROR: {str(e)}")
        return jsonify({"error": str(e)}), 500

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã—ã¦æ–°ã—ã„ã‚¹ã‚­ãƒ¼ãƒæ¤œå‡ºã‚’ä¿è¨¼
agent = None

# AgentCore Memory è¨­å®š

# ãƒ¡ãƒ¢ãƒªè¨­å®š
REGION = os.getenv('AWS_REGION', 'ap-southeast-2')
MEMORY_NAME = "SalesAnalystMemory"

# Memory ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
# amazonq-ignore-next-line
memory_client = MemoryClient(region_name=REGION)
memory_id = None

# é©åˆ‡ãªãƒ­ã‚®ãƒ³ã‚°ã‚’ä¿è¨¼ã™ã‚‹ãŸã‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã«ãƒ¡ãƒ¢ãƒªã‚’åˆæœŸåŒ–
memory_id = None

class MemoryHookProvider(HookProvider):
    def __init__(self, memory_client: MemoryClient, memory_id: str):
        self.memory_client = memory_client
        self.memory_id = memory_id
    
    def on_agent_initialized(self, event: AgentInitializedEvent):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–‹å§‹æ™‚ã«æœ€è¿‘ã®ä¼šè©±å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã™"""
        try:
            actor_id = event.agent.state.get("actor_id")
            session_id = event.agent.state.get("session_id")
            
            # åŒ¿åãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å ´åˆã€session_id ã‚’ actor_id ã¨ã—ã¦ä½¿ç”¨
            if not actor_id:
                actor_id = session_id

            if not actor_id or not session_id or not self.memory_id:
                return
            
            recent_turns = self.memory_client.get_last_k_turns(
                memory_id=self.memory_id,
                actor_id=actor_id,
                session_id=session_id,
                # amazonq-ignore-next-line
                k=6  # Last 6 turns for context
            )
            
            if recent_turns:
                context_messages = []
                for turn in recent_turns:
                    for message in turn:
                        role = message['role']
                        # amazonq-ignore-next-line
                        content = message['content']['text']
                        context_messages.append(f"{role}: {content}")
                
                context = "\n".join(context_messages)
                event.agent.system_prompt += f"\n\nPREVIOUS CONVERSATION CONTEXT:\n{context}\n\nCURRENT QUESTION:\n"
                # amazonq-ignore-next-line
                print(f"âœ… Loaded {len(recent_turns)} conversation turns from AgentCore Memory")
                
        except Exception as e:
            if "Memory not found" in str(e):
                print(f"âŒ Memory not found during load, recreating: {e}")
                self._recreate_memory()
            else:
                print(f"âŒ Memory load error: {e}")
    
    def on_message_added(self, event: MessageAddedEvent):
        """AgentCore Memoryã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜ã—ã¾ã™"""
        try:
            messages = event.agent.messages
            actor_id = event.agent.state.get("actor_id")
            session_id = event.agent.state.get("session_id")
            
            # åŒ¿åãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å ´åˆã€session_id ã‚’ actor_id ã¨ã—ã¦ä½¿ç”¨
            if not actor_id:
                actor_id = session_id

            # amazonq-ignore-next-line
            if messages and messages[-1]["content"][0].get("text") and self.memory_id:
                self.memory_client.create_event(
                    memory_id=self.memory_id,
                    actor_id=actor_id,
                    session_id=session_id,
                    messages=[(messages[-1]["content"][0]["text"], messages[-1]["role"])]
                )
        except Exception as e:
            # amazonq-ignore-next-line
            if "Memory not found" in str(e):
                print(f"âŒ Memory not found, recreating: {e}")
                self._recreate_memory()
            else:
                print(f"âŒ Memory save error: {e}")
    
    def _recreate_memory(self):
        """å‰Šé™¤ã•ã‚ŒãŸå ´åˆã«ãƒ¡ãƒ¢ãƒªã‚’å†ä½œæˆã—ã¾ã™"""
        try:
            # amazonq-ignore-next-line
            global memory_id
            print(f"ğŸ”„ Recreating AgentCore memory: {MEMORY_NAME}")
            memory = self.memory_client.create_memory_and_wait(
                name=MEMORY_NAME,
                strategies=[],
                description="Short-term memory for sales assistant",
                event_expiry_days=30
            )
            # amazonq-ignore-next-line
            memory_id = memory['id']
            self.memory_id = memory_id
            print(f"âœ… Recreated AgentCore memory: {memory_id}")
        # amazonq-ignore-next-line
        except Exception as e:
            print(f"âŒ Failed to recreate memory: {e}")
    
    def register_hooks(self, registry: HookRegistry):
        registry.add_callback(MessageAddedEvent, self.on_message_added)
        registry.add_callback(AgentInitializedEvent, self.on_agent_initialized)

# AgentCore ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆapp ãŒ BedrockAgentCoreApp ã®å ´åˆã®ã¿å‹•ä½œï¼‰
# amazonq-ignore-next-line
def agentcore_invoke(payload):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    try:
        print(f"[AgentCore Runtime] Received payload: {payload}")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ ID ã‚’æŠ½å‡º
        user_message = payload.get('prompt')
        session_id = payload.get('sessionId')
        
        if not user_message:
            messages = payload.get('messages', [])
            user_message = messages[0]['content'] if messages else payload.get('inputText', '')
        
        if not user_message:
            print("[AgentCore Runtime] No prompt found in payload")
            return "No prompt found in input, please provide a message"
        
        # AgentCore Memory ç”¨ã«ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ ID ã‚’æŠ½å‡º
        user_id = payload.get('userId') or payload.get('user_id')
        actor_id = user_id  # åŒ¿åãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯ None ã‚’ä½¿ç”¨
        
        print(f"[AgentCore Runtime] Processing message: {user_message}")
        print(f"[AgentCore Runtime] Session ID: {session_id}")
        print(f"[AgentCore Runtime] User ID: {user_id}")
        print(f"[AgentCore Runtime] Actor ID: {actor_id}")
        contextual_message = user_message

        # ã¾ã åˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ¡ãƒ¢ãƒªã‚’åˆæœŸåŒ–
        # amazonq-ignore-next-line
        global memory_id
        # amazonq-ignore-next-line
        if not memory_id:
            try:
                print(f"ğŸ”„ Initializing AgentCore memory: {MEMORY_NAME}")
                memories = memory_client.list_memories()
                memory_id = next((m['id'] for m in memories if m['id'].startswith(MEMORY_NAME)), None)
                
                if memory_id:
                    print(f"âœ… Found existing AgentCore memory: {memory_id}")
                else:
                    print(f"ğŸ”„ Creating new AgentCore memory: {MEMORY_NAME}")
                    memory = memory_client.create_memory_and_wait(
                        name=MEMORY_NAME,
                        strategies=[],
                        description="Short-term memory for sales assistant",
                        event_expiry_days=30
                    )
                    memory_id = memory['id']
                    print(f"âœ… Created AgentCore memory: {memory_id}")
            except Exception as e:
                print(f"âŒ Memory initialization failed: {e}")
                memory_id = None
        else:
            print(f"âœ… Using existing memory: {memory_id}")
        
        # ã‚¹ã‚­ãƒ¼ãƒã¯æœ€åˆã®æ¤œå‡ºå¾Œã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹

        # AgentCore Memory ãƒ•ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
        print('ğŸ”¥ INITIALIZING AGENT WITH DYNAMIC SCHEMA DISCOVERY')
        print('='*60)
        
        hooks = []
        if memory_id:
            hooks.append(MemoryHookProvider(memory_client, memory_id))
            print(f"âœ… Added memory hook with ID: {memory_id}")
        
        # amazonq-ignore-next-line
        agent = Agent(
            model="anthropic.claude-3-sonnet-20240229-v1:0",
            system_prompt=get_system_prompt(),
            tools=[execute_sql_query, search_web],
            hooks=hooks,
            state={"actor_id": actor_id, "session_id": session_id}
        )
        print('âœ… Agent initialized with dynamic schema and AgentCore Memory')
        print('='*60)
        
        # OTEL ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã—
        print("ğŸš€ INVOKING AGENT NOW...")
        try:
            from opentelemetry import trace
            tracer = trace.get_tracer(__name__)
            with tracer.start_as_current_span("agent_invoke") as span:
                span.set_attribute("session_id", session_id or "unknown")
                span.set_attribute("user_id", user_id or "unknown")
                span.add_event("Agent invocation started")
                response = agent(contextual_message)
                span.add_event("Agent invocation completed")
                print("[OTEL] âœ… Agent invocation traced")
        # amazonq-ignore-next-line
        except Exception as otel_error:
            print(f"[OTEL] âš ï¸ Tracing failed: {otel_error}")
            response = agent(contextual_message)
        
        print("âœ… AGENT INVOCATION COMPLETE")
        print(f"[AgentCore Runtime] Agent response type: {type(response)}")
        
        # JSON ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        result = response.message['content'][0]['text']
        print(f"[AgentCore Runtime] Raw result length: {len(result)}")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æŠ½å‡ºã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

        # æœ€çµ‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å«ã¾ã‚Œã‚‹ã¹ãã§ãªã„ãƒ‡ãƒãƒƒã‚°ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰Šé™¤
        result = re.sub(r'<search_quality_reflection>.*?</search_quality_reflection>', '', result, flags=re.DOTALL)
        result = re.sub(r'<search_quality_score>.*?</search_quality_score>', '', result, flags=re.DOTALL)
        
        # amazonq-ignore-next-line
        json_match = re.search(r'\{[\s\S]*\}', result)
        if json_match:
            json_str = json_match.group(0)
            print(f"[AgentCore Runtime] Original JSON length: {len(json_str)}")
            print(f"[AgentCore Runtime] First 200 chars: {repr(json_str[:200])}")
            
            # åˆ¶å¾¡æ–‡å­—ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¦ç©ºç™½ã‚’æ­£è¦åŒ–
            cleaned_json = re.sub(r'[\x00-\x1f\x7f-\x9f]', ' ', json_str)
            cleaned_json = re.sub(r'\s+', ' ', cleaned_json)
            
            # content ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å†…ã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã¦ã„ãªã„ã‚¯ã‚©ãƒ¼ãƒˆã‚’ä¿®æ­£
            try:
                # ãƒ‘ãƒ¼ã‚¹ã—ã¦å†ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã—ã¦ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚’ä¿®æ­£
                parsed = json.loads(cleaned_json)
                cleaned_json = json.dumps(parsed, ensure_ascii=False)
            except json.JSONDecodeError:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦æ‰‹å‹•ã§ã‚¯ã‚©ãƒ¼ãƒˆã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                cleaned_json = re.sub(r'"([^"]*?)"([^"]*?)"([^"]*?)"', r'"\1\\"\2\\"\3"', cleaned_json)
            print(f"[AgentCore Runtime] Cleaned JSON length: {len(cleaned_json)}")
            print(f"[AgentCore Runtime] Cleaned first 200 chars: {repr(cleaned_json[:200])}")
            
            try:
                json.loads(cleaned_json)
                result = cleaned_json
                print(f"[AgentCore Runtime] JSON validation successful")
            except json.JSONDecodeError as e:
                print(f"[AgentCore Runtime] JSON validation failed: {e}")
                print(f"[AgentCore Runtime] Error at position {e.pos}: {repr(cleaned_json[max(0, e.pos-50):e.pos+50])}")
                print("[AgentCore Runtime] Keeping original response")
        else:
            print("[AgentCore Runtime] No JSON object found in response")
        
        # AgentCore Memory ã¯ãƒ•ãƒƒã‚¯ã‚’ä»‹ã—ã¦ä¼šè©±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’è‡ªå‹•çš„ã«å‡¦ç†
        print(f"[AgentCore Runtime] Conversation stored in AgentCore Memory for user: {actor_id}, session: {session_id}")
        
        # AgentCore ã®å ´åˆã¯ç”Ÿã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ï¼ˆJSON ãƒ‘ãƒ¼ã‚¹ã¯ AgentCore ãŒå‡¦ç†ï¼‰
        return result
        
    except Exception as e:
        print(f"[AgentCore Runtime] ERROR: {str(e)}")
        print(f"[AgentCore Runtime] Traceback: {traceback.format_exc()}")
        return f"Error processing request: {str(e)}"

if __name__ == "__main__":
    # ã‚³ãƒ³ãƒ†ãƒŠãƒ­ã‚®ãƒ³ã‚°ç”¨ã«ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ãªã—å‡ºåŠ›ã‚’å¼·åˆ¶
    sys.stdout.flush()
    sys.stderr.flush()
    
    print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Starting Strands Agent with ADOT observability")
    print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Available tools: execute_sql_query, search_web")
    print(f"[{DEPLOYMENT_MODE.upper()} Runtime] Deployment mode: {DEPLOYMENT_MODE}")
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºæ™‚ã®ã¿ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–
    debug_mode = DEPLOYMENT_MODE == 'local'
    # æ³¨æ„: host='0.0.0.0' ã¯ã‚³ãƒ³ãƒ†ãƒŠãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã§å¤–éƒ¨æ¥ç¶šã‚’å—ã‘å…¥ã‚Œã‚‹ãŸã‚ã«å¿…è¦
    # ã‚³ãƒ³ãƒ†ãƒŠãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãŒã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¢ƒç•Œã‚’æä¾›
    app.run(host='0.0.0.0', port=8080, debug=debug_mode, use_reloader=False)  # nosec B104