#!/usr/bin/env python3

import asyncio
import logging
import os
from datetime import datetime, timezone
from typing import Any, Dict

from fastapi import FastAPI, HTTPException
from langchain_core.messages import HumanMessage
from langchain_core.tools import BaseTool
from pydantic import BaseModel

from .agent_state import AgentState
from .constants import SREConstants

# Import logging config
from .logging_config import configure_logging
from .multi_agent_langgraph import create_multi_agent_system

# Configure logging based on DEBUG environment variable
# This ensures debug mode works even when not run via __main__
if not logging.getLogger().handlers:
    # Check if DEBUG is already set in environment
    debug_from_env = os.getenv("DEBUG", "false").lower() in ("true", "1", "yes")
    configure_logging(debug_from_env)


# Custom filter to exclude /ping endpoint logs
class PingEndpointFilter(logging.Filter):
    def filter(self, record):
        # Filter out GET /ping requests from access logs
        if hasattr(record, "getMessage"):
            message = record.getMessage()
            if '"GET /ping HTTP/' in message:
                return False
        return True


# Configure uvicorn access logger to filter out ping requests
uvicorn_logger = logging.getLogger("uvicorn.access")
uvicorn_logger.addFilter(PingEndpointFilter())

logger = logging.getLogger(__name__)

# Simple FastAPI app
app = FastAPI(title="SRE Agent Runtime", version="1.0.0")


# Simple request/response models
class InvocationRequest(BaseModel):
    input: Dict[str, Any]


class InvocationResponse(BaseModel):
    output: Dict[str, Any]


# Global variables for agent state
agent_graph = None
tools: list[BaseTool] = []


async def initialize_agent():
    """CLI ã¨åŒã˜æ–¹æ³•ã§ SRE ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚"""
    global agent_graph, tools

    if agent_graph is not None:
        return  # Already initialized

    try:
        logger.info("SRE ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")

        # Get provider from environment variable with bedrock as default
        provider = os.getenv("LLM_PROVIDER", "bedrock").lower()

        # Validate provider
        if provider not in ["anthropic", "bedrock"]:
            logger.warning(f"ç„¡åŠ¹ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ '{provider}'ã€'bedrock' ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã—ã¾ã™")
            provider = "bedrock"

        logger.info(f"ç’°å¢ƒå¤‰æ•° LLM_PROVIDER: {os.getenv('LLM_PROVIDER', 'NOT_SET')}")
        logger.info(f"LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ä½¿ç”¨: {provider}")
        logger.info(f"ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ {provider} ã§ create_multi_agent_system ã‚’å‘¼ã³å‡ºã—ä¸­")

        # Create multi-agent system using the same function as CLI
        agent_graph, tools = await create_multi_agent_system(provider)

        logger.info(
            f"SRE ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ãŒ {len(tools)} å€‹ã®ãƒ„ãƒ¼ãƒ«ã§æ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ"
        )

    except Exception as e:
        from .llm_utils import LLMAccessError, LLMAuthenticationError, LLMProviderError

        if isinstance(e, (LLMAuthenticationError, LLMAccessError, LLMProviderError)):
            logger.error(f"LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"\nâŒ {type(e).__name__}:")
            print(str(e))
            print("\nğŸ’¡ LLM_PROVIDER ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„:")
            other_provider = "anthropic" if provider == "bedrock" else "bedrock"
            print(f"   export LLM_PROVIDER={other_provider}")
        else:
            logger.error(f"SRE ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise


@app.on_event("startup")
async def startup_event():
    """èµ·å‹•æ™‚ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚"""
    await initialize_agent()


@app.post("/invocations", response_model=InvocationResponse)
async def invoke_agent(request: InvocationRequest):
    """ãƒ¡ã‚¤ãƒ³ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‚"""
    global agent_graph, tools

    logger.info("å‘¼ã³å‡ºã—ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ä¿¡ã—ã¾ã—ãŸ")

    try:
        # Ensure agent is initialized
        await initialize_agent()

        # Extract user prompt
        user_prompt = request.input.get("prompt", "")
        if not user_prompt:
            raise HTTPException(
                status_code=400,
                detail="No prompt found in input. Please provide a 'prompt' key in the input.",
            )

        logger.info(f"ã‚¯ã‚¨ãƒªã‚’å‡¦ç†ä¸­: {user_prompt}")

        # Extract session_id and user_id from request
        session_id = request.input.get("session_id", "")
        user_id = request.input.get("user_id", "default_user")

        logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ ID: {session_id}, ãƒ¦ãƒ¼ã‚¶ãƒ¼ ID: {user_id}")

        # Create initial state exactly like the CLI does
        initial_state: AgentState = {
            "messages": [HumanMessage(content=user_prompt)],
            "next": "supervisor",
            "agent_results": {},
            "current_query": user_prompt,
            "metadata": {},
            "requires_collaboration": False,
            "agents_invoked": [],
            "final_response": None,
            "auto_approve_plan": True,  # Always auto-approve plans in runtime mode
            "session_id": session_id,  # Required for memory retrieval
            "user_id": user_id,  # Required for user personalization
        }

        # Process through the agent graph exactly like the CLI
        final_response = ""

        logger.info("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œã‚’é–‹å§‹")

        async for event in agent_graph.astream(initial_state):
            for node_name, node_output in event.items():
                logger.info(f"ãƒãƒ¼ãƒ‰ã‚’å‡¦ç†ä¸­: {node_name}")

                # Log key events from each node
                if node_name == "supervisor":
                    next_agent = node_output.get("next", "")
                    metadata = node_output.get("metadata", {})
                    logger.info(f"Supervisor ãŒ {next_agent} ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ä¸­")
                    if metadata.get("routing_reasoning"):
                        logger.info(
                            f"ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®ç†ç”±: {metadata['routing_reasoning']}"
                        )

                elif node_name in [
                    "kubernetes_agent",
                    "logs_agent",
                    "metrics_agent",
                    "runbooks_agent",
                ]:
                    agent_results = node_output.get("agent_results", {})
                    logger.info(f"{node_name} ãŒçµæœã‚’è¿”ã—ã¦å®Œäº†ã—ã¾ã—ãŸ")

                # Capture final response from aggregate node
                elif node_name == "aggregate":
                    final_response = node_output.get("final_response", "")
                    logger.info("é›†ç´„ãƒãƒ¼ãƒ‰ãŒå®Œäº†ã—ã€æœ€çµ‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¾ã—ãŸ")

        if not final_response:
            logger.warning("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚°ãƒ©ãƒ•ã‹ã‚‰æœ€çµ‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            final_response = (
                "ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‡¦ç†ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            )
        else:
            logger.info(f"æœ€çµ‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®é•·ã•: {len(final_response)} æ–‡å­—")

        # Simple response format
        response_data = {
            "message": final_response,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "model": SREConstants.app.agent_model_name,
        }

        logger.info("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ­£å¸¸ã«å‡¦ç†ã—ã¾ã—ãŸ")
        logger.info("å‘¼ã³å‡ºã—ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã—ã¦ã„ã¾ã™")
        return InvocationResponse(output=response_data)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ãŒå¤±æ•—ã—ã¾ã—ãŸ: {e}")
        logger.exception("å®Œå…¨ãªä¾‹å¤–ã®è©³ç´°:")
        raise HTTPException(
            status_code=500, detail=f"Agent processing failed: {str(e)}"
        )


@app.get("/ping")
async def ping():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‚"""
    return {"status": "healthy"}


async def invoke_sre_agent_async(prompt: str, provider: str = "anthropic") -> str:
    """
    SRE ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™ãŸã‚ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ†ã‚£ãƒƒã‚¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€‚

    Args:
        prompt: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ/ã‚¯ã‚¨ãƒª
        provider: LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆ"anthropic" ã¾ãŸã¯ "bedrock"ï¼‰

    Returns:
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆæ–‡å­—åˆ—ï¼‰
    """
    try:
        # Create the multi-agent system
        graph, tools = await create_multi_agent_system(provider=provider)

        # Create initial state
        initial_state: AgentState = {
            "messages": [HumanMessage(content=prompt)],
            "next": "supervisor",
            "agent_results": {},
            "current_query": prompt,
            "metadata": {},
            "requires_collaboration": False,
            "agents_invoked": [],
            "final_response": None,
        }

        # Execute and get final response
        final_response = ""
        async for event in graph.astream(initial_state):
            for node_name, node_output in event.items():
                if node_name == "aggregate":
                    final_response = node_output.get("final_response", "")

        return final_response or "ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‡¦ç†ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

    except Exception as e:
        logger.error(f"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—ãŒå¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise


def invoke_sre_agent(prompt: str, provider: str = "anthropic") -> str:
    """
    invoke_sre_agent_async ã®åŒæœŸãƒ©ãƒƒãƒ‘ãƒ¼ã€‚

    Args:
        prompt: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ/ã‚¯ã‚¨ãƒª
        provider: LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆ"anthropic" ã¾ãŸã¯ "bedrock"ï¼‰

    Returns:
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆæ–‡å­—åˆ—ï¼‰
    """
    return asyncio.run(invoke_sre_agent_async(prompt, provider))


if __name__ == "__main__":
    import argparse

    import uvicorn

    parser = argparse.ArgumentParser(description="SRE Agent Runtime")
    parser.add_argument(
        "--provider",
        choices=["anthropic", "bedrock"],
        default=os.getenv("LLM_PROVIDER", "bedrock"),
        help="LLM provider to use (default: bedrock)",
    )
    parser.add_argument("--host", default="0.0.0.0", help="Host to bind to")
    parser.add_argument("--port", type=int, default=8080, help="Port to bind to")
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable debug logging and trace output",
    )

    args = parser.parse_args()

    # Configure logging based on debug flag
    from .logging_config import configure_logging

    debug_enabled = configure_logging(args.debug)

    # Set environment variables
    os.environ["LLM_PROVIDER"] = args.provider
    os.environ["DEBUG"] = "true" if debug_enabled else "false"

    logger.info(f"ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ {args.provider} ã§ SRE ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ Runtime ã‚’èµ·å‹•ä¸­")
    if debug_enabled:
        logger.info("ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸ")
    uvicorn.run(app, host=args.host, port=args.port)
