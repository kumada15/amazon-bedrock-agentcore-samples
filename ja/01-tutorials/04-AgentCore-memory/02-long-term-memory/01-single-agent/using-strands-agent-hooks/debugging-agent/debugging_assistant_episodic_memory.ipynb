{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒãƒƒã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ\n",
    "\n",
    "## æ¦‚è¦\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä»˜ãã® **AgentCore ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒª**ã‚’ä½¿ç”¨ã—ã¦ã€ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãª**ãƒ‡ãƒãƒƒã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ**ã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯éå»ã®ãƒ‡ãƒãƒƒã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å­¦ç¿’ã—ã€å±¥æ­´ã®çµŒé¨“ã«åŸºã¥ã„ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚\n",
    "\n",
    "### ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã¨ã¯?\n",
    "\n",
    "**ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒª**ã¯ã€æ§‹é€ åŒ–ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒã¤å®Œå…¨ãªã‚„ã‚Šå–ã‚Šã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼ˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¾ã™ã€‚å­¤ç«‹ã—ãŸäº‹å®Ÿã‚’ä¿å­˜ã™ã‚‹ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã¨ã¯ç•°ãªã‚Šã€ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã¯ä»¥ä¸‹ã‚’ä¿æŒã—ã¾ã™:\n",
    "- **å®Œå…¨ãªä¼šè©±ãƒ•ãƒ­ãƒ¼**: å•é¡Œã®èª¬æ˜ã‹ã‚‰è§£æ±ºã¾ã§ã®å®Œå…¨ãªãƒ‡ãƒãƒƒã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³\n",
    "- **æ™‚é–“çš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ**: å–ã‚‰ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°\n",
    "- **çµæœ**: ãƒ‡ãƒãƒƒã‚°ã®è©¦è¡ŒãŒæˆåŠŸã—ãŸã‹å¤±æ•—ã—ãŸã‹\n",
    "- **æ§‹é€ åŒ–ã•ã‚ŒãŸã‚¿ãƒ¼ãƒ³**: æ€è€ƒã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€è¦³å¯Ÿã‚’å«ã‚€å€‹ã€…ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "![ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒª](./episodic_memory.png)\n",
    "\n",
    "### ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¨ã¯?\n",
    "\n",
    "**ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³**ã¯ã€è¤‡æ•°ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‹ã‚‰è‡ªå‹•çš„ã«æŠ½å‡ºã•ã‚ŒãŸåˆæˆã‚¤ãƒ³ã‚µã‚¤ãƒˆã§ã™ã€‚ä»¥ä¸‹ã‚’æä¾›ã—ã¾ã™:\n",
    "- **ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜**: é¡ä¼¼ã—ãŸã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é–“ã§å…±é€šã®å•é¡Œã¨ãã®è§£æ±ºç­–\n",
    "- **ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹**: æˆåŠŸã—ãŸãƒ‡ãƒãƒƒã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã†ã¾ãã„ã£ãŸæˆ¦ç•¥\n",
    "- **ã‚ˆãã‚ã‚‹è½ã¨ã—ç©´**: å¤±æ•—ã—ãŸè©¦è¡Œã«åŸºã¥ã„ã¦é¿ã‘ã‚‹ã¹ããƒŸã‚¹\n",
    "- **æˆ¦ç•¥çš„ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹**: é¡ä¼¼ã®å•é¡Œã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã™ã‚‹ãŸã‚ã®é«˜ãƒ¬ãƒ™ãƒ«ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹\n",
    "\n",
    "**å‡ºåŠ›æ§‹é€ :**\n",
    "- **ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰**: `debugging/{actorId}/sessions/{sessionId}` ã«ä¿å­˜ - å®Œå…¨ãªä¼šè©±ãƒˆãƒ¬ãƒ¼ã‚¹\n",
    "- **ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³**: `debugging/{actorId}` ã«ä¿å­˜ - è¤‡æ•°ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‹ã‚‰ã®åˆæˆçŸ¥è­˜\n",
    "\n",
    "### ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã‚’ä½¿ç”¨ã™ã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°\n",
    "\n",
    "ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã¯ä»¥ä¸‹ã®å ´åˆã«ä½¿ç”¨ã—ã¾ã™:\n",
    "1. **é †åºçš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒé‡è¦ãªå ´åˆ**: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®é †åºã¨ãã®çµæœãŒé‡è¦ï¼ˆä¾‹: ãƒ‡ãƒãƒƒã‚°ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã€ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ‰‹é †ï¼‰\n",
    "2. **çµŒé¨“ã‹ã‚‰å­¦ç¿’ã™ã‚‹å ´åˆ**: éå»ã®æˆåŠŸã¨å¤±æ•—ã‚’åˆ†æã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ”¹å–„ã—ãŸã„\n",
    "3. **ãƒ—ãƒ­ã‚»ã‚¹ã®å–å¾—**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œå‰å› X ã‚’ã©ã†è§£æ±ºã—ãŸã‹?ã€ã‚„ã€Œæ­£ç¢ºãªæ‰‹é †ã‚’è¦‹ã›ã¦ã€ã‚’æ€ã„å‡ºã™å¿…è¦ãŒã‚ã‚‹\n",
    "\n",
    "### ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã®è©³ç´°\n",
    "\n",
    "| é …ç›® | è©³ç´° |\n",
    "|:-----|:-----|\n",
    "| ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ— | ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä»˜ãã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒª |\n",
    "| ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¤ãƒ— | ãƒ‡ãƒãƒƒã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ |\n",
    "| ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ | Strands Agents |\n",
    "| LLM ãƒ¢ãƒ‡ãƒ« | Claude Haiku 4.5 |\n",
    "| ãƒ¡ãƒ¢ãƒªæˆ¦ç•¥ | ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¨­å®šä»˜ãã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒª |\n",
    "| è¤‡é›‘ã• | ä¸­ç´š |\n",
    "\n",
    "## å‰ææ¡ä»¶\n",
    "\n",
    "- Python 3.10+\n",
    "- AgentCore Memory æ¨©é™ã‚’æŒã¤ AWS èªè¨¼æƒ…å ±\n",
    "- AgentCore ã‚µãƒ¼ãƒ“ã‚¹ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 1: ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import uuid\n",
    "from datetime import datetime, timezone\n",
    "from typing import List, Dict, Any\n",
    "from pprint import pprint\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"debugging-assistant\")\n",
    "\n",
    "# Import boto3 for control plane and data plane operations\n",
    "import boto3\n",
    "\n",
    "# Import Strands Agent framework\n",
    "from strands import Agent, tool\n",
    "\n",
    "logger.info(\"âœ… ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ãŒæ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Configuration\n",
    "REGION = os.getenv('AWS_REGION', 'us-west-2')\n",
    "# Session identifiers\n",
    "ACTOR_ID = \"developer\"\n",
    "\n",
    "logger.info(f\"ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ {REGION} ã®è¨­å®šãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
    "logger.info(f\"ã‚¢ã‚¯ã‚¿ãƒ¼ID: {ACTOR_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 2: ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯æˆ¦ç•¥ã‚’ä½¿ç”¨ã—ãŸãƒ¡ãƒ¢ãƒªã®ä½œæˆ\n",
    "\n",
    "**ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¨­å®š**ã‚’å«ã‚€**ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªæˆ¦ç•¥**ã§æ§‹æˆã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Š:\n",
    "- å®Œå…¨ãªãƒ‡ãƒãƒƒã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ä¿å­˜\n",
    "- è¤‡æ•°ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚¤ãƒ³ã‚µã‚¤ãƒˆã®è‡ªå‹•ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize boto3 client for control and data plane operations\n",
    "client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=REGION,\n",
    ")\n",
    "memory_client = boto3.client(\n",
    "  'bedrock-agentcore-control',\n",
    "   region_name=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define episodic memory strategy with reflections as dictionary\n",
    "memory_name = \"DebugAssistantEpisodic\"\n",
    "\n",
    "# Episodic memory is implemented as a customMemoryStrategy\n",
    "episodic_strategy = {\n",
    "    \"episodicMemoryStrategy\": {\n",
    "      \"name\": \"DebuggingEpisodeExtractor\",\n",
    "      \"description\": \"Creates debugging session episodes with reflections per actor\",\n",
    "      \"namespaces\": [\n",
    "        \"debugging/{actorId}/sessions/{sessionId}\"\n",
    "      ],\n",
    "      \"reflectionConfiguration\": {\n",
    "        \"namespaces\": [\n",
    "          \"debugging/{actorId}\" # should be an exact prefix of the episodic memory namespace.\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "}\n",
    "logger.info(f\"æˆ¦ç•¥ã‚’è¨­å®š: {episodic_strategy['episodicMemoryStrategy']['name']}\")\n",
    "logger.info(f\"ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒãƒ¼ãƒ ã‚¹ãƒšãƒ¼ã‚¹: {episodic_strategy['episodicMemoryStrategy']['namespaces'][0]}\")\n",
    "logger.info(f\"ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¼ãƒ ã‚¹ãƒšãƒ¼ã‚¹: {episodic_strategy['episodicMemoryStrategy']['reflectionConfiguration']['namespaces'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create memory\n",
    "try:\n",
    "    # Try to find existing memory first\n",
    "    list_response = memory_client.list_memories(maxResults=100)\n",
    "    memory_id = None\n",
    "    for mem in list_response.get('memories', []):\n",
    "        detail = memory_client.get_memory(memoryId=mem['id'])\n",
    "        if detail['memory'].get('name') == memory_name:\n",
    "            memory_id = mem['id']\n",
    "            logger.info(f\"âœ… æ—¢å­˜ã®ãƒ¡ãƒ¢ãƒªã‚’ä½¿ç”¨: {memory_id}\")\n",
    "            break\n",
    "    \n",
    "    # Create if not found\n",
    "    if not memory_id:\n",
    "        logger.info(f\"æ–°ã—ã„ãƒ¡ãƒ¢ãƒªã‚’ä½œæˆä¸­: {memory_name}\")\n",
    "        response = memory_client.create_memory(\n",
    "            name=memory_name,\n",
    "            description=\"Episodic memory for debugging assistant with reflections\",\n",
    "            eventExpiryDuration=90,\n",
    "            memoryStrategies=[episodic_strategy],\n",
    "            clientToken=str(uuid.uuid4())\n",
    "        )\n",
    "        memory_id = response['memory']['id']\n",
    "        logger.info(f\"âœ… ãƒ¡ãƒ¢ãƒªãŒä½œæˆã•ã‚Œã¾ã—ãŸ: {memory_id}\")\n",
    "        \n",
    "        # Wait for ACTIVE\n",
    "        import time\n",
    "        for _ in range(30):\n",
    "            status = memory_client.get_memory(memoryId=memory_id)['memory']['status']\n",
    "            if status == 'ACTIVE':\n",
    "                logger.info(\"âœ… ãƒ¡ãƒ¢ãƒªãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ãªã‚Šã¾ã—ãŸ\")\n",
    "                break\n",
    "            time.sleep(10)\n",
    "            \n",
    "except Exception as e:\n",
    "    logger.error(f\"âŒ ãƒ¡ãƒ¢ãƒªã®å–å¾—/ä½œæˆã«å¤±æ•—: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 4: å±¥æ­´ãƒ‡ãƒãƒƒã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ãƒ¡ãƒ¢ãƒªã‚’ãƒã‚¤ãƒ‰ãƒ¬ãƒ¼ãƒˆ\n",
    "\n",
    "éå»ã®ãƒ‡ãƒãƒƒã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã«ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ã‚‡ã†ã€‚å„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯å®Œå…¨ãªãƒ‡ãƒãƒƒã‚°ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è¡¨ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Load all session data files\n",
    "data_dir = \"./data\"\n",
    "session_files = sorted(glob.glob(f\"{data_dir}/*.json\"))\n",
    "\n",
    "logger.info(f\"ãƒã‚¤ãƒ‰ãƒ¬ãƒ¼ãƒˆå¯¾è±¡ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒ {len(session_files)} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "\n",
    "# Hydrate each session\n",
    "for session_file in session_files:\n",
    "    session_name = os.path.basename(session_file).replace('.json', '')\n",
    "    session_id = f\"{session_name}_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "    \n",
    "    logger.info(f\"ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒã‚¤ãƒ‰ãƒ¬ãƒ¼ãƒˆä¸­: {session_name}\")\n",
    "    \n",
    "    # Load conversation data\n",
    "    with open(session_file, 'r') as f:\n",
    "        conversation = json.load(f)\n",
    "    \n",
    "    # Convert to payload format\n",
    "    payload = []\n",
    "    for turn in conversation:\n",
    "        conv_data = turn['conversational']\n",
    "        payload.append({\n",
    "            'conversational': {\n",
    "                'content': {'text': conv_data['content']['text']},\n",
    "                'role': conv_data['role']\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Create event using boto3 directly\n",
    "    event_timestamp = datetime.now(timezone.utc)\n",
    "    result = client.create_event(\n",
    "        memoryId=memory_id,\n",
    "        actorId=ACTOR_ID,\n",
    "        sessionId=session_id,\n",
    "        eventTimestamp=event_timestamp,\n",
    "        payload=payload\n",
    "    )\n",
    "\n",
    "    logger.info(f\"   âœ“ {len(payload)} ã‚¿ãƒ¼ãƒ³ã‚’ä¿å­˜ - ã‚¤ãƒ™ãƒ³ãƒˆID: {result['event']['eventId']}\")\n",
    "\n",
    "logger.info(f\"âœ… {len(session_files)} ä»¶ã®ãƒ‡ãƒãƒƒã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒã‚¤ãƒ‰ãƒ¬ãƒ¼ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### list memory records to see if its been extracted to LTM\n",
    "import time\n",
    "import pprint\n",
    "reflection_namespace = f\"debugging/{ACTOR_ID}\"\n",
    "# time.sleep(60)\n",
    "# Use boto3 client directly to retrieve memory records\n",
    "response = client.list_memory_records(\n",
    "    memoryId=memory_id,\n",
    "    namespace=reflection_namespace,\n",
    "    maxResults=20\n",
    ")\n",
    "memories = response.get('memoryRecordSummaries', [])\n",
    "logger.info(f\"   {len(memories)} ä»¶ã®ãƒ¡ãƒ¢ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "if memories:\n",
    "    pprint.pp(json.loads(memories[0][\"content\"][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if reflections and episodes have been generated or not.\n",
    "import pprint\n",
    "# Use boto3 client directly to retrieve memory records\n",
    "response = client.retrieve_memory_records(\n",
    "memoryId=memory_id,\n",
    "namespace=f\"debugging/{ACTOR_ID}\",\n",
    "searchCriteria={\n",
    "    'searchQuery': \"memory leaks\",\n",
    "    \"metadataFilters\":[{\"left\": {\"metadataKey\": \"x-amz-agentcore-memory-recordType\"},\n",
    "        \"operator\": \"EQUALS_TO\",\n",
    "        \"right\": {\"metadataValue\": {\"stringValue\": \"REFLECTION\"}}\n",
    "        }],          \n",
    "    'topK': 10\n",
    "},\n",
    "    maxResults=20\n",
    ")\n",
    "\n",
    "reflections = response.get('memoryRecordSummaries', [])\n",
    "logger.info(f\"   {len(reflections)} ä»¶ã®é–¢é€£ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "if reflections:\n",
    "    for reflection in reflections:\n",
    "        reflection_json = json.loads(reflection['content']['text'])\n",
    "        pprint.pp(reflection_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 5: ãƒ¡ãƒ¢ãƒªå–å¾—ãƒ„ãƒ¼ãƒ«ã®ä½œæˆ\n",
    "\n",
    "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨ã« 2 ã¤ã®ç‰¹åŒ–ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã™:\n",
    "1. **retrieve_process**: è©³ç´°ãªã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ—ãƒ­ã‚»ã‚¹ç”¨ã«å®Œå…¨ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—\n",
    "2. **retrieve_reflection_knowledge**: è¤‡æ•°ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‹ã‚‰ã®åˆæˆã‚¤ãƒ³ã‚µã‚¤ãƒˆã¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"Approximate token count for a text string.\"\"\"\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def linearize_episodes(episodes: List[Dict], include_steps: bool = True,\n",
    "                       include_reflections: bool = True) -> str:\n",
    "    \"\"\"Linearize episode data into human-readable format.\"\"\"\n",
    "    if not episodes:\n",
    "        return \"No relevant episodes found.\"\n",
    "\n",
    "    output = []\n",
    "    for idx, episode in enumerate(episodes, 1):\n",
    "        content = episode.get('content', {})\n",
    "        \n",
    "        # Parse JSON from text field\n",
    "        if 'text' in content:\n",
    "            try:\n",
    "                episode_data = json.loads(content['text'])\n",
    "            except json.JSONDecodeError:\n",
    "                output.append(f\"Episode {idx}: Unable to parse content\\n\")\n",
    "                continue\n",
    "        else:\n",
    "            output.append(f\"Episode {idx}: No content available\\n\")\n",
    "            continue\n",
    "        \n",
    "        output.append(f\"{'='*80}\\nEpisode {idx}\\n{'='*80}\")\n",
    "        output.append(f\"**Situation:** {episode_data.get('situation', 'N/A')}\")\n",
    "        output.append(f\"**Intent:** {episode_data.get('intent', 'N/A')}\")\n",
    "        output.append(f\"**Assessment:** {episode_data.get('assessment', 'N/A')}\\n\")\n",
    "        \n",
    "        if include_steps:\n",
    "            turns = episode_data.get('turns', [])\n",
    "            if turns:\n",
    "                output.append(\"**Debugging Steps:**\")\n",
    "                for turn_idx, turn in enumerate(turns, 1):\n",
    "                    output.append(f\"\\nStep {turn_idx}:\")\n",
    "                    output.append(f\"  Situation: {turn.get('situation', 'N/A')}\")\n",
    "                    output.append(f\"  Action: {turn.get('action', 'N/A')}\")\n",
    "                    output.append(f\"  Thought: {turn.get('thought', 'N/A')}\")\n",
    "        \n",
    "        if include_reflections:\n",
    "            reflection = episode_data.get('reflection')\n",
    "            if reflection:\n",
    "                output.append(f\"\\n**Reflection:** {reflection}\\n\")\n",
    "    \n",
    "    result = \"\\n\".join(output)\n",
    "    logger.info(f\"   ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {count_tokens(result)}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def linearize_reflections(reflections: List[Dict]) -> str:\n",
    "    \"\"\"Linearize reflection knowledge into human-readable format.\"\"\"\n",
    "    if not reflections:\n",
    "        return \"No reflection knowledge found.\"\n",
    "\n",
    "    output = []\n",
    "    for idx, reflection in enumerate(reflections, 1):\n",
    "        content = reflection.get('content', {})\n",
    "        score = reflection.get('score', 0)\n",
    "        \n",
    "        # Parse JSON from text field\n",
    "        if 'text' in content:\n",
    "            try:\n",
    "                reflection_data = json.loads(content['text'])\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        output.append(f\"{'='*80}\\nReflection {idx} (Relevance: {score:.2f})\\n{'='*80}\")\n",
    "        output.append(f\"**Title:** {reflection_data.get('title', 'Untitled')}\")\n",
    "        output.append(f\"**Use Cases:** {reflection_data.get('use_cases', 'N/A')}\")\n",
    "        output.append(f\"**Hints:** {reflection_data.get('hints', 'N/A')}\\n\")\n",
    "    \n",
    "    result = \"\\n\".join(output)\n",
    "    logger.info(f\"   ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {count_tokens(result)}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "logger.info(\"âœ… ç·šå½¢åŒ–ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ãŒä½œæˆã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create memory retrieval tools for the agent\n",
    "\n",
    "@tool\n",
    "def retrieve_process(task: str, include_steps: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve example processes to help solve the given task. Returns complete debugging\n",
    "    episodes with configurable detail level.\n",
    "    \n",
    "    Use include_steps parameter to control verbosity:\n",
    "    - Set include_steps=True when user asks for \"exact steps\", \"full details\", \"how did we\",\n",
    "      \"what steps did we take\", or needs complete procedural information\n",
    "    - Set include_steps=False for pattern/best practice queries where high-level context\n",
    "      (situation, intent, assessment) is sufficient without step-by-step details\n",
    "\n",
    "    Args:\n",
    "        task: The task to solve that requires example processes\n",
    "        include_steps: Whether to include detailed step-by-step turns (default: True)\n",
    "\n",
    "    Returns:\n",
    "        Formatted debugging episodes with optional detailed steps\n",
    "    \"\"\"\n",
    "    logger.info(f\"ğŸ” ã‚¿ã‚¹ã‚¯ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å–å¾—ä¸­: {task} (include_steps={include_steps})\")\n",
    "    \n",
    "    try:\n",
    "        # Search in episode namespace\n",
    "        namespace = f\"debugging/{ACTOR_ID}/sessions/{session_id}\"\n",
    "        \n",
    "        # Use boto3 client directly to retrieve memory records\n",
    "        response = client.retrieve_memory_records(\n",
    "            memoryId=memory_id,\n",
    "            namespace=namespace,\n",
    "            searchCriteria={\n",
    "                'searchQuery': task,\n",
    "                'topK': 3\n",
    "            },\n",
    "            maxResults=20\n",
    "        )\n",
    "        \n",
    "        episodes = response.get('memoryRecordSummaries', [])\n",
    "        logger.info(f\"   {len(episodes)} ä»¶ã®é–¢é€£ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "        \n",
    "        # Linearize with configurable detail level\n",
    "        return linearize_episodes(episodes, include_steps=include_steps, include_reflections=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"ãƒ—ãƒ­ã‚»ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return f\"Error retrieving processes: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def retrieve_reflection_knowledge(task: str, k: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve synthesized reflection knowledge from past agent experiences. Each knowledge \n",
    "    entry contains: (1) a descriptive title, (2) specific use cases for when to apply it, \n",
    "    and (3) actionable hints including best practices from successful episodes and common \n",
    "    pitfalls to avoid from failed episodes. Use this to get strategic guidance and patterns\n",
    "    for similar tasks.\n",
    "\n",
    "    Args:\n",
    "        task: The current task to get strategic guidance for\n",
    "        k: Number of reflection entries to retrieve (default: 5)\n",
    "\n",
    "    Returns:\n",
    "        Synthesized reflection knowledge from past debugging experiences\n",
    "    \"\"\"\n",
    "    logger.info(f\"ğŸ” ã‚¿ã‚¹ã‚¯ã®ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çŸ¥è­˜ã‚’å–å¾—ä¸­: {task}\")\n",
    "    \n",
    "    try:\n",
    "        # Search in reflection namespace\n",
    "        namespace = f\"debugging/{ACTOR_ID}\"\n",
    "        \n",
    "        # Use boto3 client directly to retrieve memory records\n",
    "        response = client.retrieve_memory_records(\n",
    "            memoryId=memory_id,\n",
    "            namespace=namespace,\n",
    "            searchCriteria={\n",
    "                'searchQuery': \"memory leaks\",\n",
    "                \"metadataFilters\":[{\"left\":{\"metadataKey\": \"x-amz-agentcore-memory-recordType\"},\n",
    "                                    \"operator\": \"EQUALS_TO\",\n",
    "                                    \"right\": {\"metadataValue\": {\"stringValue\": \"REFLECTION\"}}\n",
    "                                    }],          \n",
    "                'topK': k\n",
    "            },\n",
    "            maxResults=20\n",
    "        )\n",
    "        \n",
    "        reflections = response.get('memoryRecordSummaries', [])\n",
    "        logger.info(f\"   {len(reflections)} ä»¶ã®é–¢é€£ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚¤ãƒ³ã‚µã‚¤ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "        \n",
    "        # Linearize reflections\n",
    "        return linearize_reflections(reflections)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return f\"Error retrieving reflections: {str(e)}\"\n",
    "\n",
    "\n",
    "logger.info(\"âœ… ãƒ¡ãƒ¢ãƒªå–å¾—ãƒ„ãƒ¼ãƒ«ãŒä½œæˆã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 6: ãƒ‡ãƒãƒƒã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆ\n",
    "\n",
    "ãƒ¡ãƒ¢ãƒªå–å¾—ãƒ„ãƒ¼ãƒ«ã‚’è£…å‚™ã—ãŸ Strands ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the debugging assistant agent\n",
    "debugging_agent = Agent(\n",
    "    model=\"global.anthropic.claude-haiku-4-5-20251001-v1:0\",\n",
    "    tools=[retrieve_process, retrieve_reflection_knowledge],\n",
    "    system_prompt=\"\"\"You are an expert Debugging Assistant with access to episodic memory.\n",
    "\n",
    "Your capabilities:\n",
    "- Retrieve past debugging episodes with complete step-by-step processes\n",
    "- Access synthesized reflection knowledge showing patterns and best practices\n",
    "- Provide guidance based on successful debugging experiences\n",
    "- Warn about common pitfalls observed in past failures\n",
    "\n",
    "When helping users:\n",
    "1. Use retrieve_reflection_knowledge for strategic guidance, patterns, and high-level advice\n",
    "2. Use retrieve_process when users need exact steps or want to recall what was done in a specific session\n",
    "3. Synthesize insights from memory with your own reasoning\n",
    "4. Be specific and actionable in your recommendations\n",
    "\n",
    "Always explain your reasoning and cite relevant past experiences when available.\"\"\"\n",
    ")\n",
    "\n",
    "logger.info(\"âœ… ãƒ‡ãƒãƒƒã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä½œæˆã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 7: ãƒ‡ãƒãƒƒã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆ\n",
    "\n",
    "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã¨ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã©ã®ã‚ˆã†ã«ä½¿ç”¨ã™ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«ã€ã•ã¾ã–ã¾ãªã‚·ãƒŠãƒªã‚ªã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ†ã‚¹ãƒˆ 1: æˆ¦ç•¥çš„ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã®ã‚¯ã‚¨ãƒªï¼ˆãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çŸ¥è­˜ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Get strategic guidance for memory issues\n",
    "query1 = \"My application is running out of memory when processing large datasets. What should I look for?\"\n",
    "\n",
    "logger.info(f\"\\n{'='*80}\")\n",
    "logger.info(f\"ãƒ†ã‚¹ãƒˆ 1: ãƒ¡ãƒ¢ãƒªå•é¡Œã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹\")\n",
    "logger.info(f\"{'='*80}\")\n",
    "logger.info(f\"ã‚¯ã‚¨ãƒª: {query1}\\n\")\n",
    "\n",
    "response1 = debugging_agent(query1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿œç­”:\")\n",
    "print(\"=\"*80)\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ†ã‚¹ãƒˆ 2: å…·ä½“çš„ãªãƒ—ãƒ­ã‚»ã‚¹ã®è©³ç´°ã®ã‚¯ã‚¨ãƒª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Get specific debugging process\n",
    "query2 = \"Show me the exact steps for debugging a timeout issue with external API calls.\"\n",
    "\n",
    "logger.info(f\"\\n{'='*80}\")\n",
    "logger.info(f\"ãƒ†ã‚¹ãƒˆ 2: API ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒ‡ãƒãƒƒã‚°ãƒ—ãƒ­ã‚»ã‚¹\")\n",
    "logger.info(f\"{'='*80}\")\n",
    "logger.info(f\"ã‚¯ã‚¨ãƒª: {query2}\\n\")\n",
    "\n",
    "response2 = debugging_agent(query2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿œç­”:\")\n",
    "print(\"=\"*80)\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ†ã‚¹ãƒˆ 3: ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã®ã‚¯ã‚¨ãƒª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Get patterns and best practices for concurrency issues\n",
    "query3 = \"What are common patterns and best practices for handling race conditions in multi-threaded applications?\"\n",
    "\n",
    "logger.info(f\"\\n{'='*80}\")\n",
    "logger.info(f\"ãƒ†ã‚¹ãƒˆ 3: ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³\")\n",
    "logger.info(f\"{'='*80}\")\n",
    "logger.info(f\"ã‚¯ã‚¨ãƒª: {query3}\\n\")\n",
    "\n",
    "response3 = debugging_agent(query3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿œç­”:\")\n",
    "print(\"=\"*80)\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ†ã‚¹ãƒˆ 4: ç‰¹å®šã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å‘¼ã³å‡ºã—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Recall what was done in memory leak session\n",
    "query4 = \"What debugging steps did we take when we encountered the memory leak issue? I need the full details.\"\n",
    "\n",
    "logger.info(f\"\\n{'='*80}\")\n",
    "logger.info(f\"ãƒ†ã‚¹ãƒˆ 4: ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å‘¼ã³å‡ºã—\")\n",
    "logger.info(f\"{'='*80}\")\n",
    "logger.info(f\"ã‚¯ã‚¨ãƒª: {query4}\\n\")\n",
    "\n",
    "response4 = debugging_agent(query4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿œç­”:\")\n",
    "print(\"=\"*80)\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 8: ç›´æ¥ãƒ¡ãƒ¢ãƒªæ¤œæŸ»\n",
    "\n",
    "ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã¨ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹å†…å®¹ã‚’ç›´æ¥æ¤œæŸ»ã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect episodes directly using boto3\n",
    "logger.info(\"\" + \"=\"*80)\n",
    "logger.info(\"ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ç›´æ¥æ¤œæŸ»\")\n",
    "logger.info(\"=\"*80)\n",
    "\n",
    "# Retrieve episodes using boto3 directly\n",
    "namespace = f\"debugging/{ACTOR_ID}/sessions\"\n",
    "response = client.retrieve_memory_records(\n",
    "    memoryId=memory_id,\n",
    "    namespace=namespace,\n",
    "    searchCriteria={\n",
    "        'searchQuery': 'debugging',\n",
    "        'topK': 2\n",
    "    },\n",
    "    maxResults=10\n",
    ")\n",
    "\n",
    "episodes = response.get('memoryRecordSummaries', [])\n",
    "\n",
    "print(f\"ãƒ¡ãƒ¢ãƒªå†…ã« {len(episodes)} ä»¶ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:\")\n",
    "for idx, episode in enumerate(episodes, 1):\n",
    "    print(f\"ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {idx}:\")\n",
    "    pprint.pp(episode, depth=2, width=100)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "response = client.retrieve_memory_records(\n",
    "memoryId=memory_id,\n",
    "namespace=reflection_namespace,\n",
    "searchCriteria={\n",
    "    'searchQuery': \"memory leaks\",\n",
    "    \"metadataFilters\":[{\n",
    "        \"left\":{\"metadataKey\": \"x-amz-agentcore-memory-recordType\"},\n",
    "        \"operator\": \"EQUALS_TO\",\n",
    "        \"right\": {\"metadataValue\": {\"stringValue\": \"REFLECTION\"}}\n",
    "                        }],          \n",
    "    'topK': 10\n",
    "},\n",
    "    maxResults=20\n",
    ")\n",
    "\n",
    "reflections = response.get('memoryRecordSummaries', [])\n",
    "logger.info(f\"   {len(reflections)} ä»¶ã®é–¢é€£ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "if reflections:\n",
    "    for reflection in reflections:\n",
    "        reflection_json = json.loads(reflection['content']['text'])\n",
    "        pprint.pp(reflection_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã¾ã¨ã‚\n",
    "\n",
    "### é”æˆã—ãŸã“ã¨\n",
    "\n",
    "- boto3 ã‚’ä½¿ç”¨ã—ã¦ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¨­å®šä»˜ãã®ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã‚’ä½œæˆ\n",
    "- å±¥æ­´ãƒ‡ãƒãƒƒã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ãƒ¡ãƒ¢ãƒªã‚’ãƒã‚¤ãƒ‰ãƒ¬ãƒ¼ãƒˆ\n",
    "- ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã¨ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç”¨ã®ç‰¹åŒ–å–å¾—ãƒ„ãƒ¼ãƒ«ã‚’æ§‹ç¯‰\n",
    "- Strands ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªãƒ‡ãƒãƒƒã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’ä½œæˆ\n",
    "- æˆ¦ç•¥çš„ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹å–å¾—ã¨è©³ç´°ãƒ—ãƒ­ã‚»ã‚¹å–å¾—ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "\n",
    "### ä¸»ãªå­¦ã³\n",
    "\n",
    "1. **ã‚¨ãƒ”ã‚½ãƒ‡ã‚£ãƒƒã‚¯ãƒ¡ãƒ¢ãƒª**ã¯æ™‚é–“çš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒã¤å®Œå…¨ãªã‚„ã‚Šå–ã‚Šã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä¿æŒ\n",
    "2. **ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³**ã¯è¤‡æ•°ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’è‡ªå‹•çš„ã«åˆæˆ\n",
    "3. **ç·šå½¢åŒ–**ã¯ LLM æ¶ˆè²»ç”¨ã«æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹ã“ã¨ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æœ€é©åŒ–\n",
    "4. **ãƒ„ãƒ¼ãƒ«é¸æŠ**ãŒé‡è¦: æˆ¦ç•¥ã«ã¯ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã€è©³ç´°æ‰‹é †ã«ã¯ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ä½¿ç”¨\n",
    "5. **Boto3 ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹**ã«ã‚ˆã‚Š Genesis Memory API æ“ä½œã®å®Œå…¨ãªåˆ¶å¾¡ãŒå¯èƒ½\n",
    "\n",
    "### ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨ã™ã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°\n",
    "\n",
    "- éå»ã®ãƒã‚±ãƒƒãƒˆè§£æ±ºã‹ã‚‰å­¦ç¿’ã™ã‚‹**ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚µãƒãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ **\n",
    "- æˆåŠŸã—ãŸè¨ºæ–­æ‰‹é †ã‚’æ€ã„å‡ºã™**ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ**\n",
    "- çŸ¥è­˜ç§»è»¢ã®ãŸã‚ã«å°‚é–€å®¶ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã™ã‚‹**ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ **\n",
    "- éå»ã®çµæœåˆ†æãŒã‚ˆã‚Šè‰¯ã„ãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’æ¨é€²ã™ã‚‹**ãƒ—ãƒ­ã‚»ã‚¹æ”¹å–„**ã‚·ãƒŠãƒªã‚ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "\n",
    "å®Œäº†ã—ãŸã‚‰ãƒ¡ãƒ¢ãƒªãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤ã™ã‚‹ã«ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’è§£é™¤ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete memory resource using boto3\n",
    "# try:\n",
    "#     client.delete_memory(memoryId=memory_id, clientToken=str(uuid.uuid4()))\n",
    "#     logger.info(f\"âœ… Successfully deleted memory: {memory_id}\")\n",
    "# except Exception as e:\n",
    "#     logger.error(f\"Error deleting memory: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
