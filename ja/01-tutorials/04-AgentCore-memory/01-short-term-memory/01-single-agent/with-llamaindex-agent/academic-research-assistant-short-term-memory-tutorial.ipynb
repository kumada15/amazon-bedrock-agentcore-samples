{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex ã¨ AgentCore Memory - å­¦è¡“ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆï¼ˆçŸ­æœŸãƒ¡ãƒ¢ãƒªï¼‰\n",
    "\n",
    "## ã¯ã˜ã‚ã«\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€Amazon Bedrock AgentCore Memory æ©Ÿèƒ½ã‚’ LlamaIndex ã¨çµ±åˆã—ã¦å­¦è¡“ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚å˜ä¸€ã®ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§ã®**çŸ­æœŸãƒ¡ãƒ¢ãƒª**ã®æ°¸ç¶šåŒ–ã«ç„¦ç‚¹ã‚’å½“ã¦ã€ä¼šè©±å…¨ä½“ã‚’é€šã˜ã¦ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒè«–æ–‡ã€ç™ºè¦‹ã€ç ”ç©¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨˜æ†¶ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚\n",
    "\n",
    "## ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã®è©³ç´°\n",
    "\n",
    "| æƒ…å ±               | è©³ç´°                                                                            |\n",
    "|:-------------------|:--------------------------------------------------------------------------------|\n",
    "| ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ— | çŸ­æœŸä¼šè©±ãƒ¡ãƒ¢ãƒª                                                                  |\n",
    "| ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ | å­¦è¡“ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ                                                            |\n",
    "| ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ | LlamaIndex                                                                      |\n",
    "| LLM ãƒ¢ãƒ‡ãƒ«          | Anthropic Claude 3.7 Sonnet                                                     |\n",
    "| ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | AgentCore çŸ­æœŸãƒ¡ãƒ¢ãƒªã€LlamaIndex ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ç ”ç©¶ãƒ„ãƒ¼ãƒ«                        |\n",
    "| é›£æ˜“åº¦              | åˆç´š                                                                            |\n",
    "\n",
    "å­¦ç¿’å†…å®¹ï¼š\n",
    "- ç ”ç©¶ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–ã®ãŸã‚ã® AgentCore Memory ã®ä½œæˆ\n",
    "- LlamaIndex ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¡ãƒ¢ãƒªçµ±åˆã®ä½¿ç”¨\n",
    "- è«–æ–‡åˆ†æã®ãŸã‚ã®ç ”ç©¶å°‚ç”¨ãƒ„ãƒ¼ãƒ«ã®æ§‹ç¯‰\n",
    "- å˜ä¸€ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§ã®ç ”ç©¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç¶­æŒ\n",
    "- ãƒ¡ãƒ¢ãƒªå¢ƒç•Œã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†é›¢ã®ãƒ†ã‚¹ãƒˆ\n",
    "\n",
    "## ã‚·ãƒŠãƒªã‚ªã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n",
    "\n",
    "ã“ã®ä¾‹ã§ã¯ã€ç ”ç©¶è€…ãŒå˜ä¸€ã®ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§è«–æ–‡ã€ç™ºè¦‹ã€ç ”ç©¶ãƒˆãƒ”ãƒƒã‚¯ã‚’è¿½è·¡ã™ã‚‹ã®ã‚’æ”¯æ´ã™ã‚‹ã€Œå­¦è¡“ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ã‚’ä½œæˆã—ã¾ã™ã€‚ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¯ AgentCore Memory ã‚’ä½¿ç”¨ã—ã¦ã€ä¼šè©±å…¨ä½“ã‚’é€šã˜ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ãŸè«–æ–‡ã€ç™ºè¦‹ã—ãŸä¸»è¦ãªçŸ¥è¦‹ã€ç ”ç©¶ã®é€²æ—çŠ¶æ³ã«é–¢ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¶­æŒã—ã¾ã™ã€‚\n",
    "\n",
    "## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¦‚è¦\n",
    "\n",
    "![LlamaIndex AgentCore çŸ­æœŸãƒ¡ãƒ¢ãƒªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](LlamaIndex-AgentCore-STM-Arch.png)\n",
    "\n",
    "## å‰ææ¡ä»¶\n",
    "\n",
    "- Python 3.10ä»¥ä¸Š\n",
    "- é©åˆ‡ãªæ¨©é™ã‚’æŒã¤ AWS ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "- AgentCore Memory æ¨©é™ã‚’æŒã¤ AWS IAM ãƒ­ãƒ¼ãƒ«ï¼š\n",
    "  - `bedrock-agentcore:CreateMemory`\n",
    "  - `bedrock-agentcore:CreateEvent`\n",
    "  - `bedrock-agentcore:ListEvents`\n",
    "  - `bedrock-agentcore:RetrieveMemories`\n",
    "- Amazon Bedrock ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 1: ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "%pip install llama-index-memory-bedrock-agentcore llama-index-llms-bedrock-converse boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required components\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from llama_index.memory.bedrock_agentcore import AgentCoreMemory, AgentCoreMemoryContext\n",
    "from llama_index.llms.bedrock_converse import BedrockConverse\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 2: AgentCore Memory ã®è¨­å®š\n",
    "\n",
    "ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆç”¨ã® AgentCore Memory ãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã¾ãŸã¯å–å¾—ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AgentCore Memory resource\n",
    "region = os.getenv('AWS_REGION', 'us-east-1')\n",
    "client = MemoryClient(region_name=region)\n",
    "\n",
    "try:\n",
    "    response = client.create_memory_and_wait(\n",
    "        name=f'AcademicResearchShortTerm_{int(datetime.now().timestamp())}',\n",
    "        description='Academic research assistant short-term memory for single session context',\n",
    "        strategies=[],\n",
    "        event_expiry_days=7,\n",
    "        max_wait=300,\n",
    "        poll_interval=10\n",
    "    )\n",
    "    memory_id = response['id']\n",
    "    print(f\"âœ… Created AgentCore Memory: {memory_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating memory: {e}\")\n",
    "    memory_id = \"your-memory-id-here\"  # Replace with existing memory ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 3: ç ”ç©¶ãƒ„ãƒ¼ãƒ«ã®å®Ÿè£…\n",
    "\n",
    "å­¦è¡“ç ”ç©¶ã‚¿ã‚¹ã‚¯ç”¨ã®å°‚é–€ãƒ„ãƒ¼ãƒ«ã‚’å®šç¾©ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_paper_summary(title: str, authors: str, key_findings: str) -> str:\n",
    "    \"\"\"Save a research paper summary with title, authors, and key findings\"\"\"\n",
    "    print(f\"ğŸ“„ Saved paper: {title} by {authors}\")\n",
    "    return f\"Successfully saved paper summary for '{title}'\"\n",
    "\n",
    "def track_research_topic(topic: str, status: str) -> str:\n",
    "    \"\"\"Track research topic progress with current status\"\"\"\n",
    "    print(f\"ğŸ”¬ Tracking research topic: {topic} (Status: {status})\")\n",
    "    return f\"Now tracking research topic: {topic} with status {status}\"\n",
    "\n",
    "def save_research_finding(finding: str, confidence: str) -> str:\n",
    "    \"\"\"Save a research finding with confidence level\"\"\"\n",
    "    print(f\"ğŸ’¡ Research finding saved with {confidence} confidence\")\n",
    "    return f\"Saved research finding with {confidence} confidence level\"\n",
    "\n",
    "# Create tool objects for the agent\n",
    "research_tools = [\n",
    "    FunctionTool.from_defaults(fn=save_paper_summary),\n",
    "    FunctionTool.from_defaults(fn=track_research_topic),\n",
    "    FunctionTool.from_defaults(fn=save_research_finding)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 4: LlamaIndex ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè£…\n",
    "\n",
    "çŸ­æœŸãƒ¡ãƒ¢ãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒã¤ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for SHORT-TERM memory (single session)\n",
    "MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "\n",
    "# Create memory context for single session\n",
    "context = AgentCoreMemoryContext(\n",
    "    actor_id=\"academic-researcher\",\n",
    "    memory_id=memory_id,\n",
    "    session_id=\"research-session-today\",  # Same session throughout\n",
    "    namespace=\"/academic-research\"\n",
    ")\n",
    "\n",
    "# Initialize AgentCore Memory and LLM\n",
    "agentcore_memory = AgentCoreMemory(context=context)\n",
    "llm = BedrockConverse(model=MODEL_ID)\n",
    "\n",
    "# Create the research assistant agent\n",
    "research_agent = FunctionAgent(\n",
    "    tools=research_tools,\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Academic Research Assistant with short-term memory is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 5: çŸ­æœŸãƒ¡ãƒ¢ãƒªæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ\n",
    "\n",
    "åŒ…æ‹¬çš„ãªç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é€šã˜ã¦ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®çŸ­æœŸãƒ¡ãƒ¢ãƒªã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ†ã‚¹ãƒˆ 1: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize research session with detailed context\n",
    "response = await research_agent.run(\n",
    "    \"I'm Dr. Sarah Smith from MIT's Computer Science Department, starting research on 'Machine Learning in Healthcare Applications'. \"\n",
    "    \"Track this topic with status 'Literature Review'.\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"ğŸ¯ Session Initialization:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ†ã‚¹ãƒˆ 2: ç ”ç©¶è«–æ–‡ã®è¿½åŠ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add first paper with detailed metrics\n",
    "response = await research_agent.run(\n",
    "    \"Save paper: 'Deep Learning for Medical Image Analysis' by Zhang et al. \"\n",
    "    \"Key findings: CNNs achieve 95.2% accuracy in chest X-ray diagnosis, 12% improvement over radiologists, \"\n",
    "    \"trained on 100,000 images with 0.03 false positive rate.\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"ğŸ“„ Paper 1 Added:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add second paper with contrasting findings\n",
    "response = await research_agent.run(\n",
    "    \"Save paper: 'Transformers in Medical NLP' by Johnson et al. \"\n",
    "    \"Key findings: BERT models achieve 89.1% F1-score in clinical note classification, \"\n",
    "    \"struggle with rare diseases (<70% accuracy), excel at symptom extraction (94% precision).\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"ğŸ“„ Paper 2 Added:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ†ã‚¹ãƒˆ 3: ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æƒ³èµ·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test identity and research context recall\n",
    "response = await research_agent.run(\n",
    "    \"What's my name, institution, and current research focus?\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"ğŸ§  Identity Recall Test:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Dr. Sarah Smith, MIT, Machine Learning in Healthcare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ†ã‚¹ãƒˆ 4: è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æƒ³èµ·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test specific metric recall\n",
    "response = await research_agent.run(\n",
    "    \"What were the exact accuracy percentages mentioned in the papers I reviewed? \"\n",
    "    \"Which authors wrote about CNNs vs Transformers?\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š Detailed Metrics Recall:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Zhang et al - CNNs 95.2%, Johnson et al - BERT 89.1%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ†ã‚¹ãƒˆ 5: æ–‡è„ˆçš„æ¨è«–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test contextual understanding and reasoning\n",
    "response = await research_agent.run(\n",
    "    \"Based on the papers I've reviewed, which approach would be better for analyzing \"\n",
    "    \"chest X-rays vs clinical notes? Explain your reasoning.\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤” Contextual Reasoning Test:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: CNNs for X-rays (Zhang paper), Transformers for clinical notes (Johnson paper)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ†ã‚¹ãƒˆ 6: ç ”ç©¶ç™ºè¦‹ã®çµ±åˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add synthesized research finding\n",
    "response = await research_agent.run(\n",
    "    \"Based on Zhang's CNN results (95.2% accuracy) and Johnson's Transformer results (89.1% F1-score), \"\n",
    "    \"I conclude that deep learning models consistently achieve >85% accuracy in healthcare tasks. \"\n",
    "    \"This finding has high confidence. Save it.\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"ğŸ”¬ Research Finding Synthesis:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ†ã‚¹ãƒˆ 7: ç›¸äº’å‚ç…§æ©Ÿèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cross-referencing between findings and papers\n",
    "response = await research_agent.run(\n",
    "    \"How does my research finding about >85% accuracy relate to the specific results \"\n",
    "    \"from Zhang and Johnson? What evidence supports this conclusion?\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"ğŸ”— Cross-Reference Test:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Reference to Zhang 95.2% and Johnson 89.1% as supporting evidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ†ã‚¹ãƒˆ 8: å®Ÿè·µçš„ãªå¿œç”¨ã‚·ãƒŠãƒªã‚ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test practical application of accumulated knowledge\n",
    "response = await research_agent.run(\n",
    "    \"I'm writing a grant proposal for healthcare AI research. What evidence can I cite \"\n",
    "    \"about deep learning effectiveness? Include specific numbers and authors.\",\n",
    "    memory=agentcore_memory\n",
    ")\n",
    "\n",
    "print(\"ğŸ“ Grant Proposal Support:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Comprehensive summary with Zhang 95.2%, Johnson 89.1%, synthesis finding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¹ãƒ†ãƒƒãƒ— 6: ã‚»ãƒƒã‚·ãƒ§ãƒ³å¢ƒç•Œã®ãƒ†ã‚¹ãƒˆ\n",
    "\n",
    "ç•°ãªã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¦çŸ­æœŸãƒ¡ãƒ¢ãƒªã®å¢ƒç•Œã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a different session context\n",
    "new_session_context = AgentCoreMemoryContext(\n",
    "    actor_id=\"academic-researcher\",\n",
    "    memory_id=memory_id,\n",
    "    session_id=\"different-research-session\",  # Different session ID\n",
    "    namespace=\"/academic-research\"\n",
    ")\n",
    "\n",
    "new_session_memory = AgentCoreMemory(context=new_session_context)\n",
    "\n",
    "# Test memory isolation\n",
    "response = await research_agent.run(\n",
    "    \"What research have I been working on? What specific accuracy numbers did I find?\",\n",
    "    memory=new_session_memory\n",
    ")\n",
    "\n",
    "print(\"ğŸš§ Session Boundary Test (Different Session):\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Limited or no recall from previous session (short-term memory boundary)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return to original session to verify persistence\n",
    "response = await research_agent.run(\n",
    "    \"Now back in my original session - what were the accuracy numbers from Zhang and Johnson again?\",\n",
    "    memory=agentcore_memory  # Original session memory\n",
    ")\n",
    "\n",
    "print(\"ğŸ”„ Original Session Return:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Full recall of Zhang 95.2%, Johnson 89.1%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è‡ªå‹•ãƒ†ã‚¹ãƒˆæ¤œè¨¼\n",
    "ã“ã‚Œã‚‰ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ã€ãƒ¡ãƒ¢ãƒªçµ±åˆãŒæ­£ã—ãæ©Ÿèƒ½ã—ã¦ã„ã‚‹ã“ã¨ã‚’æ¤œè¨¼ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define validation functions inline\n",
    "class TestValidator:\n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "    \n",
    "    def validate_memory_recall(self, response):\n",
    "        \"\"\"Check if agent can recall information from earlier in the session\"\"\"\n",
    "        # Check for substantive response (not just \"I don't know\")\n",
    "        has_content = len(response) > 50\n",
    "        # Check for memory indicators\n",
    "        has_memory_indicators = any(word in response.lower() for word in \n",
    "            ['earlier', 'mentioned', 'discussed', 'previously', 'you', 'we', 'our'])\n",
    "        return \"âœ… PASS\" if (has_content and has_memory_indicators) else \"âŒ FAIL\"\n",
    "    \n",
    "    def validate_session_memory(self, response):\n",
    "        \"\"\"Check if agent maintains context within session\"\"\"\n",
    "        has_memory_content = len(response) > 100 and any(word in response.lower() for word in \n",
    "            ['previous', 'earlier', 'mentioned', 'discussed', 'before', 'already'])\n",
    "        return \"âœ… PASS\" if has_memory_content else \"âŒ FAIL\"\n",
    "    \n",
    "    def validate_cross_reference(self, response):\n",
    "        \"\"\"Check if agent can connect current query to previous context\"\"\"\n",
    "        # Look for connecting language\n",
    "        connecting_words = ['relate', 'connection', 'previous', 'earlier', 'discussed', \n",
    "                           'mentioned', 'context', 'based on', 'as we', 'as i']\n",
    "        has_connection = any(word in response.lower() for word in connecting_words)\n",
    "        has_substance = len(response) > 80\n",
    "        return \"âœ… PASS\" if (has_connection and has_substance) else \"âŒ FAIL\"\n",
    "    \n",
    "    def run_validation_summary(self, test_results):\n",
    "        print(\"ğŸ§ª COMPREHENSIVE TEST VALIDATION SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        total_tests = len(test_results)\n",
    "        passed_tests = sum(1 for result in test_results.values() if \"PASS\" in result)\n",
    "        pass_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0\n",
    "        \n",
    "        for test_name, result in test_results.items():\n",
    "            print(f\"{test_name}: {result}\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(f\"ğŸ“Š Overall Pass Rate: {passed_tests}/{total_tests} ({pass_rate:.1f}%)\")\n",
    "        \n",
    "        if pass_rate >= 80:\n",
    "            print(\"âœ… EXCELLENT: Memory integration working correctly!\")\n",
    "        elif pass_rate >= 60:\n",
    "            print(\"âš ï¸  GOOD: Most memory features working, some issues to investigate\")\n",
    "        else:\n",
    "            print(\"âŒ NEEDS ATTENTION: Memory integration has significant issues\")\n",
    "        \n",
    "        return pass_rate\n",
    "\n",
    "validator = TestValidator()\n",
    "print(\"âœ… Validation functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run all validation tests\ntest_results = {}\n\n# Test 1: Memory recall - can the agent recall what was discussed?\nresponse1 = await research_agent.run(\"What have we discussed so far in this session?\", memory=agentcore_memory)\ntest_results['Memory Recall'] = validator.validate_memory_recall(str(response1))\nprint(f\"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ 1 ã®é•·ã•: {len(str(response1))} æ–‡å­—\")\n\n# Test 2: Session memory - does the agent maintain context?\nresponse2 = await research_agent.run(\"What did we talk about earlier?\", memory=agentcore_memory)\ntest_results['Session Memory'] = validator.validate_session_memory(str(response2))\nprint(f\"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ 2 ã®é•·ã•: {len(str(response2))} æ–‡å­—\")\n\n# Test 3: Cross-reference capability - can it connect to previous context?\nresponse3 = await research_agent.run(\"How does this relate to what we discussed before?\", memory=agentcore_memory)\ntest_results['Cross Reference'] = validator.validate_cross_reference(str(response3))\nprint(f\"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ 3 ã®é•·ã•: {len(str(response3))} æ–‡å­—\")\n\n# Display results\nvalidator.run_validation_summary(test_results)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã¾ã¨ã‚\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ä»¥ä¸‹ã‚’å®Ÿæ¼”ã—ã¾ã—ãŸï¼š\n",
    "\n",
    "- **çŸ­æœŸãƒ¡ãƒ¢ãƒªçµ±åˆ**: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ã‚³ãƒ¼ãƒ—ã®æ°¸ç¶šåŒ–ã®ãŸã‚ã« AgentCore Memory ã‚’ LlamaIndex ã¨ä½¿ç”¨\n",
    "\n",
    "- **ç ”ç©¶å°‚ç”¨ãƒ„ãƒ¼ãƒ«**: è«–æ–‡è¦ç´„ã€ãƒˆãƒ”ãƒƒã‚¯è¿½è·¡ã€ç™ºè¦‹ã®ä¿å­˜\n",
    "\n",
    "- **æ–‡è„ˆçš„ãªä¼šè©±**: ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒè©³ç´°æƒ…å ±ã‚’è¨˜æ†¶\n",
    "\n",
    "- **ç›¸äº’å‚ç…§æ©Ÿèƒ½**: è¤‡æ•°ã®è«–æ–‡ã‚„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³é–“ã§ç™ºè¦‹ã‚’æ¥ç¶š\n",
    "\n",
    "- **ã‚»ãƒƒã‚·ãƒ§ãƒ³å¢ƒç•Œ**: ç•°ãªã‚‹ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³é–“ã§ã®ãƒ¡ãƒ¢ãƒªåˆ†é›¢\n",
    "\n",
    "- **å®Ÿè·µçš„ãªå¿œç”¨**: ç ”ç©¶åŠ©æˆé‡‘ç”³è«‹ã®ã‚µãƒãƒ¼ãƒˆã¨ç ”ç©¶ã®çµ±åˆ\n",
    "\n",
    "å­¦è¡“ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¯ã€çŸ­æœŸãƒ¡ãƒ¢ãƒªãŒå˜ä¸€ã®ç ”ç©¶ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§è‡ªç„¶ã§æ–‡è„ˆã«æ²¿ã£ãŸä¼šè©±ã‚’å¯èƒ½ã«ã—ãªãŒã‚‰ã€ç•°ãªã‚‹ä¼šè©±ã‚¹ãƒ¬ãƒƒãƒ‰é–“ã§æ˜ç¢ºãªå¢ƒç•Œã‚’ç¶­æŒã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ä½¿ç”¨ã—ãŸãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«ãƒ¡ãƒ¢ãƒªã‚’å‰Šé™¤ã—ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up AgentCore Memory resource\n",
    "try:\n",
    "    client.delete_memory(memory_id)\n",
    "    print(f\"âœ… Successfully deleted memory: {memory_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error deleting memory: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}