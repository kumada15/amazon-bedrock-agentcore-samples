{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# LangGraph と AgentCore Memory Tool（短期メモリ）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## はじめに\n",
    "このノートブックでは、LangGraph フレームワークを使用した会話型 AI エージェントに Amazon Bedrock AgentCore Memory 機能を統合する方法を紹介します。単一の会話セッション内での**短期メモリ**の保持に焦点を当て、明示的なコンテキスト管理なしで会話の早い段階の情報をエージェントが想起できるようにします。\n",
    "\n",
    "\n",
    "## チュートリアルの詳細\n",
    "\n",
    "| 情報               | 詳細                                                                            |\n",
    "|:-------------------|:--------------------------------------------------------------------------------|\n",
    "| チュートリアルタイプ | 短期会話メモリ                                                                  |\n",
    "| エージェントのユースケース | パーソナルフィットネス                                                          |\n",
    "| エージェントフレームワーク | LangGraph                                                                       |\n",
    "| LLM モデル          | Anthropic Claude Haiku 4.5                                                     |\n",
    "| チュートリアルコンポーネント | AgentCore 短期メモリ、LangGraph、ツール経由のメモリ取得                          |\n",
    "| 難易度              | 初級                                                                            |\n",
    "\n",
    "学習内容：\n",
    "- 短期メモリ用の AgentCore Memory を使用したメモリストアの作成\n",
    "- LangGraph を使用した構造化メモリワークフローを持つエージェントの作成\n",
    "- 会話履歴取得用のメモリツールの実装\n",
    "- 単一セッション内での文脈情報へのアクセスと活用\n",
    "- 効果的なメモリ想起による会話体験の向上\n",
    "\n",
    "\n",
    "### シナリオのコンテキスト\n",
    "\n",
    "この例では、会話全体を通じてワークアウトの詳細、フィットネス目標、身体的制限、エクササイズの好みを記憶できる「**パーソナルフィットネスコーチ**」を作成します。このアシスタントは、効果的な短期メモリ管理により、ユーザーが繰り返し情報を述べる必要なく、より自然でパーソナライズされたフィットネスコーチング体験を可能にする方法を実演します。\n",
    "\n",
    "\n",
    "## アーキテクチャ\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture.png\" width=\"65%\" />\n",
    "</div>\n",
    "\n",
    "## 前提条件\n",
    "\n",
    "- Python 3.10以上\n",
    "- 適切な権限を持つ AWS アカウント\n",
    "- AgentCore Memory の適切な権限を持つ AWS IAM ロール\n",
    "- Amazon Bedrock モデルへのアクセス\n",
    "\n",
    "環境のセットアップから始めましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## ステップ 1: 環境のセットアップ\n",
    "このノートブックを動作させるために必要なすべてのライブラリのインポートとクライアントの定義から始めましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Amazon Bedrock モデルと AgentCore に適切な権限を持つリージョンとロールを定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "region = os.getenv('AWS_REGION', 'us-west-2')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "logger = logging.getLogger(\"agentcore-memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 統合の仕組み\n",
    "\n",
    "LangGraph と AgentCore Memory の統合には以下が含まれます：\n",
    "\n",
    "1. AgentCore Memory を使用して会話を短期メモリに保存\n",
    "2. メモリ操作を管理する LangGraph の構造化ワークフロー\n",
    "\n",
    "このアプローチは、メモリ管理と推論を分離し、よりクリーンで保守性の高いエージェントアーキテクチャを実現します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## ステップ 2: メモリの作成\n",
    "このセクションでは、AgentCore Memory SDK を使用してメモリストアを作成します。このメモリストアにより、エージェントは会話から情報を保持できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MemoryClient(region_name=region)\n",
    "memory_name = \"FitnessCoach\"\n",
    "memory_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Creating Memory...\")\n",
    "    # Create the memory resource\n",
    "    memory = client.create_memory_and_wait(\n",
    "        name=memory_name,                       # This name is unique across all memories in this account\n",
    "        description=\"Fitness Coach Agent\",      # Human-readable description\n",
    "        strategies=[],                          # No memory strategies for short-term memory\n",
    "        event_expiry_days=7,                    # Memories expire after 7 days\n",
    "        max_wait=300,                           # Maximum time to wait for memory creation (5 minutes)\n",
    "        poll_interval=10                        # Check status every 10 seconds\n",
    "    )\n",
    "\n",
    "    # Extract and print the memory ID\n",
    "    memory_id = memory['id']\n",
    "    logger.info(f\"Memory created successfully with ID: {memory_id}\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ValidationException' and \"already exists\" in str(e):\n",
    "        # If memory already exists, retrieve its ID\n",
    "        memories = client.list_memories()\n",
    "        memory_id = next((m['id'] for m in memories if m['id'].startswith(memory_name)), None)\n",
    "        logger.info(f\"Memory already exists. Using existing memory ID: {memory_id}\")\n",
    "except Exception as e:\n",
    "    # Handle any errors during memory creation\n",
    "    logger.info(f\"❌ ERROR: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    # Cleanup on error - delete the memory if it was partially created\n",
    "    if memory_id:\n",
    "        try:\n",
    "            client.delete_memory_and_wait(memory_id=memory_id)\n",
    "            logger.info(f\"Cleaned up memory: {memory_id}\")\n",
    "        except Exception as cleanup_error:\n",
    "            logger.info(f\"Failed to clean up memory: {cleanup_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## ステップ 3: LangGraph エージェントの作成\n",
    "LangGraph でエージェントを作成するために必要なすべてのライブラリをインポートしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_aws import ChatBedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### LangGraph エージェントの実装\n",
    "\n",
    "メモリツールを組み込んで LangGraph でエージェントを作成しましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": "def create_agent(client, memory_id, actor_id, session_id):\n    \"\"\"Create and configure the LangGraph agent\"\"\"\n    \n    # Initialize your LLM (adjust model and parameters as needed)\n    llm = ChatBedrock(\n        model_id=\"global.anthropic.claude-haiku-4-5-20251001-v1:0\",  # or your preferred model\n        model_kwargs={\"temperature\": 0.1}\n    )\n    \n    @tool\n    def list_events():\n        \"\"\"Tool used when needed to retrieve recent information\"\"\" \n        events = client.list_events(\n                memory_id=memory_id,\n                actor_id=actor_id,\n                session_id=session_id,\n                max_results=10\n            )\n        return events\n        \n    \n    # Bind tools to the LLM\n    tools = [list_events]\n    llm_with_tools = llm.bind_tools(tools)\n    \n    # System message\n    system_message = \"\"\"You are the Personal Fitness Coach, a sophisticated fitness guidance assistant.\n                        PURPOSE:\n                        - Help users develop workout routines based on their fitness goals\n                        - Remember user's exercise preferences, limitations, and progress\n                        - Provide personalized fitness recommendations and training plans\n                        MEMORY CAPABILITIES:\n                        - You have access to recent events with the list_events tool\n                        \"\"\"\n    \n    # Define the chatbot node\n    def chatbot(state: MessagesState):\n        raw_messages = state[\"messages\"]\n    \n        # Remove any existing system messages to avoid duplicates or misplacement\n        non_system_messages = [msg for msg in raw_messages if not isinstance(msg, SystemMessage)]\n    \n        # Always ensure SystemMessage is first\n        messages = [SystemMessage(content=system_message)] + non_system_messages\n    \n        latest_user_message = next((msg.content for msg in reversed(messages) if isinstance(msg, HumanMessage)), None)\n    \n        # Get response from model with tools bound\n        response = llm_with_tools.invoke(messages)\n    \n        # Save conversation if applicable\n        if latest_user_message and response.content.strip():  # Check that response has content\n            conversation = [\n                (latest_user_message, \"USER\"),\n                (response.content, \"ASSISTANT\")\n            ]\n            \n            # Validate that all message texts are non-empty\n            if all(msg[0].strip() for msg in conversation):  # Ensure no empty messages\n                try:\n                    client.create_event(\n                        memory_id=memory_id,\n                        actor_id=actor_id,\n                        session_id=session_id,\n                        messages=conversation\n                    )\n                except Exception as e:\n                    print(f\"会話の保存エラー: {str(e)}\")\n        \n        # Append response to full message history\n        return {\"messages\": raw_messages + [response]}\n    \n    # Create the graph\n    graph_builder = StateGraph(MessagesState)\n    \n    # Add nodes\n    graph_builder.add_node(\"chatbot\", chatbot)\n    graph_builder.add_node(\"tools\", ToolNode(tools))\n    \n    # Add edges\n    graph_builder.add_conditional_edges(\n        \"chatbot\",\n        tools_condition,\n    )\n    graph_builder.add_edge(\"tools\", \"chatbot\")\n    \n    # Set entry point\n    graph_builder.set_entry_point(\"chatbot\")\n    \n    # Compile the graph\n    return graph_builder.compile()"
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### エージェント呼び出し用のラッパーの作成\n",
    "\n",
    "エージェントを呼び出すためのシンプルなラッパーを作成しましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def langgraph_bedrock(payload, agent):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    \n",
    "    # Create the input in the format expected by LangGraph\n",
    "    response = agent.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
    "    \n",
    "    # Extract the final message content\n",
    "    return response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## ステップ 4: LangGraph エージェントの実行\n",
    "AgentCore Memory 統合でエージェントを実行できるようになりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique actor and session IDs for this conversation\n",
    "actor_id = f\"user-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "session_id = f\"workout-{datetime.now().strftime('%Y%m%d%H%M%S')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent with AgentCore Memory integration\n",
    "agent = create_agent(client, memory_id, actor_id, session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### おめでとうございます！エージェントの準備ができました！\n",
    "\n",
    "### エージェントをテストしましょう\n",
    "\n",
    "エージェントと対話してメモリ機能をテストしましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": "response = langgraph_bedrock({\"prompt\": \"Hello! This is my first day, I need a workout routine.\"}, agent)\nprint(f\"エージェント: {response}\\n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": "response = langgraph_bedrock({\"prompt\": \"I want to build muscle, looking for a biceps routine. I have some lower back problems.\"}, agent)\nprint(f\"エージェント: {response}\\n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": "response = langgraph_bedrock({\"prompt\": \"Can you give me three exercises with number of reps?\"}, agent)\nprint(f\"エージェント: {response}\\n\")"
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### メモリ永続化のテスト\n",
    "\n",
    "AgentCore Memory 統合の威力を真に実証するために、新しいエージェントインスタンスを作成し、以前の会話を想起できるか確認しましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": "# Create a new agent instance (simulating a new session)\nnew_agent = create_agent(client, memory_id, actor_id, session_id)\n\n# Test if the new agent remembers our preferences\nresponse = langgraph_bedrock({\n    \"prompt\": \"Hello again! Can you remind me about my last workout session?\"\n}, new_agent)\n\nprint(\"新しいエージェントセッション:\\n\")\nprint(f\"エージェント: {response}\")"
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "このノートブックでは、以下を実演しました：\n",
    "\n",
    "1. AI エージェント用の AgentCore Memory リソースの作成方法\n",
    "2. メモリ統合を持つ LangGraph ワークフローの構築\n",
    "3. 会話履歴取得用のメモリツールの実装\n",
    "4. 必要に応じてインテリジェントにメモリを使用するエージェントの作成\n",
    "5. エージェントインスタンス間でのメモリ永続化のテスト\n",
    "\n",
    "この統合は、構造化されたワークフロー（LangGraph）と堅牢なメモリシステム（AgentCore Memory）を組み合わせることで、よりインテリジェントでコンテキストを意識した AI エージェントを作成する力を示しています。\n",
    "\n",
    "ここで実演したアプローチは、マルチエージェントシステム、抽出ストラテジーを使用した長期メモリ、会話コンテキストに基づく特殊なメモリ取得など、より複雑なユースケースに拡張できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## クリーンアップ\n",
    "このノートブックで使用したリソースをクリーンアップするためにメモリを削除しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.delete_memory_and_wait(memory_id = memory_id, max_wait = 300, poll_interval =10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}