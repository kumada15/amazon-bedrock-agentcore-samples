{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Memory を追加してエージェントをパーソナライズ\n",
    "\n",
    "### 概要\n",
    "\n",
    "Lab 1 では、単一ユーザーのローカルセッションで正常に動作するカスタマーサポートエージェントを構築しました。しかし、実際のカスタマーサポートでは、ローカル環境で実行される単一ユーザーを超えてスケールする必要があります。\n",
    "\n",
    "**本番環境でエージェントを実行する**場合、以下が必要になります：\n",
    "- **マルチユーザーサポート**: 数千の顧客を同時に処理\n",
    "- **永続的ストレージ**: セッションのライフサイクルを超えて会話を保存\n",
    "- **長期学習**: 顧客の好みや行動パターンを抽出\n",
    "- **クロスセッションの継続性**: 異なるインタラクション間で顧客を記憶\n",
    "\n",
    "**ワークショップの進捗:**\n",
    "- **Lab 1（完了）**: エージェントプロトタイプの作成 - 機能するカスタマーサポートエージェントを構築\n",
    "- **Lab 2（現在）**: Memory による強化 - 会話コンテキストとパーソナライゼーションを追加\n",
    "- **Lab 3**: Gateway と Identity によるスケーリング - エージェント間でツールを安全に共有\n",
    "- **Lab 4**: 本番環境へのデプロイ - AgentCore Runtime を使用してオブザーバビリティを実現\n",
    "- **Lab 5**: エージェントパフォーマンスの評価 - オンライン評価で品質を監視\n",
    "- **Lab 6**: ユーザーインターフェースの構築 - 顧客向けアプリケーションを作成\n",
    "\n",
    "このLabでは、あなたの金魚エージェント（数秒で会話を忘れる）をスマートでパーソナライズされたアシスタントに変換する、欠けている永続性と学習レイヤーを追加します。\n",
    "\n",
    "Memory は知性の重要な構成要素です。大規模言語モデル（LLM）には印象的な能力がありますが、会話間で永続的なMemoryがありません。[Amazon Bedrock AgentCore Memory](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory-getting-started.html) は、AI エージェントが時間を超えてコンテキストを維持し、重要な事実を記憶し、一貫したパーソナライズされた体験を提供できるようにするマネージドサービスを提供することで、この制限に対処します。\n",
    "\n",
    "AgentCore Memory は2つのレベルで動作します：\n",
    "- **短期Memory**: 単一のインタラクションまたは密接に関連するセッション内で継続性を提供する、即時の会話コンテキストとセッションベースの情報\n",
    "- **長期Memory**: 複数の会話にわたって抽出・保存される永続的な情報で、時間をかけてパーソナライズされた体験を可能にする事実、好み、要約を含む\n",
    "\n",
    "### Lab 2 のアーキテクチャ\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_lab2_memory.png\" width=\"75%\"/>\n",
    "</div>\n",
    "\n",
    "*永続的な短期および長期Memory機能を備えたマルチユーザーエージェント*\n",
    "\n",
    "### 前提条件\n",
    "\n",
    "* 適切な権限を持つ **AWS アカウント**\n",
    "* ローカルにインストールされた **Python 3.10+**\n",
    "* 認証情報が設定された **AWS CLI**\n",
    "* [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html) で有効化された **Anthropic Claude 3.7**\n",
    "* 次のセルでインストールする **Strands Agents** およびその他のライブラリ\n",
    "* AWS ワークショップアカウント内で作成される以下のリソース\n",
    "    - AWS Lambda 関数 \n",
    "    - AWS Lambda 実行 IAM ロール\n",
    "    - AgentCore Gateway IAM ロール\n",
    "    - AWS Lambda 関数が使用する DynamoDB テーブル\n",
    "    - Cognito User Pool と User Pool Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ステップ 1: ライブラリのインポート\n",
    "\n",
    "AgentCore Memory 用のライブラリをインポートしましょう。これには、AgentCore 機能を扱うための軽量なラッパーである [Amazon Bedrock AgentCore Python SDK](https://github.com/aws/bedrock-agentcore-sdk-python) を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from boto3.session import Session\n",
    "\n",
    "from bedrock_agentcore_starter_toolkit.operations.memory.manager import MemoryManager\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from bedrock_agentcore.memory.constants import StrategyType\n",
    "\n",
    "from lab_helpers.utils import put_ssm_parameter\n",
    "\n",
    "boto_session = Session()\n",
    "REGION = boto_session.region_name\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ステップ 2: Bedrock AgentCore Memory リソースの作成\n",
    "\n",
    "Amazon Bedrock AgentCore Memory は、AI エージェントに永続的なMemory機能を提供するフルマネージドサービスです。\n",
    "\n",
    "#### AgentCore Memory の概念:\n",
    "\n",
    "1. **短期Memory（STM）**: セッション内で会話コンテキストを即座に保存\n",
    "2. **長期Memory（LTM）**: STM を非同期で処理し、意味のあるパターン、好み、事実を抽出\n",
    "3. **Memory ストラテジー**: 情報の抽出と整理のための異なるアプローチ：\n",
    "   - **USER_PREFERENCE**: 顧客の好み、行動、パターンを学習\n",
    "   - **SEMANTIC**: ベクトル埋め込みを使用して事実情報を保存し、類似性検索を実現\n",
    "4. **名前空間**: 顧客とコンテキストタイプによるMemoryの論理的なグループ化。以下の2つの名前空間を作成します：\n",
    "- `support/customer/{actorId}/preferences`: 顧客の好みと行動パターン\n",
    "- `support/customer/{actorId}/semantic`: 事実情報と会話履歴\n",
    "\n",
    "この構造により、各顧客の情報が分離され、簡単に取得できるマルチテナントMemoryが実現します。\n",
    "\n",
    "#### Memory 作成プロセス:\n",
    "\n",
    "Memory リソースの作成には、基盤となるインフラストラクチャ（ベクトルデータベース、処理パイプラインなど）のプロビジョニングが含まれます。AWS がバックグラウンドでマネージドサービスをセットアップするため、通常2〜3分かかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_name = \"CustomerSupportMemory\"\n",
    "\n",
    "memory_manager = MemoryManager(region_name=REGION)\n",
    "memory = memory_manager.get_or_create_memory(\n",
    "    name=memory_name,\n",
    "    strategies=[\n",
    "                {\n",
    "                    StrategyType.USER_PREFERENCE.value: {\n",
    "                        \"name\": \"CustomerPreferences\",\n",
    "                        \"description\": \"Captures customer preferences and behavior\",\n",
    "                        \"namespaces\": [\"support/customer/{actorId}/preferences\"],\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    StrategyType.SEMANTIC.value: {\n",
    "                        \"name\": \"CustomerSupportSemantic\",\n",
    "                        \"description\": \"Stores facts from conversations\",\n",
    "                        \"namespaces\": [\"support/customer/{actorId}/semantic\"],\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    ")\n",
    "memory_id = memory[\"id\"]\n",
    "put_ssm_parameter(\"/app/customersupport/agentcore/memory_id\", memory_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if memory_id:\n",
    "    print(\"✅ AgentCore Memory が正常に作成されました！\")\n",
    "    print(f\"メモリ ID: {memory_id}\")\n",
    "else:\n",
    "    print(\"メモリリソースが作成されませんでした。再試行してください！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ 3: 過去の顧客インタラクションをシード\n",
    "\n",
    "**なぜMemoryをシードするのか？**\n",
    "\n",
    "本番環境では、エージェントは顧客とのインタラクションを通じて自然にMemoryを蓄積します。しかし、このLabでは、実際の会話を待たずに長期Memory（LTM）がどのように機能するかを示すために、過去の会話をシードしています。\n",
    "\n",
    "**Memory処理の仕組み:**\n",
    "1. `create_event` はインタラクションを**短期Memory**（STM）に即座に保存\n",
    "2. STM は**長期Memory**ストラテジーによって非同期で処理される\n",
    "3. LTM は将来の取得のためにパターン、好み、事実を抽出\n",
    "\n",
    "実際の動作を確認するために、いくつかの顧客履歴をシードしましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab_helpers.lab2_memory import ACTOR_ID\n",
    "\n",
    "\n",
    "# Seed with previous customer interactions\n",
    "previous_interactions = [\n",
    "    (\"I'm having issues with my MacBook Pro overheating during video editing.\", \"USER\"),\n",
    "    (\n",
    "        \"I can help with that thermal issue. For video editing workloads, let's check your Activity Monitor and adjust performance settings. Your MacBook Pro order #MB-78432 is still under warranty.\",\n",
    "        \"ASSISTANT\",\n",
    "    ),\n",
    "    (\n",
    "        \"What's the return policy on gaming headphones? I need low latency for competitive FPS games\",\n",
    "        \"USER\",\n",
    "    ),\n",
    "    (\n",
    "        \"For gaming headphones, you have 30 days to return. Since you're into competitive FPS, I'd recommend checking the audio latency specs - most gaming models have <40ms latency.\",\n",
    "        \"ASSISTANT\",\n",
    "    ),\n",
    "    (\n",
    "        \"I need a laptop under $1200 for programming. Prefer 16GB RAM minimum and good Linux compatibility. I like ThinkPad models.\",\n",
    "        \"USER\",\n",
    "    ),\n",
    "    (\n",
    "        \"Perfect! For development work, I'd suggest looking at our ThinkPad E series or Dell XPS models. Both have excellent Linux support and 16GB RAM options within your budget.\",\n",
    "        \"ASSISTANT\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Save previous interactions\n",
    "if memory_id:\n",
    "    try:\n",
    "        memory_client = MemoryClient(region_name=REGION)\n",
    "        memory_client.create_event(\n",
    "            memory_id=memory_id,\n",
    "            actor_id=ACTOR_ID,\n",
    "            session_id=\"previous_session\",\n",
    "            messages=previous_interactions,\n",
    "        )\n",
    "        print(\"✅ 顧客履歴のシードが正常に完了しました\")\n",
    "        print(\"📝 インタラクションが短期メモリに保存されました\")\n",
    "        print(\"⏳ 長期メモリの処理が自動的に開始されます...\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 履歴のシード中にエラー: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory処理の理解\n",
    "\n",
    "`create_event` でイベントを作成した後、AgentCore Memory は2段階でデータを処理します：\n",
    "\n",
    "1. **即時**: メッセージが短期Memory（STM）に保存される\n",
    "2. **非同期**: STM が長期Memory（LTM）ストラテジーに処理される\n",
    "\n",
    "LTM の処理には通常20〜30秒かかります。システムが以下を行うためです：\n",
    "- 会話パターンの分析\n",
    "- 顧客の好みと行動の抽出\n",
    "- 事実情報のセマンティック埋め込みの作成\n",
    "- 効率的な取得のための名前空間によるMemoryの整理\n",
    "\n",
    "長期Memory処理が完了したかどうかを、顧客の好みを取得して確認しましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Wait for Long-Term Memory processing to complete\n",
    "print(\"🔍 処理済みの長期メモリを確認中...\")\n",
    "retries = 0\n",
    "max_retries = 6  # 1 minute wait\n",
    "\n",
    "while retries < max_retries:\n",
    "    memories = memory_client.retrieve_memories(\n",
    "        memory_id=memory_id,\n",
    "        namespace=f\"support/customer/{ACTOR_ID}/preferences\",\n",
    "        query=\"can you summarize the support issue\",\n",
    "    )\n",
    "\n",
    "    if memories:\n",
    "        print(\n",
    "            f\"✅ {retries * 10} 秒後に {len(memories)} 件の好みメモリが見つかりました！\"\n",
    "        )\n",
    "        break\n",
    "\n",
    "    retries += 1\n",
    "    if retries < max_retries:\n",
    "        print(\n",
    "            f\"⏳ 処理中... あと10秒待機します（試行 {retries}/{max_retries}）\"\n",
    "        )\n",
    "        time.sleep(10)\n",
    "    else:\n",
    "        print(\n",
    "            \"⚠️ メモリ処理に予想以上の時間がかかっています。過負荷の可能性があります...\"\n",
    "        )\n",
    "        break\n",
    "\n",
    "print(\n",
    "    \"🎯 AgentCore Memory がシードされた会話から自動的に抽出した顧客の好み:\"\n",
    ")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, memory in enumerate(memories, 1):\n",
    "    if isinstance(memory, dict):\n",
    "        content = memory.get(\"content\", {})\n",
    "        if isinstance(content, dict):\n",
    "            text = content.get(\"text\", \"\")\n",
    "            print(f\"  {i}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### セマンティックMemoryの探索\n",
    "\n",
    "セマンティックMemoryは、ベクトル埋め込みを使用して会話からの事実情報を保存します。これにより、関連する事実とコンテキストの類似性ベースの取得が可能になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Retrieve semantic memories (factual information)\n",
    "while True:\n",
    "    semantic_memories = memory_client.retrieve_memories(\n",
    "        memory_id=memory_id,\n",
    "        namespace=f\"support/customer/{ACTOR_ID}/semantic\",\n",
    "        query=\"information on the technical support issue\",\n",
    "    )\n",
    "    print(\"🧠 AgentCore Memory が会話から特定した事実情報:\")\n",
    "    print(\"=\" * 80)\n",
    "    if semantic_memories:\n",
    "        break\n",
    "    time.sleep(10)\n",
    "for i, memory in enumerate(semantic_memories, 1):\n",
    "    if isinstance(memory, dict):\n",
    "        content = memory.get(\"content\", {})\n",
    "        if isinstance(content, dict):\n",
    "            text = content.get(\"text\", \"\")\n",
    "            print(f\"  {i}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ 4: Memory を備えたカスタマーサポートエージェントの作成\n",
    "\n",
    "次に、Lab 1 と同様にカスタマーサポートエージェントを実装しますが、今回はエージェントのセッションマネージャーに AgentCoreMemoryConfig を追加します。これにより、エージェントは新しいイベントを作成し、Memoryを取得できるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from bedrock_agentcore.memory.integrations.strands.config import AgentCoreMemoryConfig, RetrievalConfig\n",
    "from bedrock_agentcore.memory.integrations.strands.session_manager import AgentCoreMemorySessionManager\n",
    "\n",
    "from lab_helpers.lab1_strands_agent import (\n",
    "    SYSTEM_PROMPT,\n",
    "    get_return_policy,\n",
    "    web_search,\n",
    "    get_product_info,\n",
    "    get_technical_support,\n",
    "    MODEL_ID,\n",
    ")\n",
    "\n",
    "session_id = uuid.uuid4()\n",
    "\n",
    "memory_config = AgentCoreMemoryConfig(\n",
    "        memory_id=memory_id,\n",
    "        session_id=str(session_id),\n",
    "        actor_id=ACTOR_ID,\n",
    "        retrieval_config={\n",
    "            \"support/customer/{actorId}/semantic\": RetrievalConfig(top_k=3, relevance_score=0.2),\n",
    "            \"support/customer/{actorId}/preferences\": RetrievalConfig(top_k=3, relevance_score=0.2)\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Initialize the Bedrock model (Anthropic Claude 3.7 Sonnet)\n",
    "model = BedrockModel(model_id=MODEL_ID, region_name=REGION)\n",
    "\n",
    "# Create the customer support agent with all 5 tools\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    session_manager=AgentCoreMemorySessionManager(memory_config, REGION),\n",
    "    tools=[\n",
    "        get_product_info,  # Tool 1: Simple product information lookup\n",
    "        get_return_policy,  # Tool 2: Simple return policy lookup\n",
    "        web_search,\n",
    "        get_technical_support,\n",
    "    ],\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ 5: パーソナライズされたエージェントのテスト\n",
    "\n",
    "Memory強化されたエージェントをテストしましょう！エージェントが顧客の過去の好みを使用してパーソナライズされた推奨事項を提供する様子を観察してください。\n",
    "\n",
    "エージェントは自動的に以下を行います：\n",
    "1. Memoryから関連する顧客コンテキストを取得\n",
    "2. そのコンテキストを使用してレスポンスをパーソナライズ\n",
    "3. この新しいインタラクションを将来の使用のために保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎧 顧客メモリを使用してヘッドフォンの推奨をテスト中...\\n\\n\")\n",
    "response1 = agent(\"Which headphones would you recommend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n💻 ノートPC の好みの記憶をテスト中...\\n\\n\")\n",
    "response2 = agent(\"What is my preferred laptop brand and requirements?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エージェントが以下を記憶していることに注目してください：\n",
    "- ゲームに関する好み（低遅延ヘッドフォン）\n",
    "- ノートPCに関する好み（ThinkPad、16GB RAM、Linux互換性）\n",
    "- 予算の制約（ノートPCは1200ドル）\n",
    "- 以前の技術的な問題（MacBookの過熱）\n",
    "\n",
    "これが AgentCore Memory の力です - 永続的でパーソナライズされた顧客体験！\n",
    "\n",
    "## おめでとうございます！\n",
    "\n",
    "**Lab 2: カスタマーサポートエージェントへの Memory の追加**を正常に完了しました！\n",
    "\n",
    "### 達成したこと:\n",
    "\n",
    "- Amazon Bedrock AgentCore Memory を使用してサーバーレスのマネージドMemoryを作成\n",
    "- ユーザー設定とセマンティック（事実）情報を保存する長期Memoryを実装\n",
    "- Strands Agents が提供するセッション管理メカニズムを使用して AgentCore Memory をカスタマーサポートエージェントと統合\n",
    "\n",
    "##### 次のステップ [Lab 3 - Gateway と Identity によるスケーリング →](lab-03-agentcore-gateway.ipynb)\n",
    "\n",
    "## リソース\n",
    "- [Amazon Bedrock Agent Core Memory](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory.html)\n",
    "- [Amazon Bedrock AgentCore Memory 詳細ブログ](https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-agentcore-memory-building-context-aware-agents/)\n",
    "- [Strands Agent SDK - AgentCore Memory サンプル](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/strands-sdk-memory.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
