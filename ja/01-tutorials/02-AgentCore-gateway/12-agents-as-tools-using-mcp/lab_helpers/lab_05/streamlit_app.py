"""
SRE AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - Streamlit ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚µãƒãƒ¼ãƒˆä»˜ãã® Strands ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€‚
ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã«æŒã¤è‡ªå·±å®Œçµå‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚
"""

import streamlit as st
import json
from typing import Generator

from strands import Agent
from strands.models import BedrockModel
from strands.tools.mcp.mcp_client import MCPClient
from mcp.client.streamable_http import streamablehttp_client
import boto3


# ============================================================================
# MCP CLIENT SETUP FUNCTIONS (inlined from mcp_client_setup.py)
# ============================================================================

def load_gateway_config():
    """
    gateway_config.json ã‹ã‚‰ Gateway è¨­å®šã‚’èª­ã¿è¾¼ã‚€

    Returns:
        dict: Gateway è¨­å®š
    """
    with open("gateway_config.json", "r") as f:
        return json.load(f)


def get_access_token(config):
    """
    boto3 ã®ç›´æ¥å‘¼ã³å‡ºã—ã‚’ä½¿ç”¨ã—ã¦ Cognito ã‹ã‚‰ OAuth ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã™ã‚‹

    Args:
        config: Gateway è¨­å®š Dict

    Returns:
        str: ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³
    """
    client_info = config["client_info"]
    cognito = boto3.client('cognito-idp', region_name=config["region"])
    
    try:
        response = cognito.initiate_auth(
            ClientId=client_info["client_id"],
            AuthFlow='USER_PASSWORD_AUTH',
            AuthParameters={
                'USERNAME': client_info["username"],
                'PASSWORD': client_info["password"]
            }
        )
        return response['AuthenticationResult']['AccessToken']
    except Exception as e:
        raise Exception(f"Failed to get access token: {str(e)}")


def create_mcp_client(gateway_url, access_token):
    """
    OAuth èªè¨¼ä»˜ãã® MCP ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹

    Args:
        gateway_url: Gateway MCP ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ URL
        access_token: Cognito ã‹ã‚‰ã® OAuth ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³

    Returns:
        MCPClient: è¨­å®šæ¸ˆã¿ã® MCP ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
    """
    return MCPClient(
        lambda: streamablehttp_client(
            gateway_url,
            headers={"Authorization": f"Bearer {access_token}"}
        )
    )


def get_all_tools(mcp_client):
    """
    ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒãƒ¼ãƒˆä»˜ãã§ Gateway ã‹ã‚‰ã™ã¹ã¦ã®ãƒ„ãƒ¼ãƒ«ã‚’å–å¾—ã™ã‚‹

    Args:
        mcp_client: MCPClient ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

    Returns:
        list: åˆ©ç”¨å¯èƒ½ãªã™ã¹ã¦ã® MCP ãƒ„ãƒ¼ãƒ«
    """
    tools = []
    pagination_token = None
    
    while True:
        result = mcp_client.list_tools_sync(pagination_token=pagination_token)
        tools.extend(result)
        
        if result.pagination_token is None:
            break
        pagination_token = result.pagination_token
    
    return tools


# ============================================================================
# SUPERVISOR AGENT FUNCTIONS (inlined from supervisor_agent.py)
# ============================================================================

def create_supervisor_agent(model_id, tools, region="us-west-2"):
    """
    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æœ‰åŠ¹ã® Strands ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹

    Args:
        model_id: Bedrock ãƒ¢ãƒ‡ãƒ«è­˜åˆ¥å­ã¾ãŸã¯æ¨è«–ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« ARN
        tools: MCP ãƒ„ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆ
        region: AWS ãƒªãƒ¼ã‚¸ãƒ§ãƒ³

    Returns:
        Agent: è¨­å®šæ¸ˆã¿ã® Strands ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    """
    # Use cross-region inference profile for Claude 3.7 Sonnet
    inference_profile = "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
    
    model = BedrockModel(
        model_id=inference_profile,
        streaming=True,  # Enable streaming
    )
    
    system_prompt = """
        # Supervisor Agent ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

ã‚ãªãŸã¯3ã¤ã®å°‚é–€ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã€å®Œå…¨ãªã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ SRE Supervisor Agent ã§ã™ã€‚

## ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ„ãƒ¼ãƒ«

### 1. Diagnostic Agent
- AWS ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚’åˆ†æã—ã¦æ ¹æœ¬åŸå› ã‚’ç‰¹å®š
- è©³ç´°ãªè¨ºæ–­æƒ…å ±ã‚’æä¾›
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨è¨­å®šå•é¡Œã‚’ç‰¹å®š

### 2. Remediation Agent
- ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã®ä¿®æ­£ã¨ä¿®å¾©ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
- æ‰¿èªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§æ˜¯æ­£ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè£…
- å®‰å…¨ãªå®Ÿè¡Œã®ãŸã‚ã« AgentCore Code Interpreter ã‚’ä½¿ç”¨

### 3. Prevention Agent
- AWS ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¨äºˆé˜²æªç½®ã‚’èª¿æŸ»
- äºˆé˜²çš„ãªæ¨å¥¨ã‚’æä¾›
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”¨ã« AgentCore Browser ã‚’ä½¿ç”¨

## ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã—ã¦:
1. **è¨ºæ–­**: è¨ºæ–­ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦å•é¡Œã‚’ç‰¹å®š
2. **ä¿®å¾©**: æ‰¿èªã•ã‚ŒãŸä¿®å¾©æ‰‹é †ã‚’å®Ÿè¡Œ
3. **äºˆé˜²**: äºˆé˜²çš„ãªæ¨å¥¨ã‚’æä¾›
4. å•é¡ŒãŒå­˜åœ¨ã—ãªã„å ´åˆã€ä»–ã®å•é¡Œã‚’æ¢ã™ã“ã¨ã«é€¸è„±ã—ãªã„

## ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ 

å¸¸ã«æä¾›ã™ã‚‹:
- **æ¦‚è¦**: å•é¡Œã®ç°¡æ½”ãªæ¦‚è¦
- **è¨ºæ–­çµæœ**: ç™ºè¦‹ã•ã‚ŒãŸå†…å®¹
- **ä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: ä¿®æ­£ã•ã‚ŒãŸå†…å®¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰
- **äºˆé˜²æ¨å¥¨**: ä»Šå¾Œã®å•é¡Œã‚’å›é¿ã™ã‚‹æ–¹æ³•

## ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³

- è¨ºæ–­ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦å•é¡Œã‚’åˆ†æãƒ»ç‰¹å®š
- ä¿®æ­£ã«ã¯ä¿®å¾©ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ï¼ˆæ‰¿èªãŒå¿…è¦ï¼‰
- ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¨èª¿æŸ»ã«ã¯äºˆé˜²ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨
- åŒ…æ‹¬çš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã§é€£æº

## å®‰å…¨ãƒ«ãƒ¼ãƒ«

- å¤‰æ›´ã‚’åŠ ãˆã‚‹å‰ã«å¿…ãšç’°å¢ƒã‚’æ¤œè¨¼
- ä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ã¯æ˜ç¤ºçš„ãªæ‰¿èªã‚’è¦æ±‚
- å®Ÿè¡Œã•ã‚ŒãŸã™ã¹ã¦ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦æ˜ç¢ºãªèª¬æ˜ã‚’æä¾›
- ä¿®å¾©æ‰‹é †ã®ãƒªã‚¹ã‚¯è©•ä¾¡ã‚’å«ã‚ã‚‹
"""
    
    return Agent(
        model=model,
        tools=tools,
        system_prompt=system_prompt
    )


# Page configuration
st.set_page_config(
    page_title="SRE AI Agent",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .status-box {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .status-success {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
    }
    .status-error {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
    }
    .status-info {
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        color: #0c5460;
    }
    .thinking-indicator {
        font-style: italic;
        color: #6c757d;
        padding: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)


def initialize_agent():
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ã™ã‚‹"""
    if 'agent_initialized' not in st.session_state:
        with st.spinner("ğŸ”§ Initializing SRE AI Agent..."):
            try:
                # Load configuration
                config = load_gateway_config()
                st.session_state.config = config
                
                # Get OAuth token
                access_token = get_access_token(config)
                st.session_state.access_token = access_token
                
                # Extract email from JWT token
                import base64
                try:
                    # Decode JWT payload (second part)
                    payload = access_token.split('.')[1]
                    # Add padding if needed
                    payload += '=' * (4 - len(payload) % 4)
                    decoded = base64.b64decode(payload)
                    token_data = json.loads(decoded)
                    st.session_state.user_email = token_data.get('email', token_data.get('username', 'Unknown'))
                except Exception as jwt_error:
                    st.session_state.user_email = config['client_info']['username']
                
                # Create MCP client
                try:
                    mcp_client = create_mcp_client(config['gateway_url'], access_token)
                    st.session_state.mcp_client = mcp_client
                    
                    # Initialize MCP client context
                    st.session_state.mcp_client.__enter__()
                    
                    # Get tools
                    tools = get_all_tools(mcp_client)
                    st.session_state.tools = tools
                except Exception as mcp_error:
                    raise Exception(f"MCP client initialization failed: {str(mcp_error)}")
                
                # Create agent
                model_id = "anthropic.claude-3-7-sonnet-20250219-v1:0"
                agent = create_supervisor_agent(model_id, tools, config['region'])
                st.session_state.agent = agent
                
                st.session_state.agent_initialized = True
                st.session_state.initialization_error = None
                
            except FileNotFoundError:
                st.session_state.agent_initialized = False
                st.session_state.initialization_error = "gateway_config.json not found. Please run Section 9.1 in the notebook first."
            except Exception as e:
                st.session_state.agent_initialized = False
                import traceback
                st.session_state.initialization_error = f"{str(e)}\n\nDetails:\n{traceback.format_exc()}"


def stream_agent_response(prompt: str, message_placeholder) -> str:
    """
    ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã™ã‚‹

    Args:
        prompt: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        message_placeholder: è¡¨ç¤ºæ›´æ–°ç”¨ã® Streamlit ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼

    Returns:
        str: å®Œå…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ
    """
    agent = st.session_state.agent
    response_data = {
        "text": "", 
        "last_update": 0, 
        "tools_shown": set(), 
        "in_tool_construction": False,
        "tool_start_times": {}
    }
    
    def streaming_callback(**kwargs):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¤ãƒ™ãƒ³ãƒˆç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ"""
        import time
        
        # Handle text streaming
        if "data" in kwargs:
            data = kwargs["data"]
            
            # Detect if we're in tool input construction phase
            if data.strip().startswith('{') or data.strip().startswith('"'):
                response_data["in_tool_construction"] = True
                return  # Skip JSON construction
            elif response_data["in_tool_construction"] and not data.strip().endswith('}'):
                return  # Still in JSON construction
            else:
                response_data["in_tool_construction"] = False
                response_data["text"] += data
                response_data["last_update"] = time.time()
        
        # Handle tool usage - show when tool execution starts (has toolUseId)
        elif "current_tool_use" in kwargs:
            tool_use = kwargs["current_tool_use"]
            tool_id = tool_use.get("toolUseId")
            tool_name = tool_use.get("name")
            
            # Only show when we have both ID and name (tool is starting execution)
            if tool_id and tool_name and tool_id not in response_data["tools_shown"]:
                response_data["tools_shown"].add(tool_id)
                response_data["tool_start_times"][tool_id] = time.time()
                tool_text = f"\n\nğŸ”§ **Using tool:** `{tool_name}`\n\n"
                response_data["text"] += tool_text
                response_data["last_update"] = time.time()
                response_data["in_tool_construction"] = False
        
        # Handle tool completion (when message is created after tool use)
        elif "message" in kwargs:
            message = kwargs["message"]
            if message.get("role") == "user":
                # Check for tool results in the message
                content = message.get("content", [])
                for item in content:
                    if isinstance(item, dict) and item.get("type") == "tool_result":
                        tool_id = item.get("tool_use_id")
                        if tool_id in response_data["tool_start_times"]:
                            elapsed = time.time() - response_data["tool_start_times"][tool_id]
                            timing_text = f"â±ï¸ *Completed in {elapsed:.2f}s*\n\n"
                            response_data["text"] += timing_text
                            response_data["last_update"] = time.time()
                            del response_data["tool_start_times"][tool_id]
    
    try:
        import time
        import threading
        
        # Start agent in background thread
        agent_thread = threading.Thread(
            target=lambda: agent(prompt, callback_handler=streaming_callback)
        )
        agent_thread.start()
        
        # Update UI from main thread while agent runs
        while agent_thread.is_alive():
            if response_data["text"]:
                message_placeholder.markdown(response_data["text"] + "â–Œ")
            time.sleep(0.1)
        
        # Wait for thread to complete
        agent_thread.join()
        
        # Display final response without cursor
        final_response = response_data["text"]
        message_placeholder.markdown(final_response)
        return final_response
        
    except Exception as e:
        import traceback
        error_msg = f"\n\nâŒ Error: {str(e)}\n```\n{traceback.format_exc()}\n```"
        message_placeholder.markdown(error_msg)
        return error_msg


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°"""
    
    # Header
    st.markdown('<div class="main-header">ğŸ¤– SRE AI Agent</div>', unsafe_allow_html=True)
    st.markdown("---")
    
    # Initialize agent
    initialize_agent()
    
    # Sidebar
    with st.sidebar:
        st.header("â„¹ï¸ About")
        st.markdown("""
        **SRE AI Agent** is a Strands-based supervisor agent that orchestrates three specialized agents.
        
        **Features:**
        - ğŸ” Diagnostics Agent - Analyzes logs and metrics
        - ğŸ”§ Remediation Agent - Executes fixes with Code Interpreter
        - ğŸ›¡ï¸ Prevention Agent - Researches best practices with Browser
        - ğŸ”„ Real-time streaming responses
        - ğŸ” OAuth authentication via Cognito
        """)
        
        st.markdown("---")
        
        # Status information
        if st.session_state.get('agent_initialized'):
            st.markdown('<div class="status-box status-success">âœ… Agent Ready</div>', unsafe_allow_html=True)
            
            config = st.session_state.config
            st.markdown("**Configuration:**")
            st.text(f"Gateway: {config['gateway_id']}")
            st.text(f"Region: {config['region']}")
            
            # Show logged in user from JWT token
            st.markdown("**Logged in as:**")
            user_email = st.session_state.get('user_email', 'Unknown')
            st.text(f"ğŸ‘¤ {user_email}")
            
            if 'tools' in st.session_state:
                st.markdown(f"**Tools Available:** {len(st.session_state.tools)}")
                for tool in st.session_state.tools:
                    st.text(f"  â€¢ {tool.tool_name}")
        else:
            error = st.session_state.get('initialization_error', 'Unknown error')
            st.markdown(f'<div class="status-box status-error">âŒ Initialization Failed<br/>{error}</div>', unsafe_allow_html=True)
            
            if "gateway_config.json not found" in error:
                st.info("ğŸ’¡ Run `python setup_gateway.py` to create the Gateway infrastructure.")
        
        st.markdown("---")
        
        # Clear chat button
        if st.button("ğŸ—‘ï¸ Clear Chat History"):
            st.session_state.messages = []
            st.rerun()
    
    # Initialize chat history
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    # Display chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # Chat input
    if st.session_state.get('agent_initialized'):
        if prompt := st.chat_input("Ask about your infrastructure (e.g., 'What issues do you see in the CRM application?')..."):
            # Add user message to chat history
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # Display user message
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # Display assistant response with streaming
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                
                # Stream the response using callback handler
                with st.spinner("ğŸ¤” Thinking..."):
                    full_response = stream_agent_response(prompt, message_placeholder)
            
            # Add assistant response to chat history
            st.session_state.messages.append({"role": "assistant", "content": full_response})
    else:
        st.error("âš ï¸ Agent not initialized. Please check the sidebar for details.")
        st.info("Make sure you have run `python setup_gateway.py` to set up the Gateway infrastructure.")


if __name__ == "__main__":
    main()