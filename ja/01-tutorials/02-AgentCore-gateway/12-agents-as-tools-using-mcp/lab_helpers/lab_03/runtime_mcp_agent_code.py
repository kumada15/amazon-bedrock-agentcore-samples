#!/usr/bin/env python3
"""
Lab 3: Strands ä¿®å¾©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆFastMCP ä½¿ç”¨ï¼‰- AgentCore Runtime ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ
Gateway ã‹ã‚‰ Runtime ã¸ã®é€šä¿¡ã« MCP ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’å®Ÿè£…ã™ã‚‹ãŸã‚ã« FastMCP ã‚’ä½¿ç”¨

é‡ç‚¹é …ç›®:
- FastMCP ã«ã‚ˆã‚‹ MCP ãƒ—ãƒ­ãƒˆã‚³ãƒ«å®Ÿè£…
- æ‰¿èªã‚²ãƒ¼ãƒˆä»˜ãã®ã‚»ã‚­ãƒ¥ã‚¢ãªä¿®å¾©ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- Code Interpreter ã‚’ä½¿ç”¨ã—ãŸã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£è‡ªå‹•åŒ–
- 2æ®µéšãƒ—ãƒ­ã‚»ã‚¹: è¨ˆç”» â†’ æ‰¿èª â†’ å®Ÿè¡Œ
- ãƒªã‚¹ã‚¯è©•ä¾¡ã¨å½±éŸ¿åˆ†æ

ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹å®Ÿè¡Œã®ãŸã‚ã« AgentCore Runtime ã«ãƒ‡ãƒ—ãƒ­ã‚¤
"""

import os
import json
import boto3
import logging
import uuid
from datetime import datetime, timezone
from typing import Dict, List, Optional, Literal
import time

# Official MCP package for AgentCore Runtime compatibility
from mcp.server.fastmcp import FastMCP

# Strands framework
from strands import Agent
from strands.models import BedrockModel
from strands.tools import tool

# Bypass tool consent for AgentCore deployment
os.environ["BYPASS_TOOL_CONSENT"] = "true"

# Configure logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("bedrock_agentcore.app")

# Auto-detect AWS region
def get_aws_region():
    """ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ boto3 ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ AWS ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è‡ªå‹•æ¤œå‡º"""
    # Try environment variable first
    region = os.environ.get('AWS_REGION')
    if region:
        return region
    
    # Try boto3 session default region
    try:
        session = boto3.Session()
        region = session.region_name
        if region:
            return region
    except Exception:
        pass
    
    # Fallback to us-east-1
    return "us-west-2"

# Environment variables (set by AgentCore Runtime)
AWS_REGION = get_aws_region()
logger.info(f"ğŸŒ Using AWS Region: {AWS_REGION}")
MODEL_ID = os.environ.get('MODEL_ID', 'us.anthropic.claude-sonnet-4-20250514-v1:0')
AWS_ACCESS_KEY_ID = 'none'
AWS_SECRET_ACCESS_KEY = 'none'

# Treat 'none' string as None for IAM role usage
if AWS_ACCESS_KEY_ID.lower() == 'none':
    AWS_ACCESS_KEY_ID = None
if AWS_SECRET_ACCESS_KEY.lower() == 'none':
    AWS_SECRET_ACCESS_KEY = None

# Initialize FastMCP server for AgentCore Runtime
# host="0.0.0.0" - Listens on all interfaces as required by AgentCore
# stateless_http=True - Enables session isolation for enterprise security
mcp = FastMCP("SRE Remediation Agent", host="0.0.0.0", stateless_http=True)

# Global variables for Code Interpreter
agentcore_code_interpreter = None
CODE_INTERPRETER_AVAILABLE = False

def get_boto3_client(service_name: str, region: str = None):
    """ç’°å¢ƒå¤‰æ•°ã®èªè¨¼æƒ…å ±ã‚’ä½¿ç”¨ã—ã¦ boto3 ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ"""
    #region = region or AWS_REGION
    region = get_aws_region()
    
    if AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY:
        return boto3.client(
            service_name,
            region_name=region,
            aws_access_key_id=AWS_ACCESS_KEY_ID,
            aws_secret_access_key=AWS_SECRET_ACCESS_KEY
        )
    else:
        return boto3.client(service_name, region_name=region)

def get_boto3_session():
    """ç’°å¢ƒå¤‰æ•°ã®èªè¨¼æƒ…å ±ã‚’ä½¿ç”¨ã—ã¦ boto3 ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
    if AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY:
        return boto3.Session(
            aws_access_key_id=AWS_ACCESS_KEY_ID,
            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
            region_name=AWS_REGION
        )
    else:
        return boto3.Session(region_name=AWS_REGION)

def get_code_interpreter_from_ssm():
    """SSM Parameter Store ã‹ã‚‰ Code Interpreter ã®è©³ç´°ã‚’å–å¾—"""
    ssm = get_boto3_client('ssm')
    WORKSHOP_NAME = 'aiml301_sre_agentcore'
    
    try:
        interpreter_id = ssm.get_parameter(Name=f'/{WORKSHOP_NAME}/lab-03/code-interpreter-id')['Parameter']['Value']
        interpreter_arn = ssm.get_parameter(Name=f'/{WORKSHOP_NAME}/lab-03/code-interpreter-arn')['Parameter']['Value']
        logger.info(f"âœ… Retrieved code interpreter from SSM: {interpreter_id}")
        return interpreter_id, interpreter_arn
    except Exception as e:
        logger.error(f"SSM ã‹ã‚‰ Code Interpreter ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise

# Get code interpreter from SSM
CUSTOM_INTERPRETER_ID, CUSTOM_INTERPRETER_ARN = get_code_interpreter_from_ssm()

def get_sre_remediation_s3_bucket():
    # Store in SSM Parameter Store
    parameter_name = '/aiml301_sre_workshop/remediation_s3_bucket'
    #ssm = get_boto3_client('ssm')
    ssm = boto3.client('ssm', region_name='us-west-2')
    parameter = ssm.get_parameter(Name=parameter_name)
    retrieved_bucket_name = parameter['Parameter']['Value']
    print(f"Parameter Store ã‹ã‚‰ãƒã‚±ãƒƒãƒˆåã‚’å–å¾—ã—ã¾ã—ãŸ: {retrieved_bucket_name}")
    return retrieved_bucket_name

# Get s3 details from SSM
retrieved_bucket_name = get_sre_remediation_s3_bucket()

def initialize_code_interpreter_client():
    """AgentCore Code Interpreter ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
    global agentcore_code_interpreter, CODE_INTERPRETER_AVAILABLE
    
    try:
        agentcore_code_interpreter = get_boto3_client('bedrock-agentcore')
        CODE_INTERPRETER_AVAILABLE = True
        logger.info("âœ… AgentCore Code Interpreter client initialized")
        return True
    except Exception as e:
        CODE_INTERPRETER_AVAILABLE = False
        logger.warning(f"âš ï¸ AgentCore Code Interpreter not available: {e}")
        return False

def start_code_interpreter_session():
    """ã‚«ã‚¹ã‚¿ãƒ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ Code Interpreter ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹"""
    if not CODE_INTERPRETER_AVAILABLE:
        return None
    
    try:
        session_response = agentcore_code_interpreter.start_code_interpreter_session(
            codeInterpreterIdentifier=CUSTOM_INTERPRETER_ID,  # Use custom interpreter
            name=f"remediation-session-{uuid.uuid4()}",
            sessionTimeoutSeconds=1800  # 30 minutes
        )
        
        session_id = session_response.get('sessionId')
        logger.info(f"âœ… Code Interpreter session started: {session_id}")
        return session_id
        
    except Exception as e:
        logger.error(f"âŒ Failed to start Code Interpreter session: {e}")
        return None

def stop_code_interpreter_session(session_id: str):
    """Code Interpreter ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åœæ­¢"""
    if not session_id or not CODE_INTERPRETER_AVAILABLE:
        return
    
    try:
        agentcore_code_interpreter.stop_code_interpreter_session(
            codeInterpreterIdentifier=CUSTOM_INTERPRETER_ID,  # Use custom interpreter
            sessionId=session_id
        )
        logger.info(f"âœ… Code Interpreter session stopped: {session_id}")
    except Exception as e:
        logger.error(f"âŒ Failed to stop Code Interpreter session: {e}")

def execute_remediation_code(session_id: str, code: str) -> Dict:
    """ã‚«ã‚¹ã‚¿ãƒ  AgentCore Code Interpreter ã‚’ä½¿ç”¨ã—ã¦ä¿®å¾©ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ"""
    if not session_id:
        return {"error": "No Code Interpreter session available"}
    
    try:
        logger.info(f"ğŸ”§ Executing remediation code: {code}")
        
        execute_response = agentcore_code_interpreter.invoke_code_interpreter(
            codeInterpreterIdentifier=CUSTOM_INTERPRETER_ID,  # Use custom interpreter
            sessionId=session_id,
            name="executeCode",
            arguments={
                "language": "python",
                "code": code
            }
        )
        
        # Process the streaming response
        output_text = ""
        execution_status = "success"
        
        for event in execute_response.get('stream', []):
            if 'result' in event:
                result = event['result']
                if 'content' in result:
                    for content_item in result['content']:
                        if content_item.get('type') == 'text':
                            output_text += content_item.get('text', '')
                        elif content_item.get('type') == 'error':
                            execution_status = "error"
                            output_text += f"ERROR: {content_item.get('text', '')}"
        
        return {
            "execution_status": execution_status,
            "output": output_text,
            "session_id": session_id
        }
        
    except Exception as e:
        logger.error(f"âŒ Failed to execute remediation code: {e}")
        return {"error": f"Code execution failed: {str(e)}"}

# Define FastMCP Tools

@tool
def execute_remediation_step(remediation_code: str) -> str:
    """ä¿®å¾©ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œ"""
    try:
        logger.info(f"ğŸ”§ execute_remediation_step called with code length: {len(remediation_code)}")
        
        if not initialize_code_interpreter_client():
            logger.error("âŒ Code interpreter client not available")
            return "AgentCore Code Interpreter not available"
        
        logger.info("âœ… Code interpreter client initialized")
        session_id = start_code_interpreter_session()
        if not session_id:
            logger.error("âŒ Failed to start code interpreter session")
            return "Failed to start code interpreter session"
        
        logger.info(f"âœ… Code interpreter session started: {session_id}")
        
        # Prepend region detection to all remediation code
        region_detection = """import requests
import os

# Detect AWS region from EC2 metadata
try:
    token = requests.put(
        'http://169.254.169.254/latest/api/token',
        headers={'X-aws-ec2-metadata-token-ttl-seconds': '21600'},
        timeout=1
    ).text
    AWS_REGION = requests.get(
        'http://169.254.169.254/latest/meta-data/placement/region',
        headers={'X-aws-ec2-metadata-token': token},
        timeout=1
    ).text
    print(f"âœ“ Detected region: {AWS_REGION}")
except Exception as e:
    AWS_REGION = 'us-west-2'
    print(f"âš  Using default region: {AWS_REGION}")

"""
        wrapped_code = region_detection + remediation_code
        
        try:
            logger.info("âš¡ Executing remediation code...")
            execution_result = execute_remediation_code(session_id, wrapped_code)
            logger.info(f"âœ… Code execution completed")
            
            if 'error' in execution_result:
                logger.error(f"âŒ Execution error: {execution_result['error']}")
                return f"âŒ failed: {execution_result['error']}"
            
            response = f"# âœ… APPROVED EXECUTION - Results\n\n"
            response += "## Execution Output\n\n```\n"
            response += execution_result['output']
            response += "\n```\n"
            
            logger.info(f"âœ… Execution successful, output length: {len(execution_result['output'])}")
            return response
            
        except Exception as e:
            logger.error(f"âŒ Execution exception: {type(e).__name__}: {str(e)}", exc_info=True)
            return f"âŒ remediation plan execution failed: {str(e)}"
        finally:
            logger.info(f"ğŸ›‘ Stopping session: {session_id}")
            stop_code_interpreter_session(session_id)
            
    except Exception as e:
        logger.error(f"âŒ execute_remediation_step failed: {type(e).__name__}: {str(e)}", exc_info=True)
        return f"âŒ Tool failed: {str(e)}"

@tool
def validate_remediation_environment() -> str:
    """ä¿®å¾©ç’°å¢ƒãŒæº–å‚™å®Œäº†ã—ã¦ã„ã‚‹ã“ã¨ã‚’æ¤œè¨¼"""
    try:
        logger.info("ğŸ” validate_remediation_environment called")
        logger.info("ğŸ” Validating remediation environment...")
        
        validation_results = {
            "code_interpreter_available": False,
            "session_creation": False,
            "aws_access": False,
            "environment_ready": False
        }
        
        try:
            # Test code interpreter initialization
            logger.info("ã‚³ãƒ¼ãƒ‰ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿ãƒ¼ã®åˆæœŸåŒ–ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
            if initialize_code_interpreter_client():
                validation_results["code_interpreter_available"] = True
                logger.info("âœ… Code interpreter available")
                
                # Test session creation
                logger.info("ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆã‚’ãƒ†ã‚¹ãƒˆä¸­...")
                session_id = start_code_interpreter_session()
                if session_id:
                    validation_results["session_creation"] = True
                    validation_results["aws_access"] = True  # Simplified for demo
                    logger.info(f"âœ… Session created: {session_id}")
                    stop_code_interpreter_session(session_id)
                else:
                    logger.error("âŒ Session creation failed")
            else:
                logger.error("âŒ Code interpreter not available")
            
            validation_results["environment_ready"] = all([
                validation_results["code_interpreter_available"],
                validation_results["session_creation"],
                validation_results["aws_access"]
            ])
            
        except Exception as e:
            logger.error(f"âŒ Environment validation failed: {type(e).__name__}: {str(e)}", exc_info=True)
        
        # Format response
        response = "# Remediation Environment Validation\n\n"
        response += f"**Validation Date**: {datetime.now(timezone.utc).isoformat()}\n\n"
        
        for check, status in validation_results.items():
            status_icon = "âœ…" if status else "âŒ"
            check_name = check.replace('_', ' ').title()
            response += f"- **{check_name}**: {status_icon} {'PASS' if status else 'FAIL'}\n"
        
        if validation_results["environment_ready"]:
            response += "\nğŸ‰ **Environment is READY for remediation**\n"
            logger.info("âœ… Environment validation passed")
        else:
            response += "\nâš ï¸ **Environment is NOT READY**\n"
            logger.warning("âš ï¸ Environment validation failed")

        logger.info("=" * 80)
        logger.info("ğŸ“¤ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹")
        logger.info(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ—: {type(response)}")
        logger.info(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹å±æ€§: {dir(response)}")
        logger.debug(f"Full response object: {response}")
        logger.debug(f"Response.message: {response.message}")
        logger.info("=" * 80)
        
        return response
        
    except Exception as e:
        logger.error(f"âŒ validate_remediation_environment failed: {type(e).__name__}: {str(e)}", exc_info=True)
        return f"âŒ Validation failed: {str(e)}"

@tool
def persist_remediation_scripts_to_s3(
    file_key: str,
    content: str
) -> dict:
    """Python ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ S3 ãƒã‚±ãƒƒãƒˆã«æ›¸ãè¾¼ã‚€ã€‚

    Args:
        file_key: ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã‚‹ S3 ã‚­ãƒ¼ï¼ˆãƒ‘ã‚¹/ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
        content: ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€å†…å®¹
    """
    bucket_name=retrieved_bucket_name
    region=AWS_REGION
    try:
        s3_client = get_boto3_client('s3')
        
        # Write to S3
        s3_client.put_object(
            Bucket=bucket_name,
            Key=file_key,
            Body=content.encode('utf-8')
        )
        
        # Generate S3 URL
        s3_url = f"s3://{bucket_name}/{file_key}"
        https_url = f"https://{bucket_name}.s3.{region}.amazonaws.com/{file_key}"
        
        result = {
            "success": True,
            "message": "Successfully wrote file to S3",
            "bucket": bucket_name,
            "key": file_key,
            "s3_url": s3_url,
            "https_url": https_url,
            "size_bytes": len(content.encode('utf-8'))
        }
        
        return {
            "status": "success",
            "content": [
                {"text": f"âœ“ File written  to {s3_url}"},
                {"json": result}
            ]
        }
        
    except Exception as e:
        error_msg = f"Failed to write file to S3: {str(e)}"
        return {
            "status": "error",
            "content": [
                {"text": error_msg}
            ]
        }

@tool
def read_remediation_scripts_from_s3(prefix: str = "") -> dict:
    """S3 ãƒã‚±ãƒƒãƒˆã‹ã‚‰ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å–ã‚Šã€ãã®å†…å®¹ã‚’è¿”ã™ã€‚

    Args:
        prefix: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼ˆä¾‹: 'crm-remediation'ï¼‰
    """
    bucket_name=retrieved_bucket_name
    region = AWS_REGION
    max_files = 100

    try:
        logger.info(f"ğŸ”§ read_remediation_scripts_from_s3 called with prefix='{prefix}'")
        logger.info(f"ğŸ“¦ Reading from bucket: {bucket_name}, region: {region}")
        
        s3_client = get_boto3_client('s3')
        
        # List objects
        list_params = {
            'Bucket': bucket_name,
            'MaxKeys': max_files
        }
        if prefix:
            list_params['Prefix'] = prefix
        
        logger.info(f"ğŸ“‹ Listing objects with params: {list_params}")
        response = s3_client.list_objects_v2(**list_params)
        
        # FIX: Changed 'in' to 'not in' - return early only when NO files found
        if 'Contents' not in response:
            logger.warning(f"âš ï¸ No files found in s3://{bucket_name}/{prefix}")
            return {
                "status": "success",
                "content": [
                    {"text": f"No files found in s3://{bucket_name}/{prefix}"},
                    {"json": {
                        "success": True,
                        "bucket": bucket_name,
                        "prefix": prefix,
                        "file_count": 0,
                        "files": []
                    }}
                ]
            }
        
        logger.info(f"âœ… Found {len(response['Contents'])} objects")
        files_data = []
        total_size = 0
        
        # Read each file
        for obj in response['Contents']:
            file_key = obj['Key']
            
            # Skip directories (keys ending with /)
            if file_key.endswith('/'):
                logger.info(f"â­ï¸ Skipping directory: {file_key}")
                continue
            
            logger.info(f"ğŸ“„ Reading file: {file_key}")
            try:
                # Read file content
                file_response = s3_client.get_object(Bucket=bucket_name, Key=file_key)
                content = file_response['Body'].read().decode('utf-8')
                
                file_info = {
                    'key': file_key,
                    's3_url': f"s3://{bucket_name}/{file_key}",
                    'size': obj['Size'],
                    'last_modified': obj['LastModified'].isoformat(),
                    'content': content
                }
                files_data.append(file_info)
                total_size += obj['Size']
                logger.info(f"âœ… Read file: {file_key} ({obj['Size']} bytes)")
            except Exception as file_error:
                # If a file can't be read, include error info but continue
                logger.error(f"âŒ Failed to read {file_key}: {type(file_error).__name__}: {str(file_error)}")
                files_data.append({
                    'key': file_key,
                    's3_url': f"s3://{bucket_name}/{file_key}",
                    'size': obj['Size'],
                    'last_modified': obj['LastModified'].isoformat(),
                    'error': str(file_error)
                })
        
        logger.info(f"âœ… Successfully read {len(files_data)} files, total size: {total_size} bytes")
        result = {
            "success": True,
            "message": f"Successfully read {len(files_data)} files from S3",
            "bucket": bucket_name,
            "prefix": prefix,
            "file_count": len(files_data),
            "total_size_bytes": total_size,
            "files": files_data
        }
        
        return {
            "status": "success",
            "content": [
                {"text": f"âœ“ Read {len(files_data)} files from s3://{bucket_name}/{prefix}"},
                {"json": result}
            ]
        }
        
    except Exception as e:
        logger.error(f"âŒ read_remediation_scripts_from_s3 failed: {type(e).__name__}: {str(e)}", exc_info=True)
        error_msg = f"Failed to read files from S3: {str(e)}"
        return {
            "status": "error",
            "content": [
                {"text": error_msg}
            ]
        }

@tool
def get_current_time() -> str:
    """ç¾åœ¨æ™‚åˆ»ã‚’ UTC ISO å½¢å¼ã§å–å¾—ã™ã‚‹ã€‚"""
    from datetime import datetime, timezone
    return datetime.now(timezone.utc).isoformat()

@tool
def convert_timezone(time_str: str, from_tz: str, to_tz: str) -> str:
    """ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³é–“ã§æ™‚åˆ»ã‚’å¤‰æ›ã™ã‚‹ã€‚UTC ã¨ ISO å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆï¼ˆä¾‹: 'America/Los_Angeles', 'US/Pacific'ï¼‰ã€‚"""
    from datetime import datetime
    from zoneinfo import ZoneInfo
    
    # Parse input time
    dt = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
    
    # Convert from source timezone
    if from_tz.upper() == 'UTC':
        dt = dt.replace(tzinfo=ZoneInfo('UTC'))
    else:
        dt = dt.replace(tzinfo=ZoneInfo(from_tz))
    
    # Convert to target timezone
    if to_tz.upper() == 'UTC':
        dt = dt.astimezone(ZoneInfo('UTC'))
    else:
        dt = dt.astimezone(ZoneInfo(to_tz))
    
    return dt.isoformat()

current_architecture = """
## Current Architecture

## System Context
You are troubleshooting a 3-tier web application deployed on AWS. The infrastructure consists of two separate application flows: a main Python application and a CRM demo application, both with complete observability through CloudWatch.

## Network Architecture

### VPC Configuration
- VPC CIDR: 10.0.0.0/16
- Public Subnets: 10.0.1.0/24 (AZ1), 10.0.2.0/24 (AZ2)
- Private Subnets: 10.0.10.0/24 (AZ1), 10.0.11.0/24 (AZ2)
- Internet Gateway: Attached to VPC for public internet access
- NAT Gateway: Located in PublicSubnet1 for private subnet egress



## Application Flow: CRM Demo Application

### Traffic Path
```
Internet (Port 8080)
  â†“
Public ALB (sre-workshop-public-alb)
  - Same ALB as main app
  - Listener: Port 8080 â†’ CRMAppTargetGroup
  â†“
CRM App Instance (CRMAppInstance)
  - Instance Type: t3.micro
  - Subnet: PrivateSubnet1 (10.0.10.0/24)
  - Port: 8080
  - Security Group: CRMAppSecurityGroup (allows PublicALBSecurityGroup â†’ 8080)
  - Application: Python Flask/Gunicorn CRM app (2 workers)
  - Health Check: /health endpoint
  â†“
DynamoDB Tables (3 tables):
  1. CRMCustomersTable
  2. CRMDealsTable
  3. CRMActivitiesTable
```

### CRM Instance Details
- **IAM Role**: prefixed with EC2InstanceRole. The role should have allow to access DynamoDB tables.
  - DynamoDB access to all 3 CRM tables
  - CloudWatch agent permissions
  - S3 read access to AssetsBucketName
- **Environment Variables**:
  - AWS_REGION: Current region
  - CUSTOMERS_TABLE: CRMCustomersTable name
  - DEALS_TABLE: CRMDealsTable name
  - ACTIVITIES_TABLE: CRMActivitiesTable name
- **Initialization**: Runs init_sample_data.py to populate sample data
- **Service**: Systemd service (crm-app.service)
- **Tags**: DeploymentVersion: "2.0"

### CRM Data Model
```
CRMCustomersTable
  - Partition Key: customer_id (String)
  - Contains: Customer profile information

CRMDealsTable
  - Partition Key: deal_id (String)
  - Global Secondary Index: customer-index
    - Hash Key: customer_id
  - Relationship: One customer â†’ Many deals

CRMActivitiesTable
  - Partition Key: activity_id (String)
  - Global Secondary Index: customer-index
    - Hash Key: customer_id
  - Relationship: One customer â†’ Many activities
```


## Security Group Chain

### Main Application Security Flow
```
PublicALBSecurityGroup
  - Ingress: 0.0.0.0/0 â†’ 80, 443, 8080
  â†“ allows traffic to
NginxSecurityGroup
  - Ingress: PublicALBSecurityGroup â†’ 80
  â†“ allows traffic to
PrivateALBSecurityGroup
  - Ingress: NginxSecurityGroup â†’ 80
  â†“ allows traffic to
AppServerSecurityGroup
  - Ingress: PrivateALBSecurityGroup â†’ 8080
```

### CRM Application Security Flow
```
PublicALBSecurityGroup
  - Ingress: 0.0.0.0/0 â†’ 8080
  â†“ allows traffic to
CRMAppSecurityGroup
  - Ingress: PublicALBSecurityGroup â†’ 8080
```


## Observability Stack


sre-workshop-crm-app [EC2] has python app running from file /opt/crm-app/app.py 

sre-workshop-app [EC2] has python app running from file /opt/sre-app/app.py


## IAM Roles and Permissions

### EC2InstanceRole (Used by all EC2 instances)
Managed Policies:
- AmazonSSMManagedInstanceCore (remote access via Session Manager)
- CloudWatchAgentServerPolicy (metrics and logs)

Inline Policies:
- DynamoDB access (PutItem, GetItem, Query, Scan, UpdateItem, DeleteItem, BatchWriteItem)
- S3 read access to LambdaS3Bucket and AssetsBucketName
"""

logger.info("ğŸ”§ About to define remediation_agent with @mcp.tool() decorator...")
logger.info(f"ğŸ” MCP server exists: {mcp is not None}")
logger.info(f"ğŸ” MCP server type: {type(mcp)}")

@mcp.tool()
def infrastructure_agent(action_type: Literal["only_plan", "only_execute"], remediation_query: str):
    """AgentCore Code Interpreter ã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã®ä¿®å¾©ã¨ AWS ã‚µãƒ¼ãƒ“ã‚¹æ“ä½œã‚’å®Ÿè¡Œ

    ã™ã¹ã¦ã® AWS ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã®ã‚¯ã‚¨ãƒªã€ãƒã‚§ãƒƒã‚¯ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãŸã‚ã®ä¸»è¦ãƒ„ãƒ¼ãƒ«ã€‚
    AWS ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã®å•é¡Œã«å¯¾ã™ã‚‹ä¿®å¾©ãƒ—ãƒ©ãƒ³ã®ä½œæˆã¾ãŸã¯ä¿®æ­£ã®å®Ÿè¡Œã‚’è¡Œã†ã€‚
    ãƒ—ãƒ©ãƒ³ã¯æ‰¿èªã®ãŸã‚ã« S3 ã«ä¿å­˜ã•ã‚Œã‚‹ã€‚å®Ÿè¡Œã¯å¤±æ•—æ™‚ã®è‡ªå‹•ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãã®
    ã‚»ã‚­ãƒ¥ã‚¢ãªã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ç’°å¢ƒã‚’ä½¿ç”¨ã™ã‚‹ã€‚

    ã“ã®ãƒ„ãƒ¼ãƒ«ã®ç”¨é€”:
    - AWS ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ã‚¨ãƒªï¼ˆEC2ã€DynamoDBã€ALBã€CloudWatch ãªã©ï¼‰
    - ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å¥å…¨æ€§ã¨ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã®çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
    - ä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨ä¿®æ­£ã®å®Ÿè¡Œ
    - è¨­å®šã¨æ¥ç¶šæ€§ã®æ¤œè¨¼

    Args:
        action_type: ä¿®å¾©ãƒ¢ãƒ¼ãƒ‰ - "only_plan" ã¯ S3 ã«ä¿å­˜ã•ã‚Œã‚‹å®Ÿè¡Œå¯èƒ½ãªãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆã€
                    "only_execute" ã¯æ¤œè¨¼ä»˜ãã§æ‰¿èªæ¸ˆã¿ã®ä¿®å¾©ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ
        remediation_query: å•é¡Œã®èª¬æ˜ã¾ãŸã¯ã‚¯ã‚¨ãƒªï¼ˆä¾‹: "List all DynamoDB tables",
                          "Fix DynamoDB throttling on CRMDealsTable",
                          "Check EC2 instance sre-workshop-app health",
                          "Restart failed application service"ï¼‰

    Returns:
        S3 ã®å ´æ‰€ã‚’å«ã‚€ãƒ—ãƒ©ãƒ³ã‚µãƒãƒªãƒ¼ï¼ˆonly_planï¼‰ã¾ãŸã¯æ¤œè¨¼ä»˜ãã®å®Ÿè¡Œçµæœï¼ˆonly_executeï¼‰
    """
    try:
        logger.info(f"ğŸ”§ remediation_agent called with action_type={action_type}, query={remediation_query}")
        
        if not initialize_code_interpreter_client():
            logger.error("âŒ Failed to initialize code interpreter client")
            return "Error: Failed to initialize code interpreter client"
        
        logger.info(f"âœ… Code interpreter client initialized")
        boto_session = get_boto3_session()
        model = BedrockModel(model_id=MODEL_ID, streaming=True, boto_session=boto_session)
        logger.info(f"âœ… Bedrock model initialized: {MODEL_ID}")
        
        if action_type == "only_plan":
            logger.info("ğŸ“‹ Setting up agent for plan-only mode")
            system_prompt=f"""ã‚ãªãŸã¯å®Ÿè¡Œå¯èƒ½ãªä¿®å¾©ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã™ã‚‹ AWS SRE ä¿®å¾©è¨ˆç”»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ï¼ˆã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãªã—ï¼‰ã€‚ä»¥ä¸‹ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è©³ç´°ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™: {current_architecture}

ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ï¼šã‚µãƒ¼ãƒ“ã‚¹ã®å¯ç”¨æ€§ã‚’å¾©æ—§ã™ã‚‹ãŸã‚ã®å³æ™‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚é•·æœŸçš„ãªæ”¹å–„ã¯å¯¾è±¡å¤–ã§ã™ã€‚

ãƒ—ãƒ©ãƒ³æ§‹é€ ï¼ˆmarkdown ä½¿ç”¨ï¼‰ï¼š
1. **å•é¡Œã®æ¦‚è¦** - å•é¡Œã®ç°¡æ½”ãªèª¬æ˜
2. **æ ¹æœ¬åŸå› ** - è¨ºæ–­ã«åŸºã¥ã„ã¦ç‰¹å®šã•ã‚ŒãŸåŸå› 
3. **å³æ™‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³** - æ®µéšçš„ãªä¿®å¾©æ‰‹é †ï¼ˆç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼‰

è¦ä»¶ï¼š
- å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯æ­£ç¢ºãª AWS ã‚µãƒ¼ãƒ“ã‚¹ã€ãƒªã‚½ãƒ¼ã‚¹ã€æ“ä½œã‚’æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
- å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å½±éŸ¿ã¨ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ï¼ˆLow/Medium/Highï¼‰ã‚’è¦‹ç©ã‚‚ã‚‹
- persist_remediation_scripts_to_s3 ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ©ãƒ³ã‚’ S3 ã«ä¿å­˜ã™ã‚‹

å®Œå…¨ãªãƒ—ãƒ©ãƒ³ãŒ markdown ã¨ã—ã¦ S3 ã«ä¿å­˜ã•ã‚ŒãŸã‚‰ã€ãƒ—ãƒ©ãƒ³ãŒä¿å­˜ã•ã‚ŒãŸ S3 ã®å ´æ‰€ã‚’å«ã‚€ç°¡æ½”ãªã‚µãƒãƒªãƒ¼ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

"""
            agent = Agent(system_prompt=system_prompt,
                model=model, 
                tools=[persist_remediation_scripts_to_s3]
            )
        elif action_type == "only_execute":
            logger.info("âš¡ Setting up agent for execute-only mode")
            system_prompt=f"""
            ã‚ãªãŸã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å•é¡Œã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’æ”¯æ´ã™ã‚‹ AWS ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä¿®å¾©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
            ä»¥ä¸‹ã¯ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°å¯¾è±¡ã®å•é¡Œã«é–¢ã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è©³ç´°ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™: {current_architecture}


å®Ÿè¡Œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ã‚³ãƒ¼ãƒ‰è¦ä»¶ï¼š
1. æ®µéšçš„ã«è€ƒãˆã‚‹
2. boto3 ã‚’ä½¿ç”¨ã—ã¦ Python ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹
3. execute_remediation_step ãƒ„ãƒ¼ãƒ«çµŒç”±ã§ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã€‚å¿…è¦ãª IAM æ¨©é™ãŒã‚ã‚Šã€å¸¸ã« action_type='only_execute' ã‚’ä½¿ç”¨ã—ã¾ã™
4. å¤‰æ›´ã‚’åŠ ãˆã‚‹å‰ã«ãƒªã‚½ãƒ¼ã‚¹ã®çŠ¶æ…‹ã‚’ç¢ºèªã™ã‚‹ï¼ˆã¾ãš describe/list æ“ä½œã‚’å®Ÿè¡Œï¼‰


é‡è¦ï¼š
- å®Ÿè¡Œç’°å¢ƒã¯ AWS ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è‡ªå‹•æ¤œå‡ºã—ã€AWS_REGION å¤‰æ•°ã¨ã—ã¦æä¾›ã—ã¾ã™ã€‚ä½œæ¥­ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¨ã—ã¦å¸¸ã« us-west-2 ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
- boto3 ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹éš›ã¯å¸¸ã«ã“ã®å¤‰æ•°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼š

- EC2 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«æ¥ç¶šã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã¯ã€SSM ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™

ã™ã¹ã¦ã®ä¿®å¾©ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒå®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã®ã‚µãƒãƒªãƒ¼ã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š
1. **å•é¡Œã®æ¦‚è¦** - å•é¡Œã®ç°¡æ½”ãªèª¬æ˜
2. **æ ¹æœ¬åŸå› ** - è¨ºæ–­ã«åŸºã¥ã„ã¦ç‰¹å®šã•ã‚ŒãŸåŸå› 
3. **é©ç”¨ã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³/ä¿®æ­£** - ä¿®æ­£ã®æ¦‚è¦ï¼ˆç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼‰

**é‡è¦ãªæ¤œè¨¼**ï¼šã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«ã€ãƒ‘ãƒ–ãƒªãƒƒã‚¯ ALB [sre-workshop-public-alb] ã«ãƒãƒ¼ãƒˆ 8080 ã§ã‚¢ã‚¯ã‚»ã‚¹ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ãŒè¡¨ç¤ºã•ã‚Œãªã„ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ãŒè¡¨ç¤ºã•ã‚Œã‚‹å ´åˆã¯ã€EC2 [sre-workshop-public-alb ãŠã‚ˆã³ sre-workshop-crm-app] ã§å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã‚’ç¢ºèªã—ã€DynamoDB ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ­£å¸¸ã«æ¥ç¶šã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„

**é‡è¦ãªæ³¨æ„**ï¼šå®Ÿè¡Œã«ã¯ 5 åˆ†ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒã‚ã‚Šã¾ã™ã€‚æ™‚é–“åŠ¹ç‡ãŒè‰¯ãæ§‹æ–‡çš„ã«æ­£ã—ã„ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚åºƒç¯„ãªæ¤œè¨¼ã¯ä¸è¦ã§ã™ã€‚

**ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼æ™‚ã®é‡è¦ãªå¯¾å¿œ**ã€ŒRuntimeError: Connection to the MCP server was closedã€ã‚’å—ä¿¡ã—ãŸå ´åˆã€æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä¸å¯§ã«é€šçŸ¥ã—ã¤ã¤ã€æ­£å¸¸ã«å®Œäº†ã§ããŸã‚¹ãƒ†ãƒƒãƒ—ã‚‚ç¢ºèªã—ã¦ãã ã•ã„ã€‚

"""

            agent = Agent(system_prompt=system_prompt,
                model=model, 
                tools=[execute_remediation_step, validate_remediation_environment, read_remediation_scripts_from_s3, get_current_time, convert_timezone]
            )
        else:
            logger.error(f"âŒ Invalid action_type: {action_type}")
            return f"Error: Invalid action_type '{action_type}'. Must be one of: only_plan, only_execute"
        
        logger.info(f"ğŸ¤– Agent configured, invoking with query...")
        return_text=""
        response = agent(remediation_query)
        logger.info(f"âœ… Agent response received")
        
        response_content = response.message.get('content', [])
        if response_content:
            for content in response_content:
                if isinstance(content, dict) and 'text' in content:
                    return_text = content['text']
            logger.info(f"âœ… Extracted response text (length: {len(return_text)})")
        else:
            logger.warning("âš ï¸ No content in agent response")
        
        return return_text
        
    except Exception as e:
        logger.error(f"âŒ remediation_agent failed: {type(e).__name__}: {str(e)}", exc_info=True)
        return f"Error: {type(e).__name__}: {str(e)}"

# Add tool registration verification AFTER function definition
logger.info("âœ… remediation_agent tool defined")
#logger.info(f"ğŸ” Tool function callable: {callable(remediation_agent)}")

#if callable(remediation_agent):
#    logger.info("âœ… Tool registration successful - MCP server should work properly")
#else:
#    logger.warning("âš ï¸ Tool registration failed - this will cause MCP requests to fail!")

# Initialize at module level
logger.info("ğŸš€ Initializing SRE Remediation Agent with FastMCP")
initialize_code_interpreter_client()

logger.info("ğŸš€ Starting FastMCP server with streamable-http transport on port 8000")

mcp.run(transport="streamable-http")
